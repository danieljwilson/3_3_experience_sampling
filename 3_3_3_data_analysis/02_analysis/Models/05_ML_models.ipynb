{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import Optional, List, Union # type tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df is the non-normalized passive data with features and target \n",
    "df = pd.read_csv('../../../3_3_2_processed_data/modeling/passive_data/df_passive_fe.csv')\n",
    "\n",
    "# mlm_gap_df is the results of the MLM on the gap data\n",
    "mlm_gap_df = pd.read_csv('../../../3_3_2_processed_data/modeling/passive_data/mlm_gap_results_df.csv')\n",
    "mlm_affect_df = pd.read_csv('../../../3_3_2_processed_data/modeling/passive_data/mlm_affect_results_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform train-test split based on the last day of data collection where a subject had \n",
    "data for the SensorKit (based on unlock duration data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 5141\n",
      "Test set size: 1350\n",
      "Number of unique PIDs in training: 105\n",
      "Number of unique PIDs in test: 105\n"
     ]
    }
   ],
   "source": [
    "# Get last day of data collection for each PID based on unlock duration data\n",
    "last_days = df.groupby('PID').agg({\n",
    "    'day': lambda x: x[df['passive_sk_device_total_unlock_duration'].notna()].max()\n",
    "}).reset_index()\n",
    "\n",
    "# Remove any data after each PID's last day\n",
    "tt_filtered = pd.merge(\n",
    "    df,\n",
    "    last_days,\n",
    "    on='PID',\n",
    "    suffixes=('', '_last')\n",
    ")\n",
    "tt_filtered = tt_filtered[tt_filtered['day'] <= tt_filtered['day_last']]\n",
    "\n",
    "# Create train/test splits for each PID\n",
    "train_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "for pid in tt_filtered['PID'].unique():\n",
    "    pid_data = tt_filtered[tt_filtered['PID'] == pid].copy()\n",
    "    \n",
    "    # Sort by day to ensure chronological split\n",
    "    pid_data = pid_data.sort_values('day')\n",
    "    \n",
    "    # Calculate split point at 80%\n",
    "    split_idx = int(len(pid_data) * 0.8)\n",
    "    \n",
    "    # Split the data\n",
    "    train_pid = pid_data.iloc[:split_idx]\n",
    "    test_pid = pid_data.iloc[split_idx:]\n",
    "    \n",
    "    # Append to main dataframes\n",
    "    train_data = pd.concat([train_data, train_pid])\n",
    "    test_data = pd.concat([test_data, test_pid])\n",
    "\n",
    "# Reset indices\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")\n",
    "print(f\"Number of unique PIDs in training: {train_data['PID'].nunique()}\")\n",
    "print(f\"Number of unique PIDs in test: {test_data['PID'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count data points per PID in training set\n",
    "pid_counts = train_data['PID'].value_counts()\n",
    "\n",
    "# Create bar plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(pid_counts)), pid_counts.values)\n",
    "plt.xlabel('PID Index')\n",
    "plt.ylabel('Number of Data Points')\n",
    "plt.title('Number of Data Points per PID in Training Set')\n",
    "\n",
    "# Add mean line\n",
    "mean_points = pid_counts.mean()\n",
    "plt.axhline(y=mean_points, color='r', linestyle='--', label=f'Mean: {mean_points:.1f}')\n",
    "plt.legend()\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty columns:\n",
      "[]\n",
      "\n",
      "Binary columns:\n",
      "['survey_complete', 'tasks_complete', 'watch_wearing', 'weekend', 'day_of_week_0', 'day_of_week_1', 'day_of_week_2', 'day_of_week_3', 'day_of_week_4', 'day_of_week_5', 'day_of_week_6', 'fe_lag_1_survey_complete', 'fe_lag_2_survey_complete', 'fe_lag_3_survey_complete', 'fe_lag_1_tasks_complete', 'fe_lag_2_tasks_complete', 'fe_lag_3_tasks_complete', 'fe_lag_1_watch_wearing', 'fe_lag_2_watch_wearing', 'fe_lag_3_watch_wearing']\n",
      "\n",
      "Non-numeric columns:\n",
      "['PID', 'trial_date', 'cohort']\n"
     ]
    }
   ],
   "source": [
    "# Check for empty, binary (0/1) columns and non-numeric columns\n",
    "empty_cols = []\n",
    "binary_cols = []\n",
    "non_numeric_cols = []\n",
    "\n",
    "for col in train_data.columns:\n",
    "    # Check if column is empty (all NaN)\n",
    "    if train_data[col].isna().all():\n",
    "        empty_cols.append(col)\n",
    "        continue\n",
    "        \n",
    "    # Check if column is non-numeric\n",
    "    if not np.issubdtype(train_data[col].dtype, np.number):\n",
    "        non_numeric_cols.append(col)\n",
    "        continue\n",
    "        \n",
    "    # Check if column only contains 0s and 1s\n",
    "    unique_vals = train_data[col].unique()\n",
    "    unique_vals = unique_vals[~np.isnan(unique_vals)]  # Remove NaN values\n",
    "    if set(unique_vals).issubset({0, 1}):\n",
    "        binary_cols.append(col)\n",
    "\n",
    "print(\"Empty columns:\")\n",
    "print(empty_cols)\n",
    "print(\"\\nBinary columns:\")\n",
    "print(binary_cols)\n",
    "print(\"\\nNon-numeric columns:\")\n",
    "print(non_numeric_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expanding_window_cv_nested(df: pd.DataFrame, validation_days: int = 15) -> list[tuple[np.ndarray, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Performs expanding window cross-validation accounting for nested observations within subjects.\n",
    "    Creates 5 splits, each moving forward by 3 days and using 3 days for validation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Training data containing 'PID' and 'day' columns\n",
    "    validation_days : int\n",
    "        Number of days to use for validation windows\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list of tuples\n",
    "        Each tuple contains (train_idx, val_idx) for one fold, \n",
    "        where indices from all subjects are combined\n",
    "    \"\"\"\n",
    "    # Dictionary to store splits by window position\n",
    "    window_splits = {}  # {window_position: [(train_idx, val_idx), ...]}\n",
    "    \n",
    "    # Process each subject separately\n",
    "    for pid in df['PID'].unique():\n",
    "        # Get data for this subject\n",
    "        subject_data = df[df['PID'] == pid].copy()\n",
    "        \n",
    "        # Get sorted unique days for this subject\n",
    "        subject_days = sorted(subject_data['day'].unique())\n",
    "        n_days = len(subject_days)\n",
    "        \n",
    "        # Skip subjects with too few observations\n",
    "        if n_days < 25:  # means min of 10 days in initial training\n",
    "            continue\n",
    "            \n",
    "        # Determine window days for this subject\n",
    "        window_start_idx = max(0, n_days - validation_days)\n",
    "        window_days = subject_days[window_start_idx:]\n",
    "        \n",
    "        # Create 5 splits, moving forward by 3 days each time\n",
    "        for window_pos in range(0, 5):  # 5 splits\n",
    "            val_start_idx = window_start_idx + (window_pos * 3)  # Move forward by 3 days each time\n",
    "            \n",
    "            # Skip if we don't have enough days left\n",
    "            if val_start_idx + 3 > len(subject_days):\n",
    "                continue\n",
    "                \n",
    "            # Get 3 validation days\n",
    "            val_days = subject_days[val_start_idx:val_start_idx + 3]\n",
    "            \n",
    "            # Get training days (all days up to validation period)\n",
    "            train_days = subject_days[:val_start_idx]\n",
    "            \n",
    "            # Get indices for this split\n",
    "            train_mask = (df['PID'] == pid) & (df['day'].isin(train_days))\n",
    "            val_mask = (df['PID'] == pid) & (df['day'].isin(val_days))\n",
    "            \n",
    "            # Convert to indices\n",
    "            train_idx = np.where(train_mask)[0]\n",
    "            val_idx = np.where(val_mask)[0]\n",
    "            \n",
    "            # Only add split if we have both training and validation data\n",
    "            if len(train_idx) > 0 and len(val_idx) > 0:\n",
    "                # Add to window_splits dictionary\n",
    "                if window_pos not in window_splits:\n",
    "                    window_splits[window_pos] = []\n",
    "                window_splits[window_pos].append((train_idx, val_idx))\n",
    "    \n",
    "    # Combine splits for each window position\n",
    "    combined_splits = []\n",
    "    for window_pos in sorted(window_splits.keys()):\n",
    "        # Combine all train indices and all val indices for this window position\n",
    "        all_train_idx = np.concatenate([split[0] for split in window_splits[window_pos]])\n",
    "        all_val_idx = np.concatenate([split[1] for split in window_splits[window_pos]])\n",
    "        combined_splits.append((all_train_idx, all_val_idx))\n",
    "    \n",
    "    return combined_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering and Scaling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, features, target_col='target'):\n",
    "    # X and y extraction\n",
    "    X = df[features].values\n",
    "    y = df[target_col].values\n",
    "    return X, y\n",
    "\n",
    "def fit_scaler(train_df, features):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_df[features])\n",
    "    return scaler\n",
    "\n",
    "def transform_data(df, scaler, features):\n",
    "    X = scaler.transform(df[features])\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Threshold Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_subject_thresholds(train_data, target_col='target'):\n",
    "    \"\"\"\n",
    "    Compute per-subject thresholds for median and terciles.\n",
    "    Returns dicts keyed by PID:\n",
    "      median_thresholds[PID] = median_value\n",
    "      tercile_thresholds[PID] = (lower_tercile_value, upper_tercile_value)\n",
    "    \"\"\"\n",
    "    median_thresholds = {}\n",
    "    tercile_thresholds = {}\n",
    "    for pid, pid_df in train_data.groupby('PID'):\n",
    "        vals = pid_df[target_col].values\n",
    "        median_val = np.median(vals)\n",
    "        # Terciles\n",
    "        lower_tercile = np.percentile(vals, 66.66) # top tercile starts above this\n",
    "        tercile_thresholds[pid] = lower_tercile\n",
    "        median_thresholds[pid] = median_val\n",
    "    return median_thresholds, tercile_thresholds\n",
    "\n",
    "def apply_median_split(x, median_val):\n",
    "    return 1 if x > median_val else 0\n",
    "\n",
    "def apply_tercile_split(x, tercile_val):\n",
    "    # top tercile is > tercile_val\n",
    "    return 1 if x > tercile_val else 0\n",
    "\n",
    "def create_categorical_labels(df, median_thresh, tercile_thresh, target_col='target'):\n",
    "    df = df.copy()\n",
    "    \n",
    "   # 1. Median split label\n",
    "    df.loc[:, 'median_label'] = df.apply(\n",
    "        lambda row: apply_median_split(row[target_col], median_thresh[row['PID']]), \n",
    "        axis=1\n",
    "    )\n",
    "    # 2. Tercile split label\n",
    "    df.loc[:, 'tercile_label'] = df.apply(\n",
    "        lambda row: apply_tercile_split(row[target_col], tercile_thresh[row['PID']]), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_change_labels(df, target_col='target', median_thresh=None, tercile_thresh=None):\n",
    "    # Create a copy of the dataframe to avoid the warning\n",
    "    df = df.copy()\n",
    "    \n",
    "    # For each PID, sort by day and create various labels\n",
    "    def pid_change_labels(pid_df):\n",
    "        # Create a copy of the group dataframe\n",
    "        pid_df = pid_df.copy()\n",
    "        pid_df = pid_df.sort_values('day')\n",
    "        vals = pid_df[target_col].values\n",
    "        \n",
    "        # median low-high change\n",
    "        if median_thresh is not None:\n",
    "            med = median_thresh[pid_df['PID'].iloc[0]]\n",
    "            low_high = (vals > med).astype(int)\n",
    "            # low to high change: current=1, previous=0\n",
    "            pid_df.loc[:, 'median_low_high_change'] = np.insert(\n",
    "                (low_high[1:] == 1) & (low_high[:-1] == 0), \n",
    "                0, \n",
    "                False\n",
    "            ).astype(int)\n",
    "        else:\n",
    "            pid_df.loc[:, 'median_low_high_change'] = np.nan\n",
    "        \n",
    "        # tercile low-high change\n",
    "        if tercile_thresh is not None:\n",
    "            t_val = tercile_thresh[pid_df['PID'].iloc[0]]\n",
    "            low_high_terc = (vals > t_val).astype(int)\n",
    "            pid_df.loc[:, 'tercile_low_high_change'] = np.insert(\n",
    "                (low_high_terc[1:] == 1) & (low_high_terc[:-1] == 0), \n",
    "                0, \n",
    "                False\n",
    "            ).astype(int)\n",
    "        else:\n",
    "            pid_df.loc[:, 'tercile_low_high_change'] = np.nan\n",
    "        \n",
    "        # daily change direction\n",
    "        diff = np.insert(np.diff(vals), 0, 0)\n",
    "        pid_df.loc[:, 'daily_change_direction'] = (diff > 0).astype(int)\n",
    "        \n",
    "        # large increase (>=1 SD)\n",
    "        std_val = np.std(vals)\n",
    "        large_inc = np.insert((np.diff(vals) >= std_val), 0, False).astype(int)\n",
    "        pid_df.loc[:, 'large_increase'] = large_inc\n",
    "        \n",
    "        return pid_df\n",
    "    \n",
    "    df = df.groupby('PID', group_keys=False).apply(pid_change_labels)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    return mae, rmse\n",
    "\n",
    "def classification_metrics(y_true, y_pred):\n",
    "    # y_pred are class labels\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    return acc, prec, rec, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard ML Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regression_model(X_train, y_train, model_type='linear'):\n",
    "    if model_type == 'linear':\n",
    "        model = LinearRegression()\n",
    "    elif model_type == 'rf':\n",
    "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    elif model_type == 'xgb':\n",
    "        model = xgb.XGBRegressor(n_estimators=100, random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model type\")\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def train_classification_model(X_train, y_train, model_type='logistic'):\n",
    "    if model_type == 'logistic':\n",
    "        model = LogisticRegression()\n",
    "    elif model_type == 'rf':\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    elif model_type == 'xgb':\n",
    "        model = xgb.XGBClassifier(n_estimators=100, random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model type\")\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y, seq_len=7):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X) - self.seq_len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.X[idx:idx+self.seq_len], self.y[idx+self.seq_len])\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=32, num_layers=1):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "def train_lstm_model(X_train, y_train, input_size, seq_len=7, epochs=10):\n",
    "    dataset = TimeSeriesDataset(X_train, y_train, seq_len=seq_len)\n",
    "    loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    model = LSTMModel(input_size)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for Xb, yb in loader:\n",
    "            Xb = Xb.float()\n",
    "            yb = yb.float().unsqueeze(1)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(Xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model\n",
    "\n",
    "# For a transformer or classification with neural nets, you’d define a similar class and training routine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction and Evaluation at Group-Level, Individual-Level, and Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, X):\n",
    "    if hasattr(model, 'predict'):\n",
    "        return model.predict(X)\n",
    "    else:\n",
    "        # For PyTorch models\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_t = torch.tensor(X, dtype=torch.float32)\n",
    "            return model(X_t).numpy().ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(y_true, y_pred, y_cat, thresh_dict, pid_series):\n",
    "    \"\"\"\n",
    "    Evaluate predictions across all metrics\n",
    "    Returns dict with all evaluation metrics\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Regression metrics\n",
    "    mae, rmse = regression_metrics(y_true, y_pred)\n",
    "    results.update({'mae': mae, 'rmse': rmse})\n",
    "    \n",
    "    # Convert continuous predictions to binary for classification metrics\n",
    "    # 1. Median split\n",
    "    med_pred = np.array([apply_median_split(pred, thresh_dict['median'][pid]) \n",
    "                        for pred, pid in zip(y_pred, pid_series)])\n",
    "    med_true = np.array([apply_median_split(true, thresh_dict['median'][pid]) \n",
    "                        for true, pid in zip(y_true, pid_series)])\n",
    "    acc, prec, rec, f1 = classification_metrics(med_true, med_pred)\n",
    "    results.update({\n",
    "        'median_accuracy': acc,\n",
    "        'median_precision': prec,\n",
    "        'median_recall': rec,\n",
    "        'median_f1': f1\n",
    "    })\n",
    "    \n",
    "    # 2. Tercile split\n",
    "    terc_pred = np.array([apply_tercile_split(pred, thresh_dict['tercile'][pid]) \n",
    "                         for pred, pid in zip(y_pred, pid_series)])\n",
    "    terc_true = np.array([apply_tercile_split(true, thresh_dict['tercile'][pid]) \n",
    "                         for true, pid in zip(y_true, pid_series)])\n",
    "    acc, prec, rec, f1 = classification_metrics(terc_true, terc_pred)\n",
    "    results.update({\n",
    "        'tercile_accuracy': acc,\n",
    "        'tercile_precision': prec,\n",
    "        'tercile_recall': rec,\n",
    "        'tercile_f1': f1\n",
    "    })\n",
    "    \n",
    "    # 3. Direct classification metrics (if y_cat provided)\n",
    "    if y_cat is not None:\n",
    "        for cat in ['median_label', 'tercile_label', 'median_low_high_change',\n",
    "                   'tercile_low_high_change', 'daily_change_direction', 'large_increase']:\n",
    "            if cat in y_cat:\n",
    "                # For regression models, convert continuous predictions to binary\n",
    "                if not np.all(np.isin(y_pred, [0, 1])):\n",
    "                    # Use 0.5 as threshold for converting continuous predictions to binary\n",
    "                    binary_preds = (y_pred > 0.5).astype(int)\n",
    "                else:\n",
    "                    binary_preds = y_pred\n",
    "                    \n",
    "                acc, prec, rec, f1 = classification_metrics(y_cat[cat].values, binary_preds)\n",
    "                results.update({\n",
    "                    f'{cat}_accuracy': acc,\n",
    "                    f'{cat}_precision': prec,\n",
    "                    f'{cat}_recall': rec,\n",
    "                    f'{cat}_f1': f1\n",
    "                })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def prepare_features(train_data, test_data, features):\n",
    "    \"\"\"\n",
    "    Prepare features by handling missing values and scaling.\n",
    "    Uses forward fill followed by backward fill for missing values.\n",
    "    \"\"\"\n",
    "    # Create copy of data to avoid modifying original\n",
    "    train_features = train_data[features + ['PID']].copy()\n",
    "    test_features = test_data[features + ['PID']].copy()\n",
    "    \n",
    "    # 1. Handle missing values\n",
    "    # First forward fill within each PID group\n",
    "    for col in features:  # Only process feature columns, not PID\n",
    "        train_features[col] = train_features.groupby('PID')[col].ffill()\n",
    "        test_features[col] = test_features.groupby('PID')[col].ffill()\n",
    "        \n",
    "        # Then backward fill for any remaining NaNs\n",
    "        train_features[col] = train_features.groupby('PID')[col].bfill()\n",
    "        test_features[col] = test_features.groupby('PID')[col].bfill()\n",
    "    \n",
    "    # If there are still any NaNs (e.g., if entire column is NaN for a subject),\n",
    "    # fill with 0 as last resort\n",
    "    train_features[features] = train_features[features].fillna(0)\n",
    "    test_features[features] = test_features[features].fillna(0)\n",
    "    \n",
    "    # 2. Scale features\n",
    "    scaler = StandardScaler()\n",
    "    train_scaled = scaler.fit_transform(train_features[features])\n",
    "    test_scaled = scaler.transform(test_features[features])\n",
    "    \n",
    "    return train_scaled, test_scaled, scaler\n",
    "\n",
    "def main_pipeline(train_data_clean, test_data_clean, features, cv_folds, target_col='target'):\n",
    "    \"\"\"\n",
    "    Main pipeline incorporating CV and multiple models with timing measurements\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    train_data_clean : pd.DataFrame\n",
    "        Training data with features and target\n",
    "    test_data_clean : pd.DataFrame\n",
    "        Test data with features and target\n",
    "    features : list\n",
    "        List of feature column names\n",
    "    cv_folds : list\n",
    "        List of (train_idx, val_idx) tuples for cross-validation\n",
    "    target_col : str\n",
    "        Name of target column\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    results_df : pd.DataFrame\n",
    "        DataFrame containing model performance metrics\n",
    "    timing_df : pd.DataFrame\n",
    "        DataFrame containing timing information for model fitting and prediction\n",
    "    \"\"\"\n",
    "    # Initialize results and timing stats\n",
    "    results = []\n",
    "    timing_stats = {\n",
    "        'model_type': [],\n",
    "        'model_name': [], \n",
    "        'level': [],\n",
    "        'fold': [],\n",
    "        'fit_time': [],\n",
    "        'predict_time': []\n",
    "    }\n",
    "    \n",
    "    # Compute thresholds\n",
    "    thresh_dict = {\n",
    "        'median': compute_subject_thresholds(train_data_clean, target_col)[0],\n",
    "        'tercile': compute_subject_thresholds(train_data_clean, target_col)[1]\n",
    "    }\n",
    "    \n",
    "    # Create categorical labels\n",
    "    train_data_clean = create_categorical_labels(train_data_clean, \n",
    "                                               thresh_dict['median'],\n",
    "                                               thresh_dict['tercile'],\n",
    "                                               target_col)\n",
    "    train_data_clean = create_change_labels(train_data_clean, target_col,\n",
    "                                          thresh_dict['median'],\n",
    "                                          thresh_dict['tercile'])\n",
    "    \n",
    "    # Model configurations\n",
    "    reg_models = {\n",
    "        'linear': 'linear',\n",
    "        'rf_reg': 'rf',\n",
    "        'xgb_reg': 'xgb'\n",
    "    }\n",
    "    \n",
    "    clf_models = {\n",
    "        'logistic': 'logistic',\n",
    "        'rf_clf': 'rf',\n",
    "        'xgb_clf': 'xgb'\n",
    "    }\n",
    "    \n",
    "    # Cross validation loop\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(cv_folds):\n",
    "        print(f\"Processing fold {fold_idx+1}/{len(cv_folds)}\")\n",
    "        \n",
    "        # Split data\n",
    "        train_fold = train_data_clean.iloc[train_idx]\n",
    "        val_fold = train_data_clean.iloc[val_idx]\n",
    "        \n",
    "        # Prepare features\n",
    "        prep_start = time.time()\n",
    "        X_train_scaled, X_val_scaled, scaler = prepare_features(\n",
    "            train_fold, val_fold, features\n",
    "        )\n",
    "        prep_time = time.time() - prep_start\n",
    "        print(f\"Feature preparation time: {prep_time:.2f} seconds\")\n",
    "        \n",
    "        y_train = train_fold[target_col].values\n",
    "        y_val = val_fold[target_col].values\n",
    "        val_pids = val_fold['PID']\n",
    "        \n",
    "        # 1. Regression Models\n",
    "        for model_name, model_type in reg_models.items():\n",
    "            print(f\"\\nProcessing regression model: {model_name}\")\n",
    "            \n",
    "            # Group level\n",
    "            start_time = time.time()\n",
    "            group_model = train_regression_model(X_train_scaled, y_train, model_type)\n",
    "            fit_time = time.time() - start_time\n",
    "            \n",
    "            start_time = time.time()\n",
    "            group_preds = group_model.predict(X_val_scaled)\n",
    "            predict_time = time.time() - start_time\n",
    "            \n",
    "            # Record group-level timing\n",
    "            timing_stats['model_type'].append('regression')\n",
    "            timing_stats['model_name'].append(model_name)\n",
    "            timing_stats['level'].append('group')\n",
    "            timing_stats['fold'].append(fold_idx)\n",
    "            timing_stats['fit_time'].append(fit_time)\n",
    "            timing_stats['predict_time'].append(predict_time)\n",
    "            \n",
    "            # Individual level\n",
    "            ind_fit_times = []\n",
    "            ind_predict_times = []\n",
    "            ind_preds = np.zeros_like(y_val)\n",
    "            \n",
    "            for pid in val_pids.unique():\n",
    "                pid_train_mask = (train_fold['PID'] == pid)\n",
    "                if pid_train_mask.sum() > 10:  # Only train if enough data\n",
    "                    # Prepare features for this individual\n",
    "                    pid_train = train_fold[pid_train_mask]\n",
    "                    pid_val = val_fold[val_pids == pid]\n",
    "                    \n",
    "                    X_pid_train, X_pid_val, _ = prepare_features(\n",
    "                        pid_train, pid_val, features\n",
    "                    )\n",
    "                    \n",
    "                    # Train and time individual model\n",
    "                    start_time = time.time()\n",
    "                    pid_model = train_regression_model(\n",
    "                        X_pid_train, \n",
    "                        pid_train[target_col].values,\n",
    "                        model_type\n",
    "                    )\n",
    "                    ind_fit_times.append(time.time() - start_time)\n",
    "                    \n",
    "                    # Predict and time\n",
    "                    start_time = time.time()\n",
    "                    pid_val_mask = (val_pids == pid)\n",
    "                    ind_preds[pid_val_mask] = pid_model.predict(X_pid_val)\n",
    "                    ind_predict_times.append(time.time() - start_time)\n",
    "                else:\n",
    "                    # Use group predictions if not enough individual data\n",
    "                    pid_val_mask = (val_pids == pid)\n",
    "                    ind_preds[pid_val_mask] = group_preds[pid_val_mask]\n",
    "            \n",
    "            # Record average individual-level timing\n",
    "            if ind_fit_times:\n",
    "                timing_stats['model_type'].append('regression')\n",
    "                timing_stats['model_name'].append(model_name)\n",
    "                timing_stats['level'].append('individual')\n",
    "                timing_stats['fold'].append(fold_idx)\n",
    "                timing_stats['fit_time'].append(np.mean(ind_fit_times))\n",
    "                timing_stats['predict_time'].append(np.mean(ind_predict_times))\n",
    "            \n",
    "            # Combined predictions\n",
    "            combined_preds = 0.5 * (group_preds + ind_preds)\n",
    "            \n",
    "            # Evaluate all prediction types\n",
    "            for pred_type, preds in [('group', group_preds), \n",
    "                                   ('individual', ind_preds),\n",
    "                                   ('combined', combined_preds)]:\n",
    "                eval_results = evaluate_predictions(\n",
    "                    y_val,\n",
    "                    preds,\n",
    "                    val_fold[['median_label', 'tercile_label',\n",
    "                             'median_low_high_change', 'tercile_low_high_change',\n",
    "                             'daily_change_direction', 'large_increase']],\n",
    "                    thresh_dict,\n",
    "                    val_pids\n",
    "                )\n",
    "                \n",
    "                results.append({\n",
    "                    'fold': fold_idx,\n",
    "                    'model': model_name,\n",
    "                    'type': 'regression',\n",
    "                    'level': pred_type,\n",
    "                    **eval_results\n",
    "                })\n",
    "        \n",
    "        # 2. Classification Models\n",
    "        for model_name, model_type in clf_models.items():\n",
    "            print(f\"\\nProcessing classification model: {model_name}\")\n",
    "            \n",
    "            for target in ['median_label', 'tercile_label', 'median_low_high_change',\n",
    "                         'tercile_low_high_change', 'daily_change_direction', 'large_increase']:\n",
    "                \n",
    "                y_train_cat = train_fold[target]\n",
    "                y_val_cat = val_fold[target]\n",
    "                \n",
    "                # Group level\n",
    "                start_time = time.time()\n",
    "                group_model = train_classification_model(X_train_scaled, y_train_cat, model_type)\n",
    "                fit_time = time.time() - start_time\n",
    "                \n",
    "                start_time = time.time()\n",
    "                group_preds = group_model.predict(X_val_scaled)\n",
    "                predict_time = time.time() - start_time\n",
    "                \n",
    "                # Record group-level timing\n",
    "                timing_stats['model_type'].append('classification')\n",
    "                timing_stats['model_name'].append(f\"{model_name}_{target}\")\n",
    "                timing_stats['level'].append('group')\n",
    "                timing_stats['fold'].append(fold_idx)\n",
    "                timing_stats['fit_time'].append(fit_time)\n",
    "                timing_stats['predict_time'].append(predict_time)\n",
    "                \n",
    "                # Individual level\n",
    "                ind_fit_times = []\n",
    "                ind_predict_times = []\n",
    "                ind_preds = np.zeros_like(y_val_cat)\n",
    "                \n",
    "                for pid in val_pids.unique():\n",
    "                    pid_train_mask = (train_fold['PID'] == pid)\n",
    "                    if pid_train_mask.sum() > 10:\n",
    "                        pid_train = train_fold[pid_train_mask]\n",
    "                        pid_val = val_fold[val_pids == pid]\n",
    "                        \n",
    "                        X_pid_train, X_pid_val, _ = prepare_features(\n",
    "                            pid_train, pid_val, features\n",
    "                        )\n",
    "                        \n",
    "                        start_time = time.time()\n",
    "                        pid_model = train_classification_model(\n",
    "                            X_pid_train,\n",
    "                            pid_train[target].values,\n",
    "                            model_type\n",
    "                        )\n",
    "                        ind_fit_times.append(time.time() - start_time)\n",
    "                        \n",
    "                        start_time = time.time()\n",
    "                        pid_val_mask = (val_pids == pid)\n",
    "                        ind_preds[pid_val_mask] = pid_model.predict(X_pid_val)\n",
    "                        ind_predict_times.append(time.time() - start_time)\n",
    "                    else:\n",
    "                        pid_val_mask = (val_pids == pid)\n",
    "                        ind_preds[pid_val_mask] = group_preds[pid_val_mask]\n",
    "                \n",
    "                # Record average individual-level timing\n",
    "                if ind_fit_times:\n",
    "                    timing_stats['model_type'].append('classification')\n",
    "                    timing_stats['model_name'].append(f\"{model_name}_{target}\")\n",
    "                    timing_stats['level'].append('individual')\n",
    "                    timing_stats['fold'].append(fold_idx)\n",
    "                    timing_stats['fit_time'].append(np.mean(ind_fit_times))\n",
    "                    timing_stats['predict_time'].append(np.mean(ind_predict_times))\n",
    "                \n",
    "                # Combined predictions\n",
    "                combined_preds = (0.5 * (group_preds + ind_preds) > 0.5).astype(int)\n",
    "                \n",
    "                # Evaluate all prediction types\n",
    "                for pred_type, preds in [('group', group_preds),\n",
    "                                       ('individual', ind_preds),\n",
    "                                       ('combined', combined_preds)]:\n",
    "                    acc, prec, rec, f1 = classification_metrics(y_val_cat, preds)\n",
    "                    results.append({\n",
    "                        'fold': fold_idx,\n",
    "                        'model': model_name,\n",
    "                        'type': 'classification',\n",
    "                        'target': target,\n",
    "                        'level': pred_type,\n",
    "                        'mae': np.nan,\n",
    "                        'rmse': np.nan,\n",
    "                        'median_accuracy': acc,\n",
    "                        'median_precision': prec,\n",
    "                        'median_recall': rec,\n",
    "                        'median_f1': f1,\n",
    "                        'tercile_accuracy': np.nan,\n",
    "                        'tercile_precision': np.nan,\n",
    "                        'tercile_recall': np.nan,\n",
    "                        'tercile_f1': np.nan,\n",
    "                        'median_low_high_change_accuracy': np.nan,\n",
    "                        'median_low_high_change_precision': np.nan,\n",
    "                        'median_low_high_change_recall': np.nan,\n",
    "                        'median_low_high_change_f1': np.nan,\n",
    "                        'tercile_low_high_change_accuracy': np.nan,\n",
    "                        'tercile_low_high_change_precision': np.nan,\n",
    "                        'tercile_low_high_change_recall': np.nan,\n",
    "                        'tercile_low_high_change_f1': np.nan,\n",
    "                        'daily_change_direction_accuracy': np.nan,\n",
    "                        'daily_change_direction_precision': np.nan,\n",
    "                        'daily_change_direction_recall': np.nan,\n",
    "                        'daily_change_direction_f1': np.nan,\n",
    "                        'large_increase_accuracy': np.nan,\n",
    "                        'large_increase_precision': np.nan,\n",
    "                        'large_increase_recall': np.nan,\n",
    "                        'large_increase_f1': np.nan,\n",
    "                    })\n",
    "                    \n",
    "                    # Update the specific target's metrics\n",
    "                    results[-1][f'{target}_accuracy'] = acc\n",
    "                    results[-1][f'{target}_precision'] = prec\n",
    "                    results[-1][f'{target}_recall'] = rec\n",
    "                    results[-1][f'{target}_f1'] = f1\n",
    "    \n",
    "    # Convert results and timing to DataFrames\n",
    "    results_df = pd.DataFrame(results)\n",
    "    timing_df = pd.DataFrame(timing_stats)\n",
    "    \n",
    "    return results_df, timing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values in t_current\n",
    "train_data_clean = train_data.dropna(subset=['t_current'])\n",
    "test_data_clean = test_data.dropna(subset=['t_current'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CV folds\n",
    "cv_folds = expanding_window_cv_nested(train_data_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 65 features with |t| > 2 (excluding css features):\n"
     ]
    }
   ],
   "source": [
    "# Filter features from mlm_gap_df where abs_t_value > 2 and exclude 'css' features\n",
    "features = [f for f in mlm_gap_df[mlm_gap_df['abs_t_value'] > 2]['feature'].tolist() \n",
    "                       if 'css' not in f]\n",
    "\n",
    "print(f\"Selected {len(features)} features with |t| > 2 (excluding css features):\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Model Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Figure out which parts of the pipeline are taking the most time\n",
    "- Figure out how this is actually scoring the folds and what is being used to determine the numbers in the results\n",
    "- How are the predictions being made? What model is being used?\n",
    "- Is it selecting a best model? If so, how is it doing this?\n",
    "- How to determine underfitting vs. overfitting with some sort of metric and/or visualizations?\n",
    "- Add hyperparameter tuning with optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 1/5\n",
      "Feature preparation time: 0.08 seconds\n",
      "\n",
      "Processing regression model: linear\n",
      "\n",
      "Processing regression model: rf_reg\n",
      "\n",
      "Processing regression model: xgb_reg\n",
      "\n",
      "Processing classification model: logistic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing classification model: rf_clf\n",
      "\n",
      "Processing classification model: xgb_clf\n",
      "Processing fold 2/5\n",
      "Feature preparation time: 0.08 seconds\n",
      "\n",
      "Processing regression model: linear\n",
      "\n",
      "Processing regression model: rf_reg\n",
      "\n",
      "Processing regression model: xgb_reg\n",
      "\n",
      "Processing classification model: logistic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing classification model: rf_clf\n",
      "\n",
      "Processing classification model: xgb_clf\n",
      "Processing fold 3/5\n",
      "Feature preparation time: 0.09 seconds\n",
      "\n",
      "Processing regression model: linear\n",
      "\n",
      "Processing regression model: rf_reg\n",
      "\n",
      "Processing regression model: xgb_reg\n",
      "\n",
      "Processing classification model: logistic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing classification model: rf_clf\n",
      "\n",
      "Processing classification model: xgb_clf\n",
      "Processing fold 4/5\n",
      "Feature preparation time: 0.08 seconds\n",
      "\n",
      "Processing regression model: linear\n",
      "\n",
      "Processing regression model: rf_reg\n",
      "\n",
      "Processing regression model: xgb_reg\n",
      "\n",
      "Processing classification model: logistic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing classification model: rf_clf\n",
      "\n",
      "Processing classification model: xgb_clf\n",
      "Processing fold 5/5\n",
      "Feature preparation time: 0.09 seconds\n",
      "\n",
      "Processing regression model: linear\n",
      "\n",
      "Processing regression model: rf_reg\n",
      "\n",
      "Processing regression model: xgb_reg\n",
      "\n",
      "Processing classification model: logistic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing classification model: rf_clf\n",
      "\n",
      "Processing classification model: xgb_clf\n"
     ]
    }
   ],
   "source": [
    "# Run the pipeline\n",
    "results_df, timing_df = main_pipeline(train_data_clean, test_data_clean, features, cv_folds, target_col='t_current')\n",
    "\n",
    "# # Save results\n",
    "# results_df.to_csv('model_evaluation_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print timing summary\n",
    "print(\"\\nTiming Summary:\")\n",
    "summary = timing_df.groupby(['model_type', 'model_name', 'level']).agg({\n",
    "    'fit_time': ['mean', 'std'],\n",
    "    'predict_time': ['mean', 'std']\n",
    "}).round(3)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'timing_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create timing visualization\u001b[39;00m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m sns\u001b[38;5;241m.\u001b[39mboxplot(data\u001b[38;5;241m=\u001b[39m\u001b[43mtiming_df\u001b[49m, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit_time\u001b[39m\u001b[38;5;124m'\u001b[39m, hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel Fitting Times by Model Type and Level\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxticks(rotation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m45\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'timing_df' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create timing visualization\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.boxplot(data=timing_df, x='model_name', y='fit_time', hue='level')\n",
    "plt.title('Model Fitting Times by Model Type and Level')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create separate plots for regression and classification models\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "# Regression models\n",
    "reg_timing = timing_df[timing_df['model_type'] == 'regression']\n",
    "sns.boxplot(data=reg_timing, x='model_name', y='fit_time', hue='level', ax=ax1)\n",
    "ax1.set_title('Regression Models Fitting Times')\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45)\n",
    "\n",
    "# Classification models\n",
    "clf_timing = timing_df[timing_df['model_type'] == 'classification']\n",
    "sns.boxplot(data=clf_timing, x='model_name', y='fit_time', hue='level', ax=ax2)\n",
    "ax2.set_title('Classification Models Fitting Times')\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>model</th>\n",
       "      <th>type</th>\n",
       "      <th>level</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>median_accuracy</th>\n",
       "      <th>median_precision</th>\n",
       "      <th>median_recall</th>\n",
       "      <th>median_f1</th>\n",
       "      <th>...</th>\n",
       "      <th>tercile_low_high_change_f1</th>\n",
       "      <th>daily_change_direction_accuracy</th>\n",
       "      <th>daily_change_direction_precision</th>\n",
       "      <th>daily_change_direction_recall</th>\n",
       "      <th>daily_change_direction_f1</th>\n",
       "      <th>large_increase_accuracy</th>\n",
       "      <th>large_increase_precision</th>\n",
       "      <th>large_increase_recall</th>\n",
       "      <th>large_increase_f1</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>linear</td>\n",
       "      <td>regression</td>\n",
       "      <td>group</td>\n",
       "      <td>15.618123</td>\n",
       "      <td>19.801684</td>\n",
       "      <td>0.532051</td>\n",
       "      <td>0.507143</td>\n",
       "      <td>0.479730</td>\n",
       "      <td>0.493056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318059</td>\n",
       "      <td>0.474359</td>\n",
       "      <td>0.474359</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.195513</td>\n",
       "      <td>0.195513</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.327078</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>linear</td>\n",
       "      <td>regression</td>\n",
       "      <td>individual</td>\n",
       "      <td>81.907273</td>\n",
       "      <td>254.039855</td>\n",
       "      <td>0.455128</td>\n",
       "      <td>0.440860</td>\n",
       "      <td>0.554054</td>\n",
       "      <td>0.491018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306785</td>\n",
       "      <td>0.455128</td>\n",
       "      <td>0.460714</td>\n",
       "      <td>0.871622</td>\n",
       "      <td>0.602804</td>\n",
       "      <td>0.253205</td>\n",
       "      <td>0.192857</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.316716</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>linear</td>\n",
       "      <td>regression</td>\n",
       "      <td>combined</td>\n",
       "      <td>45.333302</td>\n",
       "      <td>129.058048</td>\n",
       "      <td>0.464744</td>\n",
       "      <td>0.445087</td>\n",
       "      <td>0.520270</td>\n",
       "      <td>0.479751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.451923</td>\n",
       "      <td>0.461794</td>\n",
       "      <td>0.939189</td>\n",
       "      <td>0.619154</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.192691</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.320442</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>rf_reg</td>\n",
       "      <td>regression</td>\n",
       "      <td>group</td>\n",
       "      <td>13.942583</td>\n",
       "      <td>17.952240</td>\n",
       "      <td>0.535256</td>\n",
       "      <td>0.510791</td>\n",
       "      <td>0.479730</td>\n",
       "      <td>0.494774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318059</td>\n",
       "      <td>0.474359</td>\n",
       "      <td>0.474359</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.195513</td>\n",
       "      <td>0.195513</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.327078</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>rf_reg</td>\n",
       "      <td>regression</td>\n",
       "      <td>individual</td>\n",
       "      <td>13.132591</td>\n",
       "      <td>16.942252</td>\n",
       "      <td>0.493590</td>\n",
       "      <td>0.470238</td>\n",
       "      <td>0.533784</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318059</td>\n",
       "      <td>0.474359</td>\n",
       "      <td>0.474359</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.195513</td>\n",
       "      <td>0.195513</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.327078</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>4</td>\n",
       "      <td>xgb_clf</td>\n",
       "      <td>classification</td>\n",
       "      <td>individual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.503205</td>\n",
       "      <td>0.484472</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.501608</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.503205</td>\n",
       "      <td>0.484472</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.501608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daily_change_direction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>4</td>\n",
       "      <td>xgb_clf</td>\n",
       "      <td>classification</td>\n",
       "      <td>combined</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>0.559524</td>\n",
       "      <td>0.313333</td>\n",
       "      <td>0.401709</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>0.559524</td>\n",
       "      <td>0.313333</td>\n",
       "      <td>0.401709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daily_change_direction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>4</td>\n",
       "      <td>xgb_clf</td>\n",
       "      <td>classification</td>\n",
       "      <td>group</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.084507</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.084507</td>\n",
       "      <td>large_increase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>4</td>\n",
       "      <td>xgb_clf</td>\n",
       "      <td>classification</td>\n",
       "      <td>individual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.733974</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.192982</td>\n",
       "      <td>0.209524</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.733974</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.192982</td>\n",
       "      <td>0.209524</td>\n",
       "      <td>large_increase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>4</td>\n",
       "      <td>xgb_clf</td>\n",
       "      <td>classification</td>\n",
       "      <td>combined</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814103</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814103</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>large_increase</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>315 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     fold    model            type       level        mae        rmse  \\\n",
       "0       0   linear      regression       group  15.618123   19.801684   \n",
       "1       0   linear      regression  individual  81.907273  254.039855   \n",
       "2       0   linear      regression    combined  45.333302  129.058048   \n",
       "3       0   rf_reg      regression       group  13.942583   17.952240   \n",
       "4       0   rf_reg      regression  individual  13.132591   16.942252   \n",
       "..    ...      ...             ...         ...        ...         ...   \n",
       "310     4  xgb_clf  classification  individual        NaN         NaN   \n",
       "311     4  xgb_clf  classification    combined        NaN         NaN   \n",
       "312     4  xgb_clf  classification       group        NaN         NaN   \n",
       "313     4  xgb_clf  classification  individual        NaN         NaN   \n",
       "314     4  xgb_clf  classification    combined        NaN         NaN   \n",
       "\n",
       "     median_accuracy  median_precision  median_recall  median_f1  ...  \\\n",
       "0           0.532051          0.507143       0.479730   0.493056  ...   \n",
       "1           0.455128          0.440860       0.554054   0.491018  ...   \n",
       "2           0.464744          0.445087       0.520270   0.479751  ...   \n",
       "3           0.535256          0.510791       0.479730   0.494774  ...   \n",
       "4           0.493590          0.470238       0.533784   0.500000  ...   \n",
       "..               ...               ...            ...        ...  ...   \n",
       "310         0.503205          0.484472       0.520000   0.501608  ...   \n",
       "311         0.551282          0.559524       0.313333   0.401709  ...   \n",
       "312         0.791667          0.214286       0.052632   0.084507  ...   \n",
       "313         0.733974          0.229167       0.192982   0.209524  ...   \n",
       "314         0.814103          0.333333       0.017544   0.033333  ...   \n",
       "\n",
       "     tercile_low_high_change_f1  daily_change_direction_accuracy  \\\n",
       "0                      0.318059                         0.474359   \n",
       "1                      0.306785                         0.455128   \n",
       "2                      0.316667                         0.451923   \n",
       "3                      0.318059                         0.474359   \n",
       "4                      0.318059                         0.474359   \n",
       "..                          ...                              ...   \n",
       "310                         NaN                         0.503205   \n",
       "311                         NaN                         0.551282   \n",
       "312                         NaN                              NaN   \n",
       "313                         NaN                              NaN   \n",
       "314                         NaN                              NaN   \n",
       "\n",
       "     daily_change_direction_precision  daily_change_direction_recall  \\\n",
       "0                            0.474359                       1.000000   \n",
       "1                            0.460714                       0.871622   \n",
       "2                            0.461794                       0.939189   \n",
       "3                            0.474359                       1.000000   \n",
       "4                            0.474359                       1.000000   \n",
       "..                                ...                            ...   \n",
       "310                          0.484472                       0.520000   \n",
       "311                          0.559524                       0.313333   \n",
       "312                               NaN                            NaN   \n",
       "313                               NaN                            NaN   \n",
       "314                               NaN                            NaN   \n",
       "\n",
       "     daily_change_direction_f1  large_increase_accuracy  \\\n",
       "0                     0.643478                 0.195513   \n",
       "1                     0.602804                 0.253205   \n",
       "2                     0.619154                 0.211538   \n",
       "3                     0.643478                 0.195513   \n",
       "4                     0.643478                 0.195513   \n",
       "..                         ...                      ...   \n",
       "310                   0.501608                      NaN   \n",
       "311                   0.401709                      NaN   \n",
       "312                        NaN                 0.791667   \n",
       "313                        NaN                 0.733974   \n",
       "314                        NaN                 0.814103   \n",
       "\n",
       "     large_increase_precision  large_increase_recall  large_increase_f1  \\\n",
       "0                    0.195513               1.000000           0.327078   \n",
       "1                    0.192857               0.885246           0.316716   \n",
       "2                    0.192691               0.950820           0.320442   \n",
       "3                    0.195513               1.000000           0.327078   \n",
       "4                    0.195513               1.000000           0.327078   \n",
       "..                        ...                    ...                ...   \n",
       "310                       NaN                    NaN                NaN   \n",
       "311                       NaN                    NaN                NaN   \n",
       "312                  0.214286               0.052632           0.084507   \n",
       "313                  0.229167               0.192982           0.209524   \n",
       "314                  0.333333               0.017544           0.033333   \n",
       "\n",
       "                     target  \n",
       "0                       NaN  \n",
       "1                       NaN  \n",
       "2                       NaN  \n",
       "3                       NaN  \n",
       "4                       NaN  \n",
       "..                      ...  \n",
       "310  daily_change_direction  \n",
       "311  daily_change_direction  \n",
       "312          large_increase  \n",
       "313          large_increase  \n",
       "314          large_increase  \n",
       "\n",
       "[315 rows x 39 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>model</th>\n",
       "      <th>type</th>\n",
       "      <th>level</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>median_accuracy</th>\n",
       "      <th>median_precision</th>\n",
       "      <th>median_recall</th>\n",
       "      <th>median_f1</th>\n",
       "      <th>...</th>\n",
       "      <th>daily_change_direction_f1</th>\n",
       "      <th>large_increase_accuracy</th>\n",
       "      <th>large_increase_precision</th>\n",
       "      <th>large_increase_recall</th>\n",
       "      <th>large_increase_f1</th>\n",
       "      <th>target</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>linear</td>\n",
       "      <td>regression</td>\n",
       "      <td>group</td>\n",
       "      <td>15.618123</td>\n",
       "      <td>19.801684</td>\n",
       "      <td>0.532051</td>\n",
       "      <td>0.507143</td>\n",
       "      <td>0.479730</td>\n",
       "      <td>0.493056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.195513</td>\n",
       "      <td>0.195513</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.327078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>linear</td>\n",
       "      <td>regression</td>\n",
       "      <td>individual</td>\n",
       "      <td>81.907273</td>\n",
       "      <td>254.039855</td>\n",
       "      <td>0.455128</td>\n",
       "      <td>0.440860</td>\n",
       "      <td>0.554054</td>\n",
       "      <td>0.491018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.602804</td>\n",
       "      <td>0.253205</td>\n",
       "      <td>0.192857</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.316716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>linear</td>\n",
       "      <td>regression</td>\n",
       "      <td>combined</td>\n",
       "      <td>45.333302</td>\n",
       "      <td>129.058048</td>\n",
       "      <td>0.464744</td>\n",
       "      <td>0.445087</td>\n",
       "      <td>0.520270</td>\n",
       "      <td>0.479751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.619154</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.192691</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.320442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>rf_reg</td>\n",
       "      <td>regression</td>\n",
       "      <td>group</td>\n",
       "      <td>13.942583</td>\n",
       "      <td>17.952240</td>\n",
       "      <td>0.535256</td>\n",
       "      <td>0.510791</td>\n",
       "      <td>0.479730</td>\n",
       "      <td>0.494774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.195513</td>\n",
       "      <td>0.195513</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.327078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>rf_reg</td>\n",
       "      <td>regression</td>\n",
       "      <td>individual</td>\n",
       "      <td>13.132591</td>\n",
       "      <td>16.942252</td>\n",
       "      <td>0.493590</td>\n",
       "      <td>0.470238</td>\n",
       "      <td>0.533784</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.195513</td>\n",
       "      <td>0.195513</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.327078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>rf_reg</td>\n",
       "      <td>regression</td>\n",
       "      <td>combined</td>\n",
       "      <td>13.005914</td>\n",
       "      <td>16.705597</td>\n",
       "      <td>0.496795</td>\n",
       "      <td>0.471338</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.485246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.195513</td>\n",
       "      <td>0.195513</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.327078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>xgb_reg</td>\n",
       "      <td>regression</td>\n",
       "      <td>group</td>\n",
       "      <td>14.520377</td>\n",
       "      <td>18.717502</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.195513</td>\n",
       "      <td>0.195513</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.327078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>xgb_reg</td>\n",
       "      <td>regression</td>\n",
       "      <td>individual</td>\n",
       "      <td>14.933582</td>\n",
       "      <td>19.392818</td>\n",
       "      <td>0.525641</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.520270</td>\n",
       "      <td>0.509934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.195513</td>\n",
       "      <td>0.195513</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.327078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>xgb_reg</td>\n",
       "      <td>regression</td>\n",
       "      <td>combined</td>\n",
       "      <td>13.601211</td>\n",
       "      <td>17.239493</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.474684</td>\n",
       "      <td>0.506757</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.195513</td>\n",
       "      <td>0.195513</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.327078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>logistic</td>\n",
       "      <td>classification</td>\n",
       "      <td>group</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>median_label</td>\n",
       "      <td>0.528846</td>\n",
       "      <td>0.503448</td>\n",
       "      <td>0.493243</td>\n",
       "      <td>0.498294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>logistic</td>\n",
       "      <td>classification</td>\n",
       "      <td>individual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>median_label</td>\n",
       "      <td>0.522436</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>0.547297</td>\n",
       "      <td>0.520900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>logistic</td>\n",
       "      <td>classification</td>\n",
       "      <td>combined</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>median_label</td>\n",
       "      <td>0.544872</td>\n",
       "      <td>0.534091</td>\n",
       "      <td>0.317568</td>\n",
       "      <td>0.398305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>logistic</td>\n",
       "      <td>classification</td>\n",
       "      <td>group</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tercile_label</td>\n",
       "      <td>0.669872</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.030928</td>\n",
       "      <td>0.055046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>logistic</td>\n",
       "      <td>classification</td>\n",
       "      <td>individual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tercile_label</td>\n",
       "      <td>0.503205</td>\n",
       "      <td>0.280303</td>\n",
       "      <td>0.381443</td>\n",
       "      <td>0.323144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>logistic</td>\n",
       "      <td>classification</td>\n",
       "      <td>combined</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tercile_label</td>\n",
       "      <td>0.682692</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>0.038835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>logistic</td>\n",
       "      <td>classification</td>\n",
       "      <td>group</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>median_low_high_change</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>logistic</td>\n",
       "      <td>classification</td>\n",
       "      <td>individual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>median_low_high_change</td>\n",
       "      <td>0.618590</td>\n",
       "      <td>0.207317</td>\n",
       "      <td>0.239437</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>logistic</td>\n",
       "      <td>classification</td>\n",
       "      <td>combined</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>median_low_high_change</td>\n",
       "      <td>0.772436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>logistic</td>\n",
       "      <td>classification</td>\n",
       "      <td>group</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tercile_low_high_change</td>\n",
       "      <td>0.804487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>logistic</td>\n",
       "      <td>classification</td>\n",
       "      <td>individual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tercile_low_high_change</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.169492</td>\n",
       "      <td>0.149254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    fold     model            type       level        mae        rmse  \\\n",
       "0      0    linear      regression       group  15.618123   19.801684   \n",
       "1      0    linear      regression  individual  81.907273  254.039855   \n",
       "2      0    linear      regression    combined  45.333302  129.058048   \n",
       "3      0    rf_reg      regression       group  13.942583   17.952240   \n",
       "4      0    rf_reg      regression  individual  13.132591   16.942252   \n",
       "5      0    rf_reg      regression    combined  13.005914   16.705597   \n",
       "6      0   xgb_reg      regression       group  14.520377   18.717502   \n",
       "7      0   xgb_reg      regression  individual  14.933582   19.392818   \n",
       "8      0   xgb_reg      regression    combined  13.601211   17.239493   \n",
       "9      0  logistic  classification       group        NaN         NaN   \n",
       "10     0  logistic  classification  individual        NaN         NaN   \n",
       "11     0  logistic  classification    combined        NaN         NaN   \n",
       "12     0  logistic  classification       group        NaN         NaN   \n",
       "13     0  logistic  classification  individual        NaN         NaN   \n",
       "14     0  logistic  classification    combined        NaN         NaN   \n",
       "15     0  logistic  classification       group        NaN         NaN   \n",
       "16     0  logistic  classification  individual        NaN         NaN   \n",
       "17     0  logistic  classification    combined        NaN         NaN   \n",
       "18     0  logistic  classification       group        NaN         NaN   \n",
       "19     0  logistic  classification  individual        NaN         NaN   \n",
       "\n",
       "    median_accuracy  median_precision  median_recall  median_f1  ...  \\\n",
       "0          0.532051          0.507143       0.479730   0.493056  ...   \n",
       "1          0.455128          0.440860       0.554054   0.491018  ...   \n",
       "2          0.464744          0.445087       0.520270   0.479751  ...   \n",
       "3          0.535256          0.510791       0.479730   0.494774  ...   \n",
       "4          0.493590          0.470238       0.533784   0.500000  ...   \n",
       "5          0.496795          0.471338       0.500000   0.485246  ...   \n",
       "6          0.551282          0.525000       0.567568   0.545455  ...   \n",
       "7          0.525641          0.500000       0.520270   0.509934  ...   \n",
       "8          0.500000          0.474684       0.506757   0.490196  ...   \n",
       "9               NaN               NaN            NaN        NaN  ...   \n",
       "10              NaN               NaN            NaN        NaN  ...   \n",
       "11              NaN               NaN            NaN        NaN  ...   \n",
       "12              NaN               NaN            NaN        NaN  ...   \n",
       "13              NaN               NaN            NaN        NaN  ...   \n",
       "14              NaN               NaN            NaN        NaN  ...   \n",
       "15              NaN               NaN            NaN        NaN  ...   \n",
       "16              NaN               NaN            NaN        NaN  ...   \n",
       "17              NaN               NaN            NaN        NaN  ...   \n",
       "18              NaN               NaN            NaN        NaN  ...   \n",
       "19              NaN               NaN            NaN        NaN  ...   \n",
       "\n",
       "    daily_change_direction_f1  large_increase_accuracy  \\\n",
       "0                    0.643478                 0.195513   \n",
       "1                    0.602804                 0.253205   \n",
       "2                    0.619154                 0.211538   \n",
       "3                    0.643478                 0.195513   \n",
       "4                    0.643478                 0.195513   \n",
       "5                    0.643478                 0.195513   \n",
       "6                    0.643478                 0.195513   \n",
       "7                    0.643478                 0.195513   \n",
       "8                    0.643478                 0.195513   \n",
       "9                         NaN                      NaN   \n",
       "10                        NaN                      NaN   \n",
       "11                        NaN                      NaN   \n",
       "12                        NaN                      NaN   \n",
       "13                        NaN                      NaN   \n",
       "14                        NaN                      NaN   \n",
       "15                        NaN                      NaN   \n",
       "16                        NaN                      NaN   \n",
       "17                        NaN                      NaN   \n",
       "18                        NaN                      NaN   \n",
       "19                        NaN                      NaN   \n",
       "\n",
       "    large_increase_precision  large_increase_recall  large_increase_f1  \\\n",
       "0                   0.195513               1.000000           0.327078   \n",
       "1                   0.192857               0.885246           0.316716   \n",
       "2                   0.192691               0.950820           0.320442   \n",
       "3                   0.195513               1.000000           0.327078   \n",
       "4                   0.195513               1.000000           0.327078   \n",
       "5                   0.195513               1.000000           0.327078   \n",
       "6                   0.195513               1.000000           0.327078   \n",
       "7                   0.195513               1.000000           0.327078   \n",
       "8                   0.195513               1.000000           0.327078   \n",
       "9                        NaN                    NaN                NaN   \n",
       "10                       NaN                    NaN                NaN   \n",
       "11                       NaN                    NaN                NaN   \n",
       "12                       NaN                    NaN                NaN   \n",
       "13                       NaN                    NaN                NaN   \n",
       "14                       NaN                    NaN                NaN   \n",
       "15                       NaN                    NaN                NaN   \n",
       "16                       NaN                    NaN                NaN   \n",
       "17                       NaN                    NaN                NaN   \n",
       "18                       NaN                    NaN                NaN   \n",
       "19                       NaN                    NaN                NaN   \n",
       "\n",
       "                     target  accuracy  precision    recall        f1  \n",
       "0                       NaN       NaN        NaN       NaN       NaN  \n",
       "1                       NaN       NaN        NaN       NaN       NaN  \n",
       "2                       NaN       NaN        NaN       NaN       NaN  \n",
       "3                       NaN       NaN        NaN       NaN       NaN  \n",
       "4                       NaN       NaN        NaN       NaN       NaN  \n",
       "5                       NaN       NaN        NaN       NaN       NaN  \n",
       "6                       NaN       NaN        NaN       NaN       NaN  \n",
       "7                       NaN       NaN        NaN       NaN       NaN  \n",
       "8                       NaN       NaN        NaN       NaN       NaN  \n",
       "9              median_label  0.528846   0.503448  0.493243  0.498294  \n",
       "10             median_label  0.522436   0.496933  0.547297  0.520900  \n",
       "11             median_label  0.544872   0.534091  0.317568  0.398305  \n",
       "12            tercile_label  0.669872   0.250000  0.030928  0.055046  \n",
       "13            tercile_label  0.503205   0.280303  0.381443  0.323144  \n",
       "14            tercile_label  0.682692   0.333333  0.020619  0.038835  \n",
       "15   median_low_high_change  0.769231   0.000000  0.000000  0.000000  \n",
       "16   median_low_high_change  0.618590   0.207317  0.239437  0.222222  \n",
       "17   median_low_high_change  0.772436   0.000000  0.000000  0.000000  \n",
       "18  tercile_low_high_change  0.804487   0.000000  0.000000  0.000000  \n",
       "19  tercile_low_high_change  0.634615   0.133333  0.169492  0.149254  \n",
       "\n",
       "[20 rows x 43 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 1/5\n",
      "Feature preparation time: 0.13 seconds\n",
      "\n",
      "Processing regression model: linear\n",
      "\n",
      "Processing regression model: rf_reg\n",
      "\n",
      "Processing regression model: xgb_reg\n",
      "\n",
      "Processing classification model: logistic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing classification model: rf_clf\n",
      "\n",
      "Processing classification model: xgb_clf\n",
      "Processing fold 2/5\n",
      "Feature preparation time: 0.14 seconds\n",
      "\n",
      "Processing regression model: linear\n",
      "\n",
      "Processing regression model: rf_reg\n",
      "\n",
      "Processing regression model: xgb_reg\n",
      "\n",
      "Processing classification model: logistic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing classification model: rf_clf\n",
      "\n",
      "Processing classification model: xgb_clf\n",
      "Processing fold 3/5\n",
      "Feature preparation time: 0.15 seconds\n",
      "\n",
      "Processing regression model: linear\n",
      "\n",
      "Processing regression model: rf_reg\n",
      "\n",
      "Processing regression model: xgb_reg\n",
      "\n",
      "Processing classification model: logistic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing classification model: rf_clf\n",
      "\n",
      "Processing classification model: xgb_clf\n",
      "Processing fold 4/5\n",
      "Feature preparation time: 0.16 seconds\n",
      "\n",
      "Processing regression model: linear\n",
      "\n",
      "Processing regression model: rf_reg\n",
      "\n",
      "Processing regression model: xgb_reg\n",
      "\n",
      "Processing classification model: logistic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing classification model: rf_clf\n",
      "\n",
      "Processing classification model: xgb_clf\n",
      "Processing fold 5/5\n",
      "Feature preparation time: 0.16 seconds\n",
      "\n",
      "Processing regression model: linear\n",
      "\n",
      "Processing regression model: rf_reg\n",
      "\n",
      "Processing regression model: xgb_reg\n",
      "\n",
      "Processing classification model: logistic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing classification model: rf_clf\n",
      "\n",
      "Processing classification model: xgb_clf\n",
      "         3655194567 function calls (3596620060 primitive calls) in 1694.947 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "     1575    0.010    0.000  150.031    0.095 104062838.py:1(train_regression_model)\n",
      "     9450    0.040    0.000  393.666    0.042 104062838.py:13(train_classification_model)\n",
      "       45    0.000    0.000    0.022    0.000 1045018668.py:1(regression_metrics)\n",
      "      630    0.003    0.000    2.657    0.004 1045018668.py:6(classification_metrics)\n",
      "       45    0.003    0.000    1.449    0.032 1287090067.py:1(evaluate_predictions)\n",
      "       45    0.003    0.000    0.004    0.000 1287090067.py:14(<listcomp>)\n",
      "       45    0.003    0.000    0.004    0.000 1287090067.py:16(<listcomp>)\n",
      "       45    0.003    0.000    0.004    0.000 1287090067.py:27(<listcomp>)\n",
      "       45    0.003    0.000    0.004    0.000 1287090067.py:29(<listcomp>)\n",
      "    10925    9.522    0.001 1114.942    0.102 1287090067.py:61(prepare_features)\n",
      "        1    2.334    2.334 1694.963 1694.963 1287090067.py:92(main_pipeline)\n",
      "        2    0.001    0.001    0.094    0.047 657612694.py:1(compute_subject_thresholds)\n",
      "    32951    0.003    0.000    0.003    0.000 657612694.py:19(apply_median_split)\n",
      "    32951    0.002    0.000    0.002    0.000 657612694.py:22(apply_tercile_split)\n",
      "        1    0.036    0.036    0.384    0.384 657612694.py:26(create_categorical_labels)\n",
      "     4871    0.002    0.000    0.035    0.000 657612694.py:31(<lambda>)\n",
      "     4871    0.002    0.000    0.034    0.000 657612694.py:36(<lambda>)\n",
      "        1    0.001    0.001    0.185    0.185 657612694.py:42(create_change_labels)\n",
      "      105    0.004    0.000    0.128    0.001 657612694.py:47(pid_change_labels)\n",
      "  4941899    0.864    0.000    3.030    0.000 <frozen abc>:117(__instancecheck__)\n",
      "  2360535    0.395    0.000    0.859    0.000 <frozen abc>:121(__subclasscheck__)\n",
      "  6572522    2.762    0.000    3.868    0.000 <frozen importlib._bootstrap>:1207(_handle_fromlist)\n",
      "  1934510    0.617    0.000    0.843    0.000 <frozen importlib._bootstrap>:405(parent)\n",
      "      240    0.000    0.000    0.000    0.000 <string>:1(<lambda>)\n",
      "        1    0.004    0.004 1694.967 1694.967 <string>:1(<module>)\n",
      "     6825    0.004    0.000    0.004    0.000 <string>:2(__eq__)\n",
      "     6300    0.005    0.000    0.006    0.000 <string>:2(__init__)\n",
      "     1890    0.002    0.000    0.003    0.000 __init__.py:1053(is_scalar_nan)\n",
      "      120    0.000    0.000    0.000    0.000 __init__.py:162(__ge__)\n",
      "    61425    0.034    0.000    0.347    0.000 __init__.py:183(dumps)\n",
      "    10500    0.016    0.000    0.088    0.000 __init__.py:299(loads)\n",
      " 39297890    6.189    0.000    6.189    0.000 __init__.py:33(using_copy_on_write)\n",
      "      240    0.002    0.000    0.004    0.000 __init__.py:334(__init__)\n",
      "      960    0.000    0.000    0.000    0.000 __init__.py:343(<genexpr>)\n",
      "      720    0.000    0.000    0.000    0.000 __init__.py:465(_parse_letter_version)\n",
      "      240    0.000    0.000    0.000    0.000 __init__.py:503(_parse_local_version)\n",
      "      240    0.001    0.000    0.001    0.000 __init__.py:515(_cmpkey)\n",
      "      360    0.000    0.000    0.000    0.000 __init__.py:529(<lambda>)\n",
      "     7350    0.008    0.000    0.010    0.000 __init__.py:72(CFUNCTYPE)\n",
      "  1864685    0.154    0.000    0.154    0.000 _array_api.py:12(_check_array_api_dispatch)\n",
      "  1566990    0.182    0.000    0.182    0.000 _array_api.py:170(_check_device_cpu)\n",
      "  7685935    2.502    0.000    3.284    0.000 _array_api.py:227(__getattr__)\n",
      "   321930    0.111    0.000    0.363    0.000 _array_api.py:243(astype)\n",
      "  1566990    0.648    0.000    0.976    0.000 _array_api.py:247(asarray)\n",
      "   345240    0.302    0.000    2.880    0.000 _array_api.py:261(unique_values)\n",
      "    20790    0.021    0.000    0.059    0.000 _array_api.py:267(reshape)\n",
      "  1147320    0.375    0.000    6.832    0.000 _array_api.py:282(isdtype)\n",
      "  2247600    0.667    0.000    2.426    0.000 _array_api.py:289(get_namespace)\n",
      "  1132095    0.868    0.000    6.861    0.000 _array_api.py:360(_asarray_with_order)\n",
      "  1919605    1.048    0.000    1.777    0.000 _array_api.py:70(_is_numpy_namespace)\n",
      "  1147320    0.695    0.000    6.457    0.000 _array_api.py:75(isdtype)\n",
      "   864750    0.172    0.000    1.195    0.000 _array_api.py:82(<genexpr>)\n",
      "1918230/1157400    2.706    0.000    5.426    0.000 _array_api.py:87(_isdtype_single)\n",
      "  1143135    0.270    0.000    3.132    0.000 _array_api.py:96(<genexpr>)\n",
      "        7    0.000    0.000    0.000    0.000 _asarray.py:108(<setcomp>)\n",
      "        7    0.000    0.000    0.000    0.000 _asarray.py:27(require)\n",
      "     3675    0.002    0.000    0.002    0.000 _base.py:122(__init__)\n",
      "     3675    0.003    0.000    0.003    0.000 _base.py:141(_validate_estimator)\n",
      "  3934875    0.714    0.000    0.985    0.000 _base.py:1461(issparse)\n",
      "   367500    0.708    0.000  120.983    0.000 _base.py:181(_make_estimator)\n",
      "   367500    0.479    0.000    0.686    0.000 _base.py:188(<dictcomp>)\n",
      "      525    0.007    0.000    0.087    0.000 _base.py:189(_preprocess_data)\n",
      "     3675    0.028    0.000    0.105    0.000 _base.py:211(_partition_estimators)\n",
      "      525    0.003    0.000    0.108    0.000 _base.py:366(_decision_function)\n",
      "      525    0.000    0.000    0.108    0.000 _base.py:372(predict)\n",
      "      525    0.004    0.000    0.004    0.000 _base.py:388(_set_intercept)\n",
      "   367500    1.596    0.000   45.687    0.000 _base.py:40(_set_random_states)\n",
      "     3150    0.020    0.000    0.313    0.000 _base.py:410(decision_function)\n",
      "     3150    0.022    0.000    0.357    0.000 _base.py:436(predict)\n",
      "      525    0.001    0.000    0.001    0.000 _base.py:637(__init__)\n",
      "      525    0.006    0.000    0.365    0.001 _base.py:650(fit)\n",
      "      525    0.181    0.000    0.199    0.000 _basic.py:1113(lstsq)\n",
      "    53025    0.039    0.000    0.064    0.000 _classes.py:1261(__init__)\n",
      "   371175    0.156    0.000    0.156    0.000 _classes.py:127(__init__)\n",
      "    52500    0.131    0.000   99.165    0.002 _classes.py:1290(fit)\n",
      "   367500    7.533    0.000  250.671    0.001 _classes.py:221(_fit)\n",
      "   367500    0.114    0.000    0.784    0.000 _classes.py:453(_validate_X_predict)\n",
      "    52500    0.058    0.000    0.691    0.000 _classes.py:476(predict)\n",
      "   367500    0.180    0.000    3.255    0.000 _classes.py:580(_prune_tree)\n",
      "   318150    0.201    0.000    0.331    0.000 _classes.py:897(__init__)\n",
      "   315000    0.766    0.000  152.403    0.000 _classes.py:928(fit)\n",
      "   315000    1.047    0.000    5.513    0.000 _classes.py:967(predict_proba)\n",
      "      630    0.001    0.000    0.721    0.001 _classification.py:1070(f1_score)\n",
      "      630    0.001    0.000    0.719    0.001 _classification.py:1251(fbeta_score)\n",
      "      630    0.001    0.000    0.009    0.000 _classification.py:135(_weighted_sum)\n",
      "     3780    0.014    0.000    0.025    0.000 _classification.py:1427(_prf_divide)\n",
      "      630    0.002    0.000    0.171    0.000 _classification.py:144(accuracy_score)\n",
      "     1890    0.004    0.000    0.667    0.000 _classification.py:1492(_check_set_wise_labels)\n",
      "     1890    0.027    0.000    2.168    0.001 _classification.py:1533(precision_recall_fscore_support)\n",
      "      630    0.001    0.000    0.737    0.001 _classification.py:1973(precision_score)\n",
      "      630    0.001    0.000    0.719    0.001 _classification.py:2144(recall_score)\n",
      "     1890    0.035    0.000    1.202    0.001 _classification.py:395(multilabel_confusion_matrix)\n",
      "     2019    0.002    0.000    0.002    0.000 _classification.py:48(_check_zero_division)\n",
      "     4410    0.018    0.000    0.948    0.000 _classification.py:57(_check_targets)\n",
      "  2253070    1.144    0.000    6.881    0.000 _config.py:196(config_context)\n",
      "  6486830    1.398    0.000    2.034    0.000 _config.py:24(_get_threadlocal_config)\n",
      "  4233760    1.522    0.000    3.295    0.000 _config.py:32(get_config)\n",
      "  2253070    3.271    0.000    4.903    0.000 _config.py:50(set_config)\n",
      "     3150    0.019    0.000    0.064    0.000 _constraints.py:417(old_bound_to_new)\n",
      "     3150    0.022    0.000    0.022    0.000 _constraints.py:430(<listcomp>)\n",
      "     3150    0.011    0.000    0.011    0.000 _constraints.py:432(<listcomp>)\n",
      "    10925    0.107    0.000    0.117    0.000 _data.py:71(_is_constant_feature)\n",
      "    10925    0.007    0.000    0.007    0.000 _data.py:796(__init__)\n",
      "    10925    0.005    0.000    0.007    0.000 _data.py:801(_reset)\n",
      "    10925    0.019    0.000   22.853    0.002 _data.py:814(fit)\n",
      "    10925    0.132    0.000   21.301    0.002 _data.py:841(partial_fit)\n",
      "    10925    0.023    0.000    0.061    0.000 _data.py:87(_handle_zeros_in_scale)\n",
      "    21850    0.228    0.000   42.445    0.002 _data.py:988(transform)\n",
      "    98771    0.144    0.000    4.408    0.000 _differentiable_functions.py:132(fun_wrapped)\n",
      "    98771    0.031    0.000    4.439    0.000 _differentiable_functions.py:154(update_fun)\n",
      "    98771    0.126    0.000    0.657    0.000 _differentiable_functions.py:162(grad_wrapped)\n",
      "    98771    0.039    0.000    0.697    0.000 _differentiable_functions.py:166(update_grad)\n",
      "    95621    0.074    0.000    0.186    0.000 _differentiable_functions.py:240(update_x)\n",
      "   101921    0.031    0.000    4.470    0.000 _differentiable_functions.py:249(_update_fun)\n",
      "   101921    0.028    0.000    0.725    0.000 _differentiable_functions.py:254(_update_grad)\n",
      "    98771    0.127    0.000    5.465    0.000 _differentiable_functions.py:282(fun_and_grad)\n",
      "     3150    0.036    0.000    0.371    0.000 _differentiable_functions.py:86(__init__)\n",
      "  8762169    1.209    0.000    1.209    0.000 _dtype.py:24(_kind_name)\n",
      "  8762169    1.430    0.000    1.548    0.000 _dtype.py:330(_name_includes_bit_suffix)\n",
      "  8762169    8.140    0.000   11.457    0.000 _dtype.py:346(_name_get)\n",
      "     1890    0.001    0.000    0.018    0.000 _encode.py:10(_unique)\n",
      "     3780    0.006    0.000    0.184    0.000 _encode.py:194(_encode)\n",
      "     3780    0.012    0.000    0.161    0.000 _encode.py:236(_check_unknown)\n",
      "     1890    0.004    0.000    0.017    0.000 _encode.py:51(_unique_np)\n",
      "   367500    0.223    0.000   33.823    0.000 _forest.py:127(_generate_sample_indices)\n",
      "     3150    0.017    0.000    0.041    0.000 _forest.py:1395(__init__)\n",
      "   367500    1.571    0.000  292.053    0.001 _forest.py:151(_parallel_build_trees)\n",
      "      525    0.003    0.000    0.008    0.000 _forest.py:1737(__init__)\n",
      "     3675    0.009    0.000    0.011    0.000 _forest.py:218(__init__)\n",
      "     3675    0.082    0.000  423.754    0.115 _forest.py:317(fit)\n",
      "     3675    0.184    0.000  121.167    0.033 _forest.py:445(<listcomp>)\n",
      "   371175    0.503    0.000    3.389    0.000 _forest.py:460(<genexpr>)\n",
      "      525    0.000    0.000    0.000    0.000 _forest.py:591(_validate_y_class_weight)\n",
      "     3675    0.012    0.000    0.321    0.000 _forest.py:595(_validate_X_predict)\n",
      "   367500    0.401    0.000    6.661    0.000 _forest.py:640(_accumulate_prediction)\n",
      "     3150    0.005    0.000    0.014    0.000 _forest.py:664(__init__)\n",
      "     3150    0.021    0.000    0.299    0.000 _forest.py:748(_validate_y_class_weight)\n",
      "     3150    0.014    0.000   12.525    0.004 _forest.py:802(predict)\n",
      "     3150    0.043    0.000   12.497    0.004 _forest.py:841(predict_proba)\n",
      "     3150    0.005    0.000    0.008    0.000 _forest.py:871(<listcomp>)\n",
      "   318150    0.324    0.000    2.254    0.000 _forest.py:876(<genexpr>)\n",
      "      525    0.001    0.000    0.003    0.000 _forest.py:933(__init__)\n",
      "     3675    0.000    0.000    0.000    0.000 _forest.py:94(_get_n_samples_bootstrap)\n",
      "      525    0.007    0.000    1.811    0.003 _forest.py:963(predict)\n",
      "    53025    0.046    0.000    0.359    0.000 _forest.py:997(<genexpr>)\n",
      "     3150    0.005    0.000    0.006    0.000 _interface.py:144(__new__)\n",
      "     3150    0.005    0.000    0.029    0.000 _interface.py:159(__init__)\n",
      "     7350    0.008    0.000    0.008    0.000 _internal.py:250(__init__)\n",
      "     7350    0.002    0.000    0.002    0.000 _internal.py:304(data)\n",
      "     3780    0.006    0.000    0.366    0.000 _label.py:118(transform)\n",
      "     1890    0.002    0.000    0.058    0.000 _label.py:84(fit)\n",
      "     3150    0.929    0.000    7.154    0.002 _lbfgsb_py.py:212(_minimize_lbfgsb)\n",
      "     3150    0.038    0.000    0.038    0.000 _lbfgsb_py.py:288(<listcomp>)\n",
      "     3150    0.028    0.000    0.081    0.000 _lbfgsb_py.py:434(__init__)\n",
      "    98771    0.893    0.000    0.936    0.000 _linear_loss.py:138(weight_intercept_raw)\n",
      "    98771    0.114    0.000    0.114    0.000 _linear_loss.py:170(l2_penalty)\n",
      "    98771    1.467    0.000    3.597    0.000 _linear_loss.py:229(loss_gradient)\n",
      "     3150    0.001    0.000    0.001    0.000 _linear_loss.py:67(__init__)\n",
      "    98771    0.042    0.000    0.042    0.000 _linear_loss.py:99(weight_intercept)\n",
      "     3150    0.006    0.000    0.006    0.000 _logistic.py:1104(__init__)\n",
      "     3150    0.059    0.000    8.764    0.003 _logistic.py:1139(fit)\n",
      "     6300    0.016    0.000    0.033    0.000 _logistic.py:1303(<genexpr>)\n",
      "     6300    0.003    0.000    0.003    0.000 _logistic.py:53(_check_solver)\n",
      "     6300    0.002    0.000    0.002    0.000 _logistic.py:78(_check_multi_class)\n",
      "     3150    0.086    0.000    7.501    0.002 _logistic.py:96(_logistic_regression_path)\n",
      "     2280    0.011    0.000    0.029    0.000 _methods.py:101(_mean)\n",
      "      105    0.001    0.000    0.003    0.000 _methods.py:135(_var)\n",
      "      105    0.000    0.000    0.003    0.000 _methods.py:204(_std)\n",
      "    10925    0.025    0.000    0.061    0.000 _methods.py:218(_ptp)\n",
      "  2928125    0.637    0.000    3.797    0.000 _methods.py:39(_amax)\n",
      "   657456    0.157    0.000    1.239    0.000 _methods.py:47(_sum)\n",
      "  1929628    0.444    0.000    2.509    0.000 _methods.py:55(_any)\n",
      "   189400    0.059    0.000    0.332    0.000 _methods.py:61(_all)\n",
      "     2385    0.005    0.000    0.006    0.000 _methods.py:67(_count_reduce_items)\n",
      "     3150    0.008    0.000    0.008    0.000 _methods.py:90(_clip)\n",
      "     3150    0.005    0.000    0.005    0.000 _minimize.py:1019(standardize_constraints)\n",
      "     3150    0.053    0.000    7.242    0.002 _minimize.py:51(minimize)\n",
      "     1050    0.000    0.000    0.000    0.000 _misc.py:181(_datacopied)\n",
      "     3150    0.000    0.000    0.000    0.000 _optimize.py:135(_wrap_callback)\n",
      "    89659    0.008    0.000    0.008    0.000 _optimize.py:156(_call_callback_maybe_halt)\n",
      "    12666    0.002    0.000    0.002    0.000 _optimize.py:221(__getattr__)\n",
      "     3150    0.000    0.000    0.000    0.000 _optimize.py:267(_check_unknown_options)\n",
      "     3150    0.008    0.000    0.379    0.000 _optimize.py:295(_prepare_scalar_function)\n",
      "     3150    0.000    0.000    0.000    0.000 _optimize.py:375(hess)\n",
      "     3150    0.002    0.000    0.002    0.000 _optimize.py:62(__init__)\n",
      "   197542    0.361    0.000    4.475    0.000 _optimize.py:68(_compute_if_needed)\n",
      "    98771    0.040    0.000    4.169    0.000 _optimize.py:75(__call__)\n",
      "    98771    0.035    0.000    0.381    0.000 _optimize.py:80(derivative)\n",
      "    10500    0.001    0.000    0.001    0.000 _parallel_backends.py:106(compute_batch_size)\n",
      "     3150    0.004    0.000    0.008    0.000 _parallel_backends.py:202(in_main_thread)\n",
      "    10500    0.001    0.000    0.001    0.000 _parallel_backends.py:219(effective_n_jobs)\n",
      "     7350    0.002    0.000    0.002    0.000 _parallel_backends.py:246(effective_n_jobs)\n",
      "    17325    0.030    0.000    0.040    0.000 _parallel_backends.py:321(__init__)\n",
      "    35175    0.019    0.000    0.019    0.000 _parallel_backends.py:43(__init__)\n",
      "     7350    0.014    0.000    0.024    0.000 _parallel_backends.py:432(configure)\n",
      "     3150    0.006    0.000    0.027    0.000 _parallel_backends.py:542(configure)\n",
      "     9975    0.009    0.000    0.020    0.000 _parallel_backends.py:557(effective_n_jobs)\n",
      "    10500    0.003    0.000    0.003    0.000 _parallel_backends.py:642(__init__)\n",
      "    10500    0.008    0.000    0.009    0.000 _parallel_backends.py:87(configure)\n",
      "258375/254700    0.254    0.000    0.800    0.000 _param_validation.py:102(make_constraint)\n",
      "7020/2610    0.026    0.000    2.676    0.001 _param_validation.py:183(wrapper)\n",
      "     2610    0.004    0.000    0.005    0.000 _param_validation.py:196(<listcomp>)\n",
      "     2610    0.002    0.000    0.002    0.000 _param_validation.py:202(<dictcomp>)\n",
      "    20885    0.179    0.000    1.466    0.000 _param_validation.py:26(validate_parameter_constraints)\n",
      "   371760    0.040    0.000    0.040    0.000 _param_validation.py:260(__init__)\n",
      "   216900    0.074    0.000    0.094    0.000 _param_validation.py:292(__init__)\n",
      "    73665    0.015    0.000    0.021    0.000 _param_validation.py:296(is_satisfied_by)\n",
      "    35475    0.003    0.000    0.003    0.000 _param_validation.py:306(is_satisfied_by)\n",
      "    26445    0.011    0.000    0.013    0.000 _param_validation.py:362(is_satisfied_by)\n",
      "    13650    0.011    0.000    0.045    0.000 _param_validation.py:432(__init__)\n",
      "    13650    0.014    0.000    0.031    0.000 _param_validation.py:441(_check_params)\n",
      "    45675    0.085    0.000    0.095    0.000 _param_validation.py:480(__contains__)\n",
      "    66150    0.027    0.000    0.186    0.000 _param_validation.py:496(is_satisfied_by)\n",
      "     9720    0.002    0.000    0.020    0.000 _param_validation.py:524(is_satisfied_by)\n",
      "     6825    0.025    0.000    0.059    0.000 _param_validation.py:558(__init__)\n",
      "     6825    0.005    0.000    0.025    0.000 _param_validation.py:566(is_satisfied_by)\n",
      "    19950    0.005    0.000    0.018    0.000 _param_validation.py:567(<genexpr>)\n",
      "    57390    0.092    0.000    0.172    0.000 _param_validation.py:583(__init__)\n",
      "    55500    0.060    0.000    0.159    0.000 _param_validation.py:591(is_satisfied_by)\n",
      "   111000    0.023    0.000    0.037    0.000 _param_validation.py:602(<genexpr>)\n",
      "     6825    0.011    0.000    0.032    0.000 _param_validation.py:618(__init__)\n",
      "     6825    0.005    0.000    0.027    0.000 _param_validation.py:626(is_satisfied_by)\n",
      "    13650    0.003    0.000    0.019    0.000 _param_validation.py:627(<genexpr>)\n",
      "   163905    0.075    0.000    0.875    0.000 _param_validation.py:73(<listcomp>)\n",
      "       45    0.000    0.000    0.007    0.000 _regression.py:140(mean_absolute_error)\n",
      "       45    0.000    0.000    0.006    0.000 _regression.py:404(mean_squared_error)\n",
      "       90    0.000    0.000    0.010    0.000 _regression.py:65(_check_reg_targets)\n",
      "32775/21850    0.062    0.000   65.471    0.003 _set_output.py:155(wrapped)\n",
      "    32775    0.032    0.000    0.067    0.000 _set_output.py:63(_get_output_config)\n",
      "    32775    0.017    0.000    0.084    0.000 _set_output.py:97(_wrap_data_with_container)\n",
      "     6300    0.009    0.000    0.019    0.000 _sputils.py:216(isintlike)\n",
      "     3150    0.005    0.000    0.024    0.000 _sputils.py:238(isshape)\n",
      "  2592910    1.783    0.000    1.955    0.000 _ufunc_config.py:132(geterr)\n",
      "  2592910    2.539    0.000    5.172    0.000 _ufunc_config.py:33(seterr)\n",
      "   557780    0.159    0.000    0.159    0.000 _ufunc_config.py:426(__init__)\n",
      "  1296455    0.735    0.000    3.650    0.000 _ufunc_config.py:430(__enter__)\n",
      "  1296455    0.657    0.000    2.914    0.000 _ufunc_config.py:435(__exit__)\n",
      "     9000    0.004    0.000    0.008    0.000 _ufunc_config.py:452(_no_nep50_warning)\n",
      "     1050    0.004    0.000    0.009    0.000 _util.py:194(_asarray_validated)\n",
      "  1486005    0.347    0.000    0.452    0.000 _validators.py:224(validate_bool_kwarg)\n",
      "    21850    0.050    0.000    0.054    0.000 _validators.py:266(validate_fillna_kwargs)\n",
      "      105    0.000    0.000    0.000    0.000 _validators.py:349(validate_ascending)\n",
      "   142560    0.101    0.000   14.201    0.000 accessor.py:220(__get__)\n",
      "   131100    0.208    0.000   14.029    0.000 accessor.py:231(_validate)\n",
      "   262200    0.059    0.000    0.069    0.000 accessor.py:233(<genexpr>)\n",
      "   142560    0.060    0.000   14.100    0.000 accessor.py:29(__init__)\n",
      "    11460    0.006    0.000    0.011    0.000 accessor.py:45(_validate)\n",
      "  2840608    3.093    0.000   16.271    0.000 algorithms.py:106(_ensure_data)\n",
      "   153043    0.134    0.000    0.375    0.000 algorithms.py:1165(take)\n",
      "  2840503    8.129    0.000   41.274    0.000 algorithms.py:1471(safe_sort)\n",
      "  5681111    3.178    0.000    8.593    0.000 algorithms.py:184(_reconstruct_data)\n",
      "  2840608    0.842    0.000    2.372    0.000 algorithms.py:217(_ensure_arraylike)\n",
      "  2840608    1.781    0.000   34.201    0.000 algorithms.py:251(_get_hashtable_algo)\n",
      "  2840608    3.953    0.000   16.149    0.000 algorithms.py:269(_check_object_for_strings)\n",
      "      105    0.000    0.000    0.012    0.000 algorithms.py:296(unique)\n",
      "      105    0.001    0.000    0.012    0.000 algorithms.py:416(unique_with_mask)\n",
      "  2840503    5.789    0.000   58.270    0.000 algorithms.py:534(factorize_array)\n",
      "  2840503    8.281    0.000  121.936    0.000 algorithms.py:596(factorize)\n",
      "        1    0.000    0.000    0.002    0.002 api.py:112(_get_combined_index)\n",
      "        1    0.000    0.000    0.002    0.002 api.py:194(union_indexes)\n",
      "        1    0.000    0.000    0.000    0.000 api.py:246(_find_common_index_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 api.py:258(<listcomp>)\n",
      "      105    0.000    0.000    0.002    0.000 api.py:299(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 api.py:311(_sanitize_and_check)\n",
      "        1    0.000    0.000    0.000    0.000 api.py:332(<setcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 api.py:367(default_index)\n",
      "        1    0.000    0.000    0.002    0.002 api.py:68(get_objs_combined_axis)\n",
      "        1    0.000    0.000    0.000    0.000 api.py:94(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 api.py:98(_get_distinct_objs)\n",
      "    32775    0.055    0.000    4.892    0.000 apply.py:1010(apply)\n",
      "    32777    0.031    0.000    0.031    0.000 apply.py:103(__init__)\n",
      "    32775    0.272    0.000    4.745    0.000 apply.py:1061(apply_standard)\n",
      "        4    0.000    0.000    0.000    0.000 apply.py:591(index)\n",
      "        2    0.000    0.000    0.000    0.000 apply.py:633(columns)\n",
      "        2    0.000    0.000    0.222    0.111 apply.py:637(values)\n",
      "        2    0.000    0.000    0.318    0.159 apply.py:645(apply)\n",
      "        2    0.000    0.000    0.000    0.000 apply.py:73(frame_apply)\n",
      "        2    0.000    0.000    0.318    0.159 apply.py:797(apply_standard)\n",
      "        2    0.004    0.002    0.315    0.157 apply.py:803(apply_series_generator)\n",
      "        2    0.000    0.000    0.003    0.001 apply.py:822(wrap_results)\n",
      "     9744    0.006    0.000    0.235    0.000 apply.py:918(series_generator)\n",
      "        2    0.000    0.000    0.000    0.000 apply.py:944(result_index)\n",
      "    32775    0.056    0.000    0.087    0.000 apply.py:991(__init__)\n",
      "    32760    0.146    0.000    2.325    0.000 array_ops.py:237(comparison_op)\n",
      "    32760    0.064    0.000    1.855    0.000 array_ops.py:67(comp_method_OBJECT_ARRAY)\n",
      "    32760    0.042    0.000    5.471    0.000 arraylike.py:38(__eq__)\n",
      "   697590    0.196    0.000    0.266    0.000 arraysetops.py:125(_unpack_tuple)\n",
      "   697590    0.064    0.000    0.064    0.000 arraysetops.py:133(_unique_dispatcher)\n",
      "   697590    0.595    0.000    7.056    0.000 arraysetops.py:138(unique)\n",
      "   697590    3.480    0.000    6.134    0.000 arraysetops.py:323(_unique1d)\n",
      "     5940    0.001    0.000    0.001    0.000 arraysetops.py:519(_in1d_dispatcher)\n",
      "     5940    0.077    0.000    0.184    0.000 arraysetops.py:524(in1d)\n",
      "    17550    0.003    0.000    0.003    0.000 arraysetops.py:630(<genexpr>)\n",
      "      270    0.000    0.000    0.000    0.000 arraysetops.py:761(_isin_dispatcher)\n",
      "      270    0.000    0.000    0.003    0.000 arraysetops.py:766(isin)\n",
      "     4410    0.001    0.000    0.001    0.000 arraysetops.py:894(_union1d_dispatcher)\n",
      "     4410    0.011    0.000    0.051    0.000 arraysetops.py:898(union1d)\n",
      "     5670    0.001    0.000    0.001    0.000 arraysetops.py:935(_setdiff1d_dispatcher)\n",
      "     5670    0.008    0.000    0.192    0.000 arraysetops.py:939(setdiff1d)\n",
      "    32775    0.023    0.000    0.103    0.000 astype.py:162(astype_array)\n",
      "    32775    0.071    0.000    0.433    0.000 astype.py:196(astype_array_safe)\n",
      "    54625    0.030    0.000    0.040    0.000 astype.py:254(astype_is_view)\n",
      "      105    0.000    0.000    0.013    0.000 base.py:1024(unique)\n",
      "  1155000    0.293    0.000    0.409    0.000 base.py:1062(is_classifier)\n",
      "   153043    0.490    0.000    1.287    0.000 base.py:1070(take)\n",
      "   153043    0.023    0.000    0.023    0.000 base.py:1101(_maybe_disallow_fill)\n",
      "385775/18275    0.913    0.000  457.502    0.025 base.py:1135(wrapper)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:1175(copy)\n",
      "  1866800    5.968    0.000   95.790    0.000 base.py:147(_get_param_names)\n",
      "  3125479    0.441    0.000    0.441    0.000 base.py:1582(name)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:1600(_validate_names)\n",
      "  1863125    6.681    0.000    9.048    0.000 base.py:161(<listcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 base.py:162(array)\n",
      "  2840715    1.515    0.000    1.923    0.000 base.py:1668(_get_names)\n",
      "  1863125    2.503    0.000    3.506    0.000 base.py:176(<listcomp>)\n",
      "  1866800    5.754    0.000  103.742    0.000 base.py:178(get_params)\n",
      "    65595    0.005    0.000    0.005    0.000 base.py:1877(nlevels)\n",
      "   735000    2.248    0.000   44.039    0.000 base.py:202(set_params)\n",
      "    54629    0.043    0.000    1.046    0.000 base.py:208(interleaved_dtype)\n",
      "    44064    0.132    0.000    0.318    0.000 base.py:2205(is_unique)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:2240(has_duplicates)\n",
      "  2840500    4.670    0.000   92.602    0.000 base.py:232(__getitem__)\n",
      "   153146    0.094    0.000    0.888    0.000 base.py:2636(inferred_type)\n",
      "  2993965    0.660    0.000    2.734    0.000 base.py:2660(_is_multi)\n",
      "   367500    0.159    0.000   50.725    0.000 base.py:267(__sklearn_clone__)\n",
      "    21862    0.012    0.000    0.014    0.000 base.py:2678(_na_value)\n",
      "  3367575    1.847    0.000    8.907    0.000 base.py:286(is_dtype)\n",
      "     9810    0.003    0.000    0.010    0.000 base.py:309(shape)\n",
      "     7350    0.009    0.000    0.013    0.000 base.py:322(__getstate__)\n",
      " 14399097    1.078    0.000    1.078    0.000 base.py:326(ndim)\n",
      "     7350    0.014    0.000    0.024    0.000 base.py:344(__setstate__)\n",
      " 11394547    5.948    0.000    8.866    0.000 base.py:3625(get_loc)\n",
      "   131190    0.623    0.000   11.650    0.000 base.py:3716(get_indexer)\n",
      "   414975    0.208    0.000    1.025    0.000 base.py:374(_check_n_features)\n",
      "   131190    0.227    0.000    1.419    0.000 base.py:3804(_get_indexer)\n",
      "   131190    0.152    0.000    1.094    0.000 base.py:3849(_check_indexing_method)\n",
      "4725000/367500    1.610    0.000   51.129    0.000 base.py:40(clone)\n",
      "      422    0.001    0.000    0.005    0.000 base.py:4059(_convert_slice_indexer)\n",
      "     1266    0.000    0.000    0.000    0.000 base.py:4084(is_int)\n",
      "    65595    0.204    0.000    7.064    0.000 base.py:4174(reindex)\n",
      "    47475    0.132    0.000    0.855    0.000 base.py:420(_check_feature_names)\n",
      "    65595    0.040    0.000    0.139    0.000 base.py:4282(_wrap_reindex_result)\n",
      "    65595    0.079    0.000    0.099    0.000 base.py:4286(_maybe_preserve_names)\n",
      "    65914    0.057    0.000    0.065    0.000 base.py:450(_engine_type)\n",
      "    87392    0.045    0.000    0.097    0.000 base.py:46(__len__)\n",
      "  2972120   15.104    0.000  100.301    0.000 base.py:469(__new__)\n",
      "  4504862    0.495    0.000    0.495    0.000 base.py:4937(_values)\n",
      "   327750    0.177    0.000    0.233    0.000 base.py:494(find)\n",
      "   197104    0.174    0.000    0.434    0.000 base.py:4963(_get_engine_target)\n",
      "      422    0.000    0.000    0.000    0.000 base.py:5071(_validate_fill_value)\n",
      "    47475    0.219    0.000   63.662    0.001 base.py:509(_validate_data)\n",
      " 19940013    9.937    0.000   11.601    0.000 base.py:5109(__contains__)\n",
      " 14226097    8.293    0.000   13.758    0.000 base.py:5159(__getitem__)\n",
      "      315    0.000    0.000    0.002    0.000 base.py:5205(_getitem_slice)\n",
      "    34665    0.036    0.000    0.450    0.000 base.py:5212(_can_hold_identifiers_and_holds_name)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:5230(append)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:5255(<setcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:5260(_concat)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:5264(<listcomp>)\n",
      "        6    0.000    0.000    0.000    0.000 base.py:530(<genexpr>)\n",
      "  7429480    2.960    0.000    5.432    0.000 base.py:5314(equals)\n",
      "  4588751    5.855    0.000   12.100    0.000 base.py:54(shape)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:5401(identical)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:5414(<genexpr>)\n",
      " 13766253    2.273    0.000    6.245    0.000 base.py:56(<genexpr>)\n",
      "  2972120    1.400    0.000    1.400    0.000 base.py:565(_ensure_array)\n",
      "      105    0.000    0.000    0.000    0.000 base.py:5739(_should_fallback_to_positional)\n",
      "  7428993    3.361    0.000   10.194    0.000 base.py:58(_validate_set_axis)\n",
      "  2972120    1.166    0.000    1.365    0.000 base.py:583(_dtype_to_subclass)\n",
      "    65595    0.079    0.000    8.049    0.000 base.py:5839(get_indexer_for)\n",
      "    65595    0.371    0.000   18.535    0.000 base.py:5863(_get_indexer_strict)\n",
      "    65595    0.238    0.000    0.554    0.000 base.py:5896(_raise_if_missing)\n",
      "   327975    0.056    0.000    0.056    0.000 base.py:6001(_index_as_unique)\n",
      "   131190    0.126    0.000    0.411    0.000 base.py:6013(_maybe_promote)\n",
      "   131190    0.192    0.000    2.858    0.000 base.py:6083(_should_compare)\n",
      "   131190    0.077    0.000    0.521    0.000 base.py:6101(_is_comparable_dtype)\n",
      "    18275    0.043    0.000    2.831    0.000 base.py:630(_validate_params)\n",
      " 11394547    0.874    0.000    0.874    0.000 base.py:6354(_maybe_cast_indexer)\n",
      "   131190    0.047    0.000    3.000    0.000 base.py:6361(_maybe_cast_listlike_indexer)\n",
      "  3169604    4.309    0.000    6.397    0.000 base.py:640(_simple_new)\n",
      "      422    0.002    0.000    0.029    0.000 base.py:6614(insert)\n",
      "  2840926    5.474    0.000  112.903    0.000 base.py:665(_with_infer)\n",
      "    21862    0.003    0.000    0.003    0.000 base.py:683(_constructor)\n",
      "  7953522    2.107    0.000    7.676    0.000 base.py:7072(ensure_index)\n",
      "    65595    0.017    0.000    0.022    0.000 base.py:7131(ensure_has_len)\n",
      "  7560611    4.277    0.000   11.564    0.000 base.py:7167(maybe_extract_name)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:7183(get_unanimous_names)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:7196(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:7197(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:7198(<genexpr>)\n",
      "   131190    0.184    0.000    0.304    0.000 base.py:7202(_unpack_nested_dtype)\n",
      "    44125    0.035    0.000    0.113    0.000 base.py:760(_view)\n",
      "   185911    0.262    0.000    0.593    0.000 base.py:767(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:769(_rename)\n",
      "  7429480    0.953    0.000    0.981    0.000 base.py:778(is_)\n",
      "4725000/367500    4.527    0.000   50.566    0.000 base.py:79(_clone_parametrized)\n",
      "  3169606    0.707    0.000    0.707    0.000 base.py:809(_reset_identity)\n",
      "    65914    0.259    0.000    0.503    0.000 base.py:820(_engine)\n",
      " 36667411    6.759    0.000    9.090    0.000 base.py:875(__len__)\n",
      "    32775    0.012    0.000    0.017    0.000 base.py:881(__array__)\n",
      "    10925    0.025    0.000   42.570    0.004 base.py:888(fit_transform)\n",
      "  3125262    0.506    0.000    0.506    0.000 base.py:931(dtype)\n",
      "    44124    0.030    0.000    0.145    0.000 base.py:953(view)\n",
      "      525    0.001    0.000    0.001    0.000 blas.py:384(getter)\n",
      "    68399    0.336    0.000    1.815    0.000 blocks.py:1143(where)\n",
      "  1420250    3.058    0.000   16.904    0.000 blocks.py:1262(fillna)\n",
      "    68399    0.037    0.000    0.095    0.000 blocks.py:1312(<listcomp>)\n",
      "  1376550    8.749    0.000   15.976    0.000 blocks.py:1505(delete)\n",
      "    87409    0.090    0.000    0.427    0.000 blocks.py:164(_consolidate_key)\n",
      "  1420985    0.656    0.000    0.899    0.000 blocks.py:169(_can_hold_na)\n",
      "      525    0.000    0.000    0.000    0.000 blocks.py:180(is_bool)\n",
      "    11635    0.007    0.000    0.024    0.000 blocks.py:188(external_values)\n",
      "  2928100    1.464    0.000    9.312    0.000 blocks.py:192(fill_value)\n",
      "    68399    0.041    0.000    0.153    0.000 blocks.py:198(_standardize_fill_value)\n",
      "  7726106    0.702    0.000    0.702    0.000 blocks.py:205(mgr_locs)\n",
      "  3550632    0.374    0.000    0.468    0.000 blocks.py:2109(get_values)\n",
      "  2941674    1.745    0.000   16.557    0.000 blocks.py:213(make_block)\n",
      "  3190338    1.608    0.000    1.608    0.000 blocks.py:230(make_block_same_class)\n",
      "  7585220    6.344    0.000   10.974    0.000 blocks.py:2305(maybe_coerce_values)\n",
      "  7552452    5.234    0.000    7.102    0.000 blocks.py:2334(get_block_type)\n",
      "  4283032    4.004    0.000   14.380    0.000 blocks.py:2372(new_block_2d)\n",
      "  3269413    4.805    0.000   16.572    0.000 blocks.py:2385(new_block)\n",
      "  3269413    2.318    0.000    3.933    0.000 blocks.py:2401(check_ndim)\n",
      "  8776282    5.178    0.000    6.913    0.000 blocks.py:2465(extend_blocks)\n",
      "  4261172    3.396    0.000    6.060    0.000 blocks.py:2481(ensure_block_shape)\n",
      "  1376550    0.320    0.000    0.397    0.000 blocks.py:258(__len__)\n",
      "    11635    0.013    0.000    0.017    0.000 blocks.py:2584(external_values)\n",
      "  2840500    2.190    0.000   71.739    0.000 blocks.py:323(apply)\n",
      "  2840500    1.390    0.000   17.387    0.000 blocks.py:350(_split_op_result)\n",
      "  1420250    1.027    0.000    1.149    0.000 blocks.py:426(_maybe_downcast)\n",
      "  7331886    0.695    0.000    0.695    0.000 blocks.py:479(dtype)\n",
      "    32775    0.081    0.000    0.740    0.000 blocks.py:483(astype)\n",
      "  5700653    4.837    0.000    5.566    0.000 blocks.py:534(copy)\n",
      "    65562    0.011    0.000    0.011    0.000 blocks.py:888(shape)\n",
      "  7114526    1.955    0.000    1.955    0.000 blocks.py:892(iget)\n",
      "  3190334    5.409    0.000   37.032    0.000 blocks.py:926(take_nd)\n",
      "     3675    0.007    0.000    0.011    0.000 callback.py:129(__init__)\n",
      "     3675    0.004    0.000    0.005    0.000 callback.py:156(before_training)\n",
      "     3675    0.007    0.000    0.017    0.000 callback.py:167(after_training)\n",
      "   367500    0.140    0.000    0.458    0.000 callback.py:179(before_iteration)\n",
      "   735000    0.166    0.000    0.193    0.000 callback.py:187(<genexpr>)\n",
      "   367500    0.048    0.000    0.048    0.000 callback.py:191(_update_history)\n",
      "   367500    0.629    0.000    4.147    0.000 callback.py:221(after_iteration)\n",
      "   735000    0.186    0.000    0.230    0.000 callback.py:241(<genexpr>)\n",
      "     3675    0.006    0.000    0.006    0.000 callback.py:491(__init__)\n",
      "   367500    0.044    0.000    0.044    0.000 callback.py:509(after_iteration)\n",
      "     3675    0.000    0.000    0.000    0.000 callback.py:53(__init__)\n",
      "     3675    0.007    0.000    0.010    0.000 callback.py:536(after_training)\n",
      "     3675    0.000    0.000    0.000    0.000 callback.py:56(before_training)\n",
      "   367500    0.027    0.000    0.027    0.000 callback.py:64(before_iteration)\n",
      "  2972128    4.053    0.000   17.410    0.000 cast.py:1171(maybe_infer_to_datetimelike)\n",
      "       12    0.001    0.000    0.002    0.000 cast.py:123(maybe_convert_platform)\n",
      "    54638    0.098    0.000    0.104    0.000 cast.py:1388(np_find_common_type)\n",
      "    54638    0.264    0.000    1.000    0.000 cast.py:1429(find_common_type)\n",
      "   163891    0.032    0.000    0.040    0.000 cast.py:1459(<genexpr>)\n",
      "   109258    0.032    0.000    0.059    0.000 cast.py:1468(<genexpr>)\n",
      "   109258    0.023    0.000    0.047    0.000 cast.py:1470(<genexpr>)\n",
      "   163891    0.036    0.000    0.254    0.000 cast.py:1475(<genexpr>)\n",
      "       12    0.000    0.000    0.000    0.000 cast.py:1573(construct_1d_object_array_from_listlike)\n",
      "    68821    0.132    0.000    0.200    0.000 cast.py:1750(np_can_hold_element)\n",
      "  6075242    8.347    0.000    9.531    0.000 cast.py:566(maybe_promote)\n",
      "    68399    0.027    0.000    0.062    0.000 cast.py:947(_maybe_infer_dtype_type)\n",
      "     3675    0.003    0.000    0.003    0.000 collective.py:72(get_rank)\n",
      "    32760    0.038    0.000    0.043    0.000 common.py:1029(is_numeric_v_string_like)\n",
      " 10150826    2.740    0.000    3.714    0.000 common.py:1077(needs_i8_conversion)\n",
      "   131193    0.164    0.000    0.444    0.000 common.py:1127(is_numeric_dtype)\n",
      "   131190    0.027    0.000    0.035    0.000 common.py:1168(<lambda>)\n",
      "  5780783    3.696    0.000   10.895    0.000 common.py:1209(is_float_dtype)\n",
      "   317954    0.066    0.000    0.085    0.000 common.py:1240(<lambda>)\n",
      "  2660901    1.813    0.000    5.888    0.000 common.py:1244(is_bool_dtype)\n",
      " 11792220    2.220    0.000    3.039    0.000 common.py:1322(is_1d_only_ea_dtype)\n",
      "  9609401    4.686    0.000    7.051    0.000 common.py:1335(is_extension_array_dtype)\n",
      "  5944240    2.229    0.000    3.238    0.000 common.py:1389(is_ea_or_datetimelike_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:1402(is_complex_dtype)\n",
      "  9716611    1.343    0.000    1.343    0.000 common.py:142(classes)\n",
      "   549562    0.310    0.000    0.615    0.000 common.py:1435(_is_dtype)\n",
      "  9716611    1.841    0.000    2.582    0.000 common.py:144(<lambda>)\n",
      " 10293215    1.990    0.000    3.015    0.000 common.py:1459(get_dtype)\n",
      "   514259    0.074    0.000    0.074    0.000 common.py:147(classes_and_not_datetimelike)\n",
      " 10230870    4.406    0.000   10.020    0.000 common.py:1494(_is_dtype_type)\n",
      " 14226096    3.445    0.000    4.446    0.000 common.py:150(cast_scalar_indexer)\n",
      "   514259    0.202    0.000    0.265    0.000 common.py:152(<lambda>)\n",
      "  3935827    2.556    0.000    6.542    0.000 common.py:158(is_object_dtype)\n",
      "  7592839    2.999    0.000   11.836    0.000 common.py:1631(validate_all_hashable)\n",
      " 15185678    4.082    0.000    6.198    0.000 common.py:1650(<genexpr>)\n",
      "   644730    0.993    0.000    2.573    0.000 common.py:1656(pandas_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:172(not_none)\n",
      "      108    0.000    0.000    0.000    0.000 common.py:176(<genexpr>)\n",
      "      120    0.000    0.000    0.000    0.000 common.py:189(is_sparse)\n",
      "  3037710    8.928    0.000   26.209    0.000 common.py:229(asarray_tuplesafe)\n",
      "    54629    0.021    0.000    0.026    0.000 common.py:275(is_datetime64_dtype)\n",
      "        8    0.000    0.000    0.000    0.000 common.py:296(maybe_iterable_to_list)\n",
      "      844    0.000    0.000    0.000    0.000 common.py:306(is_null_slice)\n",
      "    65549    0.019    0.000    0.029    0.000 common.py:351(is_timedelta64_dtype)\n",
      " 14355693    3.132    0.000    4.023    0.000 common.py:367(apply_if_callable)\n",
      "   131612    0.096    0.000    0.580    0.000 common.py:422(is_interval_dtype)\n",
      "  3235963    1.862    0.000   10.684    0.000 common.py:460(is_categorical_dtype)\n",
      "  4197195    1.433    0.000    1.433    0.000 common.py:498(is_string_or_object_np_dtype)\n",
      "     1890    0.001    0.000    0.006    0.000 common.py:505(is_string_dtype)\n",
      "     1890    0.002    0.000    0.002    0.000 common.py:540(condition)\n",
      "  3541376    2.225    0.000    4.403    0.000 common.py:551(is_dtype_equal)\n",
      "   328202    0.111    0.000    0.315    0.000 common.py:571(require_length_match)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:629(is_builtin_func)\n",
      "   383066    0.282    0.000    0.865    0.000 common.py:653(is_integer_dtype)\n",
      "    32760    0.064    0.000    5.702    0.000 common.py:67(new_method)\n",
      "    98528    0.021    0.000    0.027    0.000 common.py:705(<lambda>)\n",
      "    32760    0.028    0.000    0.084    0.000 common.py:86(get_op_result_name)\n",
      "   109506    0.202    0.000    0.559    0.000 common.py:95(is_bool_indexer)\n",
      "    10500    0.006    0.000    0.010    0.000 compat.py:16(py_str)\n",
      "   133350    0.042    0.000    0.042    0.000 compat.py:21(lazy_isinstance)\n",
      "        1    0.000    0.000    0.042    0.042 concat.py:149(concat)\n",
      "        1    0.004    0.004    0.037    0.037 concat.py:176(concatenate_managers)\n",
      "        1    0.000    0.000    0.003    0.003 concat.py:208(<listcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 concat.py:226(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 concat.py:293(_maybe_reindex_columns_na_proxy)\n",
      "      105    0.002    0.000    0.003    0.000 concat.py:322(_get_mgr_concatenation_plan)\n",
      "        9    0.005    0.001    0.006    0.001 concat.py:33(concat_compat)\n",
      "        1    0.000    0.000    0.003    0.003 concat.py:393(__init__)\n",
      "     1260    0.000    0.000    0.000    0.000 concat.py:399(__init__)\n",
      "      840    0.001    0.000    0.002    0.000 concat.py:411(needs_filling)\n",
      "      840    0.000    0.000    0.002    0.000 concat.py:420(dtype)\n",
      "      525    0.000    0.000    0.000    0.000 concat.py:430(_is_valid_na_for)\n",
      "     1260    0.001    0.000    0.002    0.000 concat.py:460(is_na)\n",
      "        1    0.000    0.000    0.000    0.000 concat.py:480(<listcomp>)\n",
      "      129    0.000    0.000    0.000    0.000 concat.py:487(<genexpr>)\n",
      "      840    0.001    0.000    0.014    0.000 concat.py:489(get_reindexed_values)\n",
      "      945    0.000    0.000    0.000    0.000 concat.py:55(is_nonempty)\n",
      "        1    0.000    0.000    0.039    0.039 concat.py:565(get_result)\n",
      "        8    0.000    0.000    0.023    0.003 concat.py:572(_concatenate_join_units)\n",
      "      848    0.000    0.000    0.000    0.000 concat.py:578(<genexpr>)\n",
      "        8    0.000    0.000    0.014    0.002 concat.py:581(<listcomp>)\n",
      "      848    0.000    0.000    0.000    0.000 concat.py:598(<genexpr>)\n",
      "        8    0.000    0.000    0.000    0.000 concat.py:618(_dtype_to_na_value)\n",
      "        1    0.000    0.000    0.000    0.000 concat.py:625(_get_result_dim)\n",
      "        1    0.000    0.000    0.003    0.003 concat.py:631(_get_new_axes)\n",
      "        1    0.000    0.000    0.003    0.003 concat.py:633(<listcomp>)\n",
      "        1    0.000    0.000    0.002    0.002 concat.py:638(_get_comb_axis)\n",
      "        8    0.000    0.000    0.002    0.000 concat.py:641(_get_empty_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 concat.py:648(_get_concat_axis)\n",
      "      848    0.000    0.000    0.000    0.000 concat.py:659(<genexpr>)\n",
      "        9    0.000    0.000    0.000    0.000 concat.py:66(<listcomp>)\n",
      "        8    0.000    0.000    0.002    0.000 concat.py:661(<listcomp>)\n",
      "       12    0.000    0.000    0.005    0.000 concat.py:671(_is_uniform_join_units)\n",
      "        1    0.000    0.000    0.000    0.000 concat.py:682(<listcomp>)\n",
      "     1272    0.000    0.000    0.000    0.000 concat.py:683(<genexpr>)\n",
      "     1272    0.001    0.000    0.002    0.000 concat.py:686(<genexpr>)\n",
      "     1272    0.001    0.000    0.002    0.000 concat.py:696(<genexpr>)\n",
      "      440    0.000    0.000    0.000    0.000 concat.py:699(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 concat.py:701(_maybe_check_integrity)\n",
      "        8    0.000    0.000    0.000    0.000 concat.py:706(_is_uniform_reindex)\n",
      "        1    0.000    0.000    0.000    0.000 concat.py:708(_concat_indexes)\n",
      "       16    0.000    0.000    0.000    0.000 concat.py:709(<genexpr>)\n",
      "        9    0.000    0.000    0.000    0.000 concat.py:71(<setcomp>)\n",
      "        9    0.000    0.000    0.000    0.000 concat.py:72(<setcomp>)\n",
      "       18    0.000    0.000    0.000    0.000 concat.py:73(<genexpr>)\n",
      "       13    0.001    0.000    0.001    0.000 concat.py:741(_combine_concat_plans)\n",
      "     1365    0.000    0.000    0.000    0.000 concat.py:757(_next_or_none)\n",
      "      954    0.000    0.000    0.001    0.000 concat.py:76(<genexpr>)\n",
      "        9    0.000    0.000    0.000    0.000 concat.py:79(<setcomp>)\n",
      "      954    0.000    0.000    0.000    0.000 concat.py:80(<genexpr>)\n",
      "    42000    0.025    0.000    0.504    0.000 config.py:106(wrap)\n",
      "    21000    0.107    0.000    0.243    0.000 config.py:115(set_config)\n",
      "   327748    0.402    0.000    0.927    0.000 config.py:116(_get_single_key)\n",
      "   327742    0.244    0.000    1.443    0.000 config.py:134(_get_option)\n",
      "    10500    0.133    0.000    0.236    0.000 config.py:135(get_config)\n",
      "        6    0.000    0.000    0.000    0.000 config.py:142(_set_option)\n",
      "    21000    0.022    0.000    0.524    0.000 config.py:155(config_context)\n",
      "   327739    0.137    0.000    1.581    0.000 config.py:260(__call__)\n",
      "        3    0.000    0.000    0.000    0.000 config.py:432(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 config.py:440(__enter__)\n",
      "        3    0.000    0.000    0.000    0.000 config.py:441(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 config.py:446(__exit__)\n",
      "   327748    0.081    0.000    0.081    0.000 config.py:578(_select_options)\n",
      "   327748    0.216    0.000    0.273    0.000 config.py:596(_get_root)\n",
      "   655487    0.213    0.000    0.213    0.000 config.py:610(_get_deprecated_option)\n",
      "        6    0.000    0.000    0.000    0.000 config.py:626(_get_registered_option)\n",
      "   327748    0.081    0.000    0.160    0.000 config.py:637(_translate_key)\n",
      "   327739    0.106    0.000    0.240    0.000 config.py:649(_warn_if_deprecated)\n",
      "        6    0.000    0.000    0.000    0.000 config.py:847(inner)\n",
      "        1    0.000    0.000    0.001    0.001 construction.py:1001(convert_object_array)\n",
      "       39    0.000    0.000    0.001    0.000 construction.py:1023(convert)\n",
      "        1    0.000    0.000    0.001    0.001 construction.py:1067(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 construction.py:197(mgr_to_mgr)\n",
      "  6217490    2.521    0.000   13.453    0.000 construction.py:396(extract_array)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:411(dict_to_mgr)\n",
      " 10939693    3.930    0.000    4.404    0.000 construction.py:458(ensure_wrapped_if_datetimelike)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:469(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:470(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:476(<listcomp>)\n",
      "        1    0.000    0.000    0.001    0.001 construction.py:484(nested_data_to_arrays)\n",
      "  3300322   11.424    0.000   44.763    0.000 construction.py:494(sanitize_array)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:510(treat_as_nested)\n",
      "        2    0.000    0.000    0.001    0.000 construction.py:574(_homogenize)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:616(_extract_index)\n",
      "       12    0.000    0.000    0.000    0.000 construction.py:636(_sanitize_non_ordered)\n",
      "  3300322    1.858    0.000    2.543    0.000 construction.py:644(_sanitize_ndim)\n",
      "  3300322    1.006    0.000    1.206    0.000 construction.py:683(_sanitize_str_dtypes)\n",
      "  3300322    0.396    0.000    0.416    0.000 construction.py:703(_maybe_repeat)\n",
      "   294960    0.299    0.000    1.030    0.000 construction.py:714(_try_cast)\n",
      "        1    0.000    0.000    0.001    0.001 construction.py:775(to_arrays)\n",
      "        1    0.000    0.000    0.001    0.001 construction.py:886(_list_of_dict_to_arrays)\n",
      "      316    0.000    0.000    0.000    0.000 construction.py:910(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 construction.py:911(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:917(<listcomp>)\n",
      "        1    0.000    0.000    0.001    0.001 construction.py:923(_finalize_columns_and_data)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:945(_validate_or_indexify_columns)\n",
      "        2    0.000    0.000    0.001    0.000 construction.py:97(arrays_to_mgr)\n",
      "    10500    0.007    0.000    0.007    0.000 context.py:237(get_context)\n",
      "  1141535    0.771    0.000    0.864    0.000 contextlib.py:104(__init__)\n",
      "  1141535    0.363    0.000    4.321    0.000 contextlib.py:132(__enter__)\n",
      "  1141535    0.486    0.000    4.451    0.000 contextlib.py:141(__exit__)\n",
      "  1141535    0.422    0.000    1.286    0.000 contextlib.py:287(helper)\n",
      "    33197    0.005    0.000    0.005    0.000 contextlib.py:428(__init__)\n",
      "    33197    0.002    0.000    0.002    0.000 contextlib.py:431(__enter__)\n",
      "    33197    0.004    0.000    0.004    0.000 contextlib.py:434(__exit__)\n",
      "   738675    0.049    0.000    0.049    0.000 contextlib.py:65(_recreate_cm)\n",
      "    10500    0.002    0.000    0.002    0.000 contextlib.py:751(__init__)\n",
      "   738675    0.780    0.000   34.978    0.000 contextlib.py:78(inner)\n",
      "  4357500    2.778    0.000    3.778    0.000 copy.py:128(deepcopy)\n",
      "  4357500    0.281    0.000    0.281    0.000 copy.py:182(_deepcopy_atomic)\n",
      "     7350    0.009    0.000    0.039    0.000 copy.py:259(_reconstruct)\n",
      "    11025    0.029    0.000    5.932    0.001 copy.py:66(copy)\n",
      "     7350    0.003    0.000    0.004    0.000 copyreg.py:104(__newobj__)\n",
      "    14700    0.017    0.000    0.609    0.000 core.py:1059(set_label)\n",
      "     7350    0.008    0.000    0.056    0.000 core.py:115(make_jcargs)\n",
      "   367500    0.367    0.000    0.488    0.000 core.py:120(_parse_eval_str)\n",
      "   371175    0.335    0.000    0.400    0.000 core.py:1213(num_row)\n",
      "   367500    0.036    0.000    0.036    0.000 core.py:124(<listcomp>)\n",
      "   367500    0.039    0.000    0.039    0.000 core.py:126(<listcomp>)\n",
      "   371175    0.680    0.000    1.084    0.000 core.py:1268(feature_names)\n",
      "   371175    0.547    0.000    0.871    0.000 core.py:1338(feature_types)\n",
      "     3675    0.050    0.000    0.051    0.000 core.py:1398(__init__)\n",
      "    14700    0.142    0.000    0.274    0.000 core.py:1417(_set_data_from_array)\n",
      "     3675    0.011    0.000    4.423    0.001 core.py:1470(__init__)\n",
      "     3675    1.566    0.000    4.406    0.001 core.py:1544(_init)\n",
      "     7350    0.006    0.000    0.006    0.000 core.py:1611(_configure_metrics)\n",
      "     7350    2.942    0.000    5.873    0.001 core.py:1634(__init__)\n",
      "     7350    0.002    0.000    0.002    0.000 core.py:1656(<listcomp>)\n",
      "     7350    0.026    0.000    0.028    0.000 core.py:1733(_configure_constraints)\n",
      "     7350    0.421    0.000    0.423    0.000 core.py:1750(__del__)\n",
      "     3675    2.436    0.001    2.557    0.001 core.py:1755(__getstate__)\n",
      "     3675    0.002    0.000    5.826    0.002 core.py:1865(__copy__)\n",
      "     3675    0.315    0.000    5.824    0.002 core.py:1868(__deepcopy__)\n",
      "     3675    0.004    0.000    5.840    0.002 core.py:1872(copy)\n",
      "     3675    0.011    0.000    0.014    0.000 core.py:1882(attr)\n",
      "  1113525    1.791    0.000    2.819    0.000 core.py:1940(_get_feature_info)\n",
      "   742350    0.638    0.000    0.969    0.000 core.py:1956(_set_feature_info)\n",
      "   371175    0.109    0.000    1.027    0.000 core.py:1978(feature_types)\n",
      "   371175    0.098    0.000    0.558    0.000 core.py:1986(feature_types)\n",
      "   742350    0.226    0.000    2.127    0.000 core.py:1990(feature_names)\n",
      "   371175    0.108    0.000    0.616    0.000 core.py:1998(feature_names)\n",
      "     7350    0.069    0.000    0.127    0.000 core.py:2002(set_param)\n",
      "   367500   83.463    0.000   91.038    0.000 core.py:2028(update)\n",
      "   367500    1.618    0.000    2.597    0.000 core.py:2090(eval_set)\n",
      "   367500    0.043    0.000    0.043    0.000 core.py:2121(<listcomp>)\n",
      "   367500    0.036    0.000    0.036    0.000 core.py:2122(<listcomp>)\n",
      "     3675    0.340    0.000    0.902    0.000 core.py:2309(inplace_predict)\n",
      "     3675    0.005    0.000    0.019    0.000 core.py:2596(best_iteration)\n",
      "     3675    0.296    0.000    0.297    0.000 core.py:2636(num_features)\n",
      "  3827775    0.341    0.000    0.341    0.000 core.py:269(_check_call)\n",
      "   371175    0.822    0.000    7.600    0.000 core.py:2922(_assign_dmatrix_features)\n",
      "   371175    0.095    0.000    1.102    0.000 core.py:2936(_validate_features)\n",
      "     7350    0.017    0.000    0.017    0.000 core.py:339(_numpy2ctypes_type)\n",
      "     7350    0.046    0.000    0.080    0.000 core.py:368(ctypes2numpy)\n",
      "     3675    0.112    0.000    0.118    0.000 core.py:407(ctypes2buffer)\n",
      "  2667000    0.803    0.000    1.025    0.000 core.py:418(c_str)\n",
      "   742350    0.693    0.000    0.845    0.000 core.py:423(c_array)\n",
      "     3675    0.017    0.000    0.162    0.000 core.py:480(_prediction_output)\n",
      "     3675    0.007    0.000    0.058    0.000 core.py:516(__init__)\n",
      "     3675    0.018    0.000    0.028    0.000 core.py:530(get_callbacks)\n",
      "    33075    0.004    0.000    0.004    0.000 core.py:546(proxy)\n",
      "    47775    0.019    0.000    1.364    0.000 core.py:551(_handle_exception)\n",
      "     3675    0.001    0.000    0.001    0.000 core.py:567(reraise)\n",
      "     3675    0.002    0.000    0.002    0.000 core.py:577(__del__)\n",
      "    18375    0.010    0.000    0.019    0.000 core.py:581(_reset_wrapper)\n",
      "    29400    0.067    0.000    2.684    0.000 core.py:588(_next_wrapper)\n",
      "    14700    0.074    0.000    1.274    0.000 core.py:597(input_data)\n",
      "    29400    0.011    0.000    1.343    0.000 core.py:640(<lambda>)\n",
      "     1260    0.001    0.000    0.001    0.000 core.py:6480(isMaskedArray)\n",
      "    29400    0.031    0.000    0.125    0.000 core.py:675(require_keyword_args)\n",
      "    29400    0.132    0.000    1.044    0.000 core.py:691(throw_if)\n",
      "44100/7350    0.141    0.000  108.916    0.015 core.py:710(inner_f)\n",
      "     7350    0.005    0.000    0.006    0.000 core.py:76(from_pystr_to_cstr)\n",
      "     7350    0.319    0.000    0.321    0.000 core.py:907(__del__)\n",
      "    14700    0.025    0.000    0.641    0.000 core.py:912(set_info)\n",
      "  1855875    0.389    0.000    0.389    0.000 core.py:96(from_cstr_to_pystr)\n",
      "    22050    0.006    0.000    0.007    0.000 data.py:1014(_is_tuple)\n",
      "     3675    0.001    0.000    0.003    0.000 data.py:1028(_is_iter)\n",
      "    14700    0.023    0.000    0.026    0.000 data.py:1134(_validate_meta_shape)\n",
      "    14700    0.380    0.000    0.498    0.000 data.py:1148(_meta_from_numpy)\n",
      "    14700    0.027    0.000    0.586    0.000 data.py:1202(dispatch_meta_backend)\n",
      "     3675    0.005    0.000    0.063    0.000 data.py:1268(__init__)\n",
      "    29400    0.024    0.000    1.332    0.000 data.py:1276(next)\n",
      "    18375    0.003    0.000    0.003    0.000 data.py:1283(reset)\n",
      "     3675    0.013    0.000    0.058    0.000 data.py:1287(_proxy_transform)\n",
      "    14700    0.050    0.000    0.452    0.000 data.py:1323(dispatch_proxy_set_data)\n",
      "    36750    0.008    0.000    0.078    0.000 data.py:167(_is_np_array_like)\n",
      "    22050    0.034    0.000    0.034    0.000 data.py:171(_ensure_np_dtype)\n",
      "     3795    0.002    0.000    0.002    0.000 data.py:221(_is_pandas_df)\n",
      "      120    0.001    0.000    0.005    0.000 data.py:384(is_pd_sparse_dtype)\n",
      "    18495    0.014    0.000    0.016    0.000 data.py:528(_is_pandas_series)\n",
      "      120    0.000    0.000    0.011    0.000 data.py:536(_meta_from_pandas_series)\n",
      "    29400    0.013    0.000    0.019    0.000 data.py:55(_check_data_shape)\n",
      "    33075    0.057    0.000    0.243    0.000 data.py:68(_array_interface)\n",
      "    21525    0.007    0.000    0.016    0.000 data.py:761(_is_cudf_df)\n",
      "    36225    0.010    0.000    0.023    0.000 data.py:895(_is_cudf_ser)\n",
      "    25200    0.014    0.000    0.075    0.000 data.py:899(_is_cupy_array)\n",
      "   100800    0.023    0.000    0.044    0.000 data.py:900(<genexpr>)\n",
      "    22050    0.016    0.000    0.016    0.000 data.py:952(_is_dlpack)\n",
      "    22050    0.006    0.000    0.007    0.000 data.py:998(_is_list)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:1256(is_dataclass)\n",
      "    10500    0.021    0.000    0.068    0.000 decoder.py:332(decode)\n",
      "    10500    0.024    0.000    0.024    0.000 decoder.py:343(raw_decode)\n",
      "    10500    0.033    0.000    0.033    0.000 disk.py:42(memstr_to_bytes)\n",
      "    32760    0.013    0.000    0.054    0.000 dispatch.py:13(should_extension_dispatch)\n",
      "   131612    0.136    0.000    0.475    0.000 dtypes.py:1241(is_dtype)\n",
      "    15750    0.003    0.000    0.003    0.000 einsumfunc.py:1001(_einsum_dispatcher)\n",
      "     3150    0.002    0.000    0.022    0.000 einsumfunc.py:1009(einsum)\n",
      "    61425    0.076    0.000    0.313    0.000 encoder.py:183(encode)\n",
      "    61425    0.222    0.000    0.222    0.000 encoder.py:205(iterencode)\n",
      " 24086480    2.174    0.000    2.174    0.000 enum.py:1091(__new__)\n",
      " 24086480    5.290    0.000    7.465    0.000 enum.py:685(__call__)\n",
      "    68399    0.177    0.000    0.185    0.000 expressions.py:169(_where_standard)\n",
      "    68399    0.026    0.000    0.211    0.000 expressions.py:243(where)\n",
      "     5670    0.010    0.000    0.129    0.000 extmath.py:1158(_nanaverage)\n",
      "     3675    0.101    0.000    0.102    0.000 extmath.py:159(safe_sparse_dot)\n",
      "    32775    0.053    0.000    0.275    0.000 extmath.py:940(_safe_accumulator_op)\n",
      "    10925    0.433    0.000    0.885    0.000 extmath.py:970(_incremental_mean_and_var)\n",
      " 14706494    3.892    0.000    3.892    0.000 flags.py:49(__init__)\n",
      "  7343142    0.814    0.000    0.814    0.000 flags.py:53(allows_duplicate_labels)\n",
      "  7343038    1.973    0.000    1.973    0.000 flags.py:85(allows_duplicate_labels)\n",
      "    54627    0.032    0.000    6.061    0.000 frame.py:11286(values)\n",
      "  4260752    3.403    0.000   11.989    0.000 frame.py:11602(_reindex_for_setitem)\n",
      "  4261594    1.176    0.000    3.035    0.000 frame.py:1489(__len__)\n",
      "  7113049    8.737    0.000   99.092    0.000 frame.py:3639(_ixs)\n",
      " 10052123   21.270    0.000  240.330    0.000 frame.py:3713(__getitem__)\n",
      "    21840    0.088    0.000    6.646    0.000 frame.py:3786(_getitem_bool_array)\n",
      "4283022/2862772    9.539    0.000  293.524    0.000 frame.py:3921(__setitem__)\n",
      "    21850    0.920    0.000   99.108    0.005 frame.py:3959(_setitem_array)\n",
      "  4260750    4.617    0.000   98.420    0.000 frame.py:4101(_iset_item_mgr)\n",
      "  4261172    5.835    0.000  115.703    0.000 frame.py:4108(_set_item_mgr)\n",
      "  4261172    7.014    0.000  247.822    0.000 frame.py:4133(_set_item)\n",
      "  4261172    1.213    0.000    3.171    0.000 frame.py:4203(_ensure_valid_index)\n",
      "  7113047    7.618    0.000   49.919    0.000 frame.py:4226(_box_col_values)\n",
      "  4282813    1.380    0.000    4.194    0.000 frame.py:4240(_clear_item_cache)\n",
      "  9964688   11.836    0.000  120.793    0.000 frame.py:4243(_get_item_cache)\n",
      "  4261172    7.089    0.000  118.166    0.000 frame.py:4847(_sanitize_column)\n",
      "        1    0.000    0.000    0.000    0.000 frame.py:5036(reindex)\n",
      "    21850    0.035    0.000   19.847    0.001 frame.py:5482(fillna)\n",
      "   131677    0.019    0.000    0.019    0.000 frame.py:632(_constructor)\n",
      "   131679    0.171    0.000    0.509    0.000 frame.py:641(__init__)\n",
      "      105    0.001    0.000    0.016    0.000 frame.py:6709(sort_values)\n",
      "  2840503    5.837    0.000  144.640    0.000 frame.py:8130(groupby)\n",
      "  2841977    0.702    0.000    0.702    0.000 frame.py:893(axes)\n",
      "   131207    0.056    0.000    0.154    0.000 frame.py:910(shape)\n",
      "        2    0.000    0.000    0.318    0.159 frame.py:9266(apply)\n",
      "    54625    0.077    0.000    5.955    0.000 frame.py:985(_values)\n",
      "  2862352    0.284    0.000    0.284    0.000 fromnumeric.py:1021(_argsort_dispatcher)\n",
      "  2862352    1.528    0.000    5.409    0.000 fromnumeric.py:1025(argsort)\n",
      "     3150    0.000    0.000    0.000    0.000 fromnumeric.py:1136(_argmax_dispatcher)\n",
      "     3150    0.004    0.000    0.012    0.000 fromnumeric.py:1140(argmax)\n",
      "     8820    0.001    0.000    0.001    0.000 fromnumeric.py:1328(_searchsorted_dispatcher)\n",
      "     8820    0.005    0.000    0.032    0.000 fromnumeric.py:1332(searchsorted)\n",
      "     1369    0.000    0.000    0.000    0.000 fromnumeric.py:1764(_ravel_dispatcher)\n",
      "     1369    0.001    0.000    0.002    0.000 fromnumeric.py:1768(ravel)\n",
      "      105    0.000    0.000    0.000    0.000 fromnumeric.py:1877(_nonzero_dispatcher)\n",
      "      105    0.000    0.000    0.000    0.000 fromnumeric.py:1881(nonzero)\n",
      "    24465    0.003    0.000    0.003    0.000 fromnumeric.py:195(_reshape_dispatcher)\n",
      "    24465    0.014    0.000    0.044    0.000 fromnumeric.py:200(reshape)\n",
      "     3150    0.000    0.000    0.000    0.000 fromnumeric.py:2096(_clip_dispatcher)\n",
      "     3150    0.003    0.000    0.016    0.000 fromnumeric.py:2100(clip)\n",
      "   839800    0.083    0.000    0.083    0.000 fromnumeric.py:2172(_sum_dispatcher)\n",
      "   839800    0.604    0.000    2.995    0.000 fromnumeric.py:2177(sum)\n",
      "   354915    0.045    0.000    0.045    0.000 fromnumeric.py:2317(_any_dispatcher)\n",
      "   354915    0.211    0.000    1.253    0.000 fromnumeric.py:2322(any)\n",
      "   205792    0.018    0.000    0.018    0.000 fromnumeric.py:2416(_all_dispatcher)\n",
      "   205792    0.090    0.000    0.494    0.000 fromnumeric.py:2421(all)\n",
      "   321825    0.033    0.000    0.033    0.000 fromnumeric.py:2508(_cumsum_dispatcher)\n",
      "   321825    0.181    0.000    1.209    0.000 fromnumeric.py:2512(cumsum)\n",
      "    10925    0.001    0.000    0.001    0.000 fromnumeric.py:2589(_ptp_dispatcher)\n",
      "    10925    0.017    0.000    0.078    0.000 fromnumeric.py:2593(ptp)\n",
      "  1755390    0.191    0.000    0.191    0.000 fromnumeric.py:2687(_max_dispatcher)\n",
      "  1755390    1.320    0.000    7.345    0.000 fromnumeric.py:2692(max)\n",
      "    11340    0.001    0.000    0.001    0.000 fromnumeric.py:2831(_min_dispatcher)\n",
      "    11340    0.007    0.000    0.034    0.000 fromnumeric.py:2836(min)\n",
      "   371175    0.037    0.000    0.037    0.000 fromnumeric.py:2974(_prod_dispatcher)\n",
      "   371175    0.243    0.000    1.904    0.000 fromnumeric.py:2979(prod)\n",
      "     6300    0.001    0.000    0.001    0.000 fromnumeric.py:3172(_ndim_dispatcher)\n",
      "     6300    0.006    0.000    0.008    0.000 fromnumeric.py:3176(ndim)\n",
      "      420    0.000    0.000    0.000    0.000 fromnumeric.py:3380(_mean_dispatcher)\n",
      "      420    0.002    0.000    0.007    0.000 fromnumeric.py:3385(mean)\n",
      "      105    0.000    0.000    0.000    0.000 fromnumeric.py:3508(_std_dispatcher)\n",
      "      105    0.000    0.000    0.003    0.000 fromnumeric.py:3513(std)\n",
      "     3150    0.007    0.000    0.018    0.000 fromnumeric.py:40(_wrapit)\n",
      "     3150    0.000    0.000    0.000    0.000 fromnumeric.py:419(_repeat_dispatcher)\n",
      "     3150    0.003    0.000    0.026    0.000 fromnumeric.py:423(repeat)\n",
      "  3230167    1.690    0.000    5.019    0.000 fromnumeric.py:53(_wrapfunc)\n",
      "      210    0.000    0.000    0.000    0.000 fromnumeric.py:658(_partition_dispatcher)\n",
      "      210    0.002    0.000    0.003    0.000 fromnumeric.py:662(partition)\n",
      "  3538412    3.716    0.000   11.491    0.000 fromnumeric.py:71(_wrapreduction)\n",
      "  3538412    1.524    0.000    1.524    0.000 fromnumeric.py:72(<dictcomp>)\n",
      "     3150    0.000    0.000    0.000    0.000 fromnumeric.py:91(_take_dispatcher)\n",
      "     3150    0.002    0.000    0.009    0.000 fromnumeric.py:95(take)\n",
      "        1    0.000    0.000    0.000    0.000 frozen.py:73(__getitem__)\n",
      "    43698    0.009    0.000    0.009    0.000 function.py:60(__call__)\n",
      "      210    0.000    0.000    0.000    0.000 function_base.py:110(<lambda>)\n",
      "      210    0.000    0.000    0.000    0.000 function_base.py:111(<lambda>)\n",
      "      210    0.000    0.000    0.000    0.000 function_base.py:1320(_diff_dispatcher)\n",
      "      210    0.001    0.000    0.001    0.000 function_base.py:1324(diff)\n",
      "      420    0.001    0.000    0.041    0.000 function_base.py:3763(_ureduce)\n",
      "      210    0.000    0.000    0.000    0.000 function_base.py:3840(_median_dispatcher)\n",
      "      210    0.000    0.000    0.010    0.000 function_base.py:3845(median)\n",
      "     1860    0.000    0.000    0.000    0.000 function_base.py:393(_average_dispatcher)\n",
      "      210    0.001    0.000    0.010    0.000 function_base.py:3931(_median)\n",
      "     1860    0.003    0.000    0.029    0.000 function_base.py:398(average)\n",
      "      210    0.000    0.000    0.000    0.000 function_base.py:3987(_percentile_dispatcher)\n",
      "      210    0.001    0.000    0.036    0.000 function_base.py:3992(percentile)\n",
      "      210    0.000    0.000    0.031    0.000 function_base.py:4547(_quantile_unchecked)\n",
      "      210    0.001    0.000    0.004    0.000 function_base.py:4565(_quantile_is_valid)\n",
      "      210    0.000    0.000    0.000    0.000 function_base.py:4619(_get_gamma)\n",
      "      210    0.002    0.000    0.002    0.000 function_base.py:4641(_lerp)\n",
      "      210    0.000    0.000    0.030    0.000 function_base.py:4696(_quantile_ureduce_func)\n",
      "      210    0.003    0.000    0.005    0.000 function_base.py:4729(_get_indexes)\n",
      "      210    0.002    0.000    0.030    0.000 function_base.py:4764(_quantile)\n",
      "      842    0.000    0.000    0.000    0.000 function_base.py:5364(_insert_dispatcher)\n",
      "      842    0.006    0.000    0.014    0.000 function_base.py:5368(insert)\n",
      "      844    0.000    0.000    0.000    0.000 function_base.py:5558(_append_dispatcher)\n",
      "      844    0.002    0.000    0.003    0.000 function_base.py:5562(append)\n",
      "     1050    0.002    0.000    0.005    0.000 function_base.py:564(asarray_chkfinite)\n",
      "   518842    0.044    0.000    0.044    0.000 function_base.py:869(_copy_dispatcher)\n",
      "   518842    0.124    0.000    0.342    0.000 function_base.py:873(copy)\n",
      "  1505700    2.409    0.000    3.915    0.000 functools.py:35(update_wrapper)\n",
      "   767550    0.222    0.000    0.222    0.000 functools.py:65(wraps)\n",
      "    32775    0.106    0.000    1.300    0.000 generic.py:10967(_logical_func)\n",
      "    32775    0.051    0.000    1.351    0.000 generic.py:11010(any)\n",
      "    10920    0.043    0.000    0.810    0.000 generic.py:11240(_min_count_stat_function)\n",
      "    10920    0.019    0.000    0.829    0.000 generic.py:11272(sum)\n",
      "    32775    0.043    0.000    1.394    0.000 generic.py:11311(any)\n",
      "    10920    0.011    0.000    0.840    0.000 generic.py:11493(sum)\n",
      "        1    0.000    0.000    0.042    0.042 generic.py:1393(_wrap_applied_output)\n",
      "  2840500    3.092    0.000   25.563    0.000 generic.py:140(_wrap_agged_manager)\n",
      "  2840500    3.021    0.000    5.626    0.000 generic.py:143(_get_data_to_aggregate)\n",
      "      105    0.000    0.000    0.001    0.000 generic.py:1638(_is_label_reference)\n",
      "      210    0.000    0.000    0.000    0.000 generic.py:1660(<genexpr>)\n",
      "      210    0.000    0.000    0.000    0.000 generic.py:1665(<genexpr>)\n",
      "  2840608    5.065    0.000    8.822    0.000 generic.py:1693(_check_label_or_level_ambiguity)\n",
      "  2840608    0.266    0.000    0.266    0.000 generic.py:1714(<genexpr>)\n",
      "      105    0.000    0.000    0.005    0.000 generic.py:1737(_get_label_or_level_values)\n",
      "  2840500    2.286    0.000   95.077    0.000 generic.py:1759(__getitem__)\n",
      "      105    0.000    0.000    0.000    0.000 generic.py:1770(<listcomp>)\n",
      "  2840500    4.524    0.000   21.398    0.000 generic.py:1773(_gotitem)\n",
      "  5681273    2.841    0.000    8.681    0.000 generic.py:1924(__contains__)\n",
      "    54625    0.082    0.000    6.098    0.000 generic.py:1996(__array__)\n",
      " 14706494   16.050    0.000   19.941    0.000 generic.py:265(__init__)\n",
      "  7343142    1.147    0.000    1.147    0.000 generic.py:338(attrs)\n",
      " 14686180    1.434    0.000    1.434    0.000 generic.py:359(flags)\n",
      " 82569763   15.259    0.000   20.073    0.000 generic.py:37(_check)\n",
      "        3    0.000    0.000    0.025    0.008 generic.py:3832(take)\n",
      "    87448    0.365    0.000   55.643    0.001 generic.py:3911(_take)\n",
      "    87445    0.212    0.000   56.883    0.001 generic.py:3940(_take_with_is_copy)\n",
      "      105    0.000    0.000    0.004    0.000 generic.py:3954(xs)\n",
      "    87447    0.058    0.000    0.101    0.000 generic.py:4153(_set_is_copy)\n",
      "  4261172    1.720    0.000    2.535    0.000 generic.py:4176(_check_setitem_copy)\n",
      " 82569763   17.009    0.000   37.405    0.000 generic.py:42(_instancecheck)\n",
      "   294960    0.154    0.000    2.303    0.000 generic.py:453(_validate_dtype)\n",
      " 14532613    2.108    0.000    2.108    0.000 generic.py:509(_get_axis_number)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:5106(reindex)\n",
      "  3017081    1.656    0.000    2.016    0.000 generic.py:523(_get_axis)\n",
      "    87450    0.057    0.000    0.079    0.000 generic.py:529(_get_block_manager_axis)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:5348(<genexpr>)\n",
      "  7343038   13.600    0.000   19.626    0.000 generic.py:5931(__finalize__)\n",
      "      105    0.000    0.000    0.000    0.000 generic.py:5963(<genexpr>)\n",
      "      106    0.000    0.000    0.000    0.000 generic.py:5968(<genexpr>)\n",
      "7754303/7688753    3.768    0.000   11.110    0.000 generic.py:5975(__getattr__)\n",
      " 10239732    2.308    0.000    3.484    0.000 generic.py:599(_info_axis)\n",
      " 24658313   17.343    0.000   50.644    0.000 generic.py:5991(__setattr__)\n",
      "   262200    0.387    0.000   30.190    0.000 generic.py:6130(dtypes)\n",
      "    32775    0.099    0.000    1.668    0.000 generic.py:6161(astype)\n",
      "  2863305    0.488    0.000    0.488    0.000 generic.py:623(ndim)\n",
      "    22063    0.063    0.000    2.577    0.000 generic.py:6342(copy)\n",
      "    21850    0.128    0.000   19.812    0.001 generic.py:6735(fillna)\n",
      "  7428993    6.082    0.000   22.118    0.000 generic.py:723(_set_axis)\n",
      "    14600    0.011    0.000    0.015    0.000 getlimits.py:484(__new__)\n",
      "   752010    0.787    0.000    0.787    0.000 getlimits.py:685(__init__)\n",
      "     5670    0.002    0.000    0.002    0.000 getlimits.py:696(min)\n",
      "   746340    0.201    0.000    0.201    0.000 getlimits.py:709(max)\n",
      "        1    0.000    0.000    0.042    0.042 groupby.py:1003(_concat_objects)\n",
      "        1    0.003    0.003    0.181    0.181 groupby.py:1315(apply)\n",
      "        1    0.001    0.001    0.179    0.179 groupby.py:1367(_python_apply_general)\n",
      "  2840500   11.707    0.000  412.292    0.000 groupby.py:2801(_fill)\n",
      "  2840500    5.590    0.000   52.162    0.000 groupby.py:2843(blk_func)\n",
      "  1420250    0.851    0.000  207.515    0.000 groupby.py:2887(ffill)\n",
      "  1420250    0.903    0.000  206.531    0.000 groupby.py:2912(bfill)\n",
      "  2840503    0.918    0.000    1.074    0.000 groupby.py:721(_selected_obj)\n",
      "        2    0.000    0.000    0.000    0.000 groupby.py:804(__iter__)\n",
      "  5681003    8.649    0.000  141.697    0.000 groupby.py:897(__init__)\n",
      "  2840503    1.532    0.000    1.532    0.000 groupby.py:946(__getattr__)\n",
      "  2840503    0.748    0.000    0.906    0.000 grouper.py:1022(_is_label_like)\n",
      "  2840503    2.812    0.000    7.554    0.000 grouper.py:1026(_convert_grouper)\n",
      "  2840503    5.998    0.000   14.655    0.000 grouper.py:508(__init__)\n",
      "  2840503    1.024    0.000   10.685    0.000 grouper.py:619(_passed_categorical)\n",
      "  2840503    2.081    0.000    2.734    0.000 grouper.py:623(name)\n",
      "  2840503    0.436    0.000    0.436    0.000 grouper.py:641(_ilevel)\n",
      "  2840503    1.495    0.000  137.715    0.000 grouper.py:669(codes)\n",
      "  2840503    3.025    0.000  118.644    0.000 grouper.py:700(group_index)\n",
      "  2840503    3.409    0.000  136.220    0.000 grouper.py:722(_codes_and_uniques)\n",
      "  2840503   23.941    0.000  131.838    0.000 grouper.py:790(get_grouper)\n",
      "  5681006    1.477    0.000    1.841    0.000 grouper.py:891(<genexpr>)\n",
      "  5681006    1.016    0.000    1.237    0.000 grouper.py:892(<genexpr>)\n",
      "  5681006    1.422    0.000    1.774    0.000 grouper.py:893(<genexpr>)\n",
      "  2840503    0.928    0.000    1.834    0.000 grouper.py:927(is_in_axis)\n",
      "  2840503    0.716    0.000    1.082    0.000 grouper.py:943(is_in_obj)\n",
      "      220    0.000    0.000    0.058    0.000 indexing.py:1089(__getitem__)\n",
      "      422    0.000    0.000    0.000    0.000 indexing.py:1160(_has_valid_setitem_indexer)\n",
      "      844    0.002    0.000    0.014    0.000 indexing.py:1364(_convert_to_indexer)\n",
      "     6372    0.001    0.000    0.001    0.000 indexing.py:148(iloc)\n",
      "      210    0.000    0.000    0.000    0.000 indexing.py:1571(_validate_integer)\n",
      "       10    0.000    0.000    0.055    0.006 indexing.py:1600(_get_list_axis)\n",
      "      220    0.001    0.000    0.058    0.000 indexing.py:1623(_getitem_axis)\n",
      "      422    0.002    0.000    0.055    0.000 indexing.py:1689(_setitem_with_indexer)\n",
      "    21840    0.037    0.000    0.538    0.000 indexing.py:2476(check_bool_indexer)\n",
      "      422    0.000    0.000    0.000    0.000 indexing.py:2528(convert_missing_indexer)\n",
      "      422    0.000    0.000    0.000    0.000 indexing.py:2565(is_nested_tuple)\n",
      " 10073093    5.920    0.000    8.323    0.000 indexing.py:2609(check_dict_or_set_indexers)\n",
      "     1266    0.000    0.000    0.000    0.000 indexing.py:2616(<genexpr>)\n",
      "     1266    0.000    0.000    0.000    0.000 indexing.py:2625(<genexpr>)\n",
      "      422    0.000    0.000    0.000    0.000 indexing.py:287(loc)\n",
      "      422    0.001    0.000    0.018    0.000 indexing.py:685(_get_setitem_indexer)\n",
      "      422    0.001    0.000    0.001    0.000 indexing.py:777(_ensure_listlike_indexer)\n",
      "      422    0.002    0.000    0.078    0.000 indexing.py:831(__setitem__)\n",
      "     1266    0.000    0.000    0.000    0.000 indexing.py:841(<genexpr>)\n",
      "     1266    0.000    0.000    0.001    0.000 indexing.py:842(<genexpr>)\n",
      "      422    0.000    0.000    0.015    0.000 indexing.py:923(_convert_tuple)\n",
      "      422    0.000    0.000    0.014    0.000 indexing.py:927(<listcomp>)\n",
      "      422    0.000    0.000    0.000    0.000 indexing.py:930(_validate_key_length)\n",
      "  5965489    2.074    0.000    3.116    0.000 inference.py:189(is_array_like)\n",
      "  4293951    2.598    0.000    9.343    0.000 inference.py:267(is_dict_like)\n",
      " 17109832    2.907    0.000    4.224    0.000 inference.py:294(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 inference.py:300(is_named_tuple)\n",
      " 28341261    5.649    0.000    7.693    0.000 inference.py:328(is_hashable)\n",
      "      107    0.000    0.000    0.000    0.000 inference.py:367(is_sequence)\n",
      "        1    0.000    0.000    0.000    0.000 inference.py:398(is_dataclass)\n",
      "  1895135    1.616    0.000    2.317    0.000 inspect.py:167(get_annotations)\n",
      "  1895135   19.761    0.000   67.246    0.000 inspect.py:2333(_signature_from_function)\n",
      "  1895135    4.492    0.000   74.547    0.000 inspect.py:2428(_signature_from_callable)\n",
      "     3675    0.002    0.000    0.002    0.000 inspect.py:2465(<lambda>)\n",
      " 24086480   19.205    0.000   30.625    0.000 inspect.py:2686(__init__)\n",
      " 70145440    3.667    0.000    3.667    0.000 inspect.py:2739(name)\n",
      "    29745    0.002    0.000    0.002    0.000 inspect.py:2743(default)\n",
      " 44471670    2.206    0.000    2.206    0.000 inspect.py:2751(kind)\n",
      "     2610    0.000    0.000    0.000    0.000 inspect.py:2831(__init__)\n",
      "     2610    0.012    0.000    0.015    0.000 inspect.py:2892(apply_defaults)\n",
      "  1171930    0.264    0.000    0.375    0.000 inspect.py:292(isclass)\n",
      "  1895135    4.605    0.000   10.446    0.000 inspect.py:2972(__init__)\n",
      " 25981615    4.367    0.000    5.841    0.000 inspect.py:3019(<genexpr>)\n",
      "  1895135    0.682    0.000   75.229    0.000 inspect.py:3024(from_callable)\n",
      "  1944455    0.159    0.000    0.159    0.000 inspect.py:3032(parameters)\n",
      "     2610    0.028    0.000    0.038    0.000 inspect.py:3076(_bind)\n",
      "     2610    0.001    0.000    0.039    0.000 inspect.py:3207(bind)\n",
      "  1895135    0.628    0.000   75.856    0.000 inspect.py:3278(signature)\n",
      "  3790270    0.660    0.000    0.832    0.000 inspect.py:378(isfunction)\n",
      "  1895135    1.244    0.000    1.984    0.000 inspect.py:735(unwrap)\n",
      "  1898810    0.342    0.000    0.471    0.000 inspect.py:755(_is_wrapper)\n",
      "       52    0.000    0.000    0.000    0.000 iostream.py:137(_event_pipe)\n",
      "       52    0.000    0.000    0.011    0.000 iostream.py:259(schedule)\n",
      "      102    0.000    0.000    0.000    0.000 iostream.py:521(_is_master_process)\n",
      "      102    0.000    0.000    0.011    0.000 iostream.py:548(_schedule_flush)\n",
      "      102    0.001    0.000    0.012    0.000 iostream.py:626(write)\n",
      "     1575    0.001    0.000    0.002    0.000 lapack.py:1010(<genexpr>)\n",
      "     1050    0.001    0.000    0.001    0.000 lapack.py:1014(_check_work_float)\n",
      "      525    0.003    0.000    0.006    0.000 lapack.py:979(_compute_lwork)\n",
      "       22    0.000    0.000    0.000    0.000 linecache.py:26(getline)\n",
      "       22    0.000    0.000    0.000    0.000 linecache.py:36(getlines)\n",
      "     6300    0.001    0.000    0.001    0.000 link.py:23(__post_init__)\n",
      "    10500    0.004    0.000    0.004    0.000 logger.py:67(__init__)\n",
      "     3150    0.009    0.000    0.014    0.000 loss.py:129(__init__)\n",
      "    98771    0.778    0.000    0.792    0.000 loss.py:200(loss_gradient)\n",
      "     3150    0.010    0.000    0.025    0.000 loss.py:905(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1004(_verify_integrity)\n",
      "       13    0.000    0.000    0.000    0.000 managers.py:1006(<genexpr>)\n",
      "   131361    0.153    0.000    0.169    0.000 managers.py:1017(from_blocks)\n",
      "        2    0.000    0.000    0.001    0.000 managers.py:1027(fast_xs)\n",
      "        2    0.000    0.000    0.000    0.000 managers.py:1052(<listcomp>)\n",
      "  7113047   15.652    0.000   21.506    0.000 managers.py:1084(iget)\n",
      "  4260750   26.915    0.000   89.621    0.000 managers.py:1138(iset)\n",
      "  1376550    0.508    0.000    0.508    0.000 managers.py:1195(value_getitem)\n",
      "  1376550    4.597    0.000   22.902    0.000 managers.py:1281(_iset_split_block)\n",
      "  2884200    3.502    0.000   12.892    0.000 managers.py:1328(_iset_single)\n",
      "      422    0.002    0.000    0.040    0.000 managers.py:1387(insert)\n",
      "     2741    0.000    0.000    0.000    0.000 managers.py:1426(<genexpr>)\n",
      "      422    0.001    0.000    0.002    0.000 managers.py:1436(_insert_update_mgr_locs)\n",
      "      422    0.001    0.000    0.004    0.000 managers.py:1446(_insert_update_blklocs_and_blknos)\n",
      " 13100522    1.900    0.000    4.666    0.000 managers.py:167(blknos)\n",
      "    54627    0.107    0.000    6.028    0.000 managers.py:1677(as_array)\n",
      "    54627    3.163    0.000    5.886    0.000 managers.py:1741(_interleave)\n",
      "    54627    0.299    0.000    0.299    0.000 managers.py:1755(<listcomp>)\n",
      "    22064    0.019    0.000    0.138    0.000 managers.py:1805(is_consolidated)\n",
      "    22064    0.040    0.000    0.119    0.000 managers.py:1813(_consolidate_check)\n",
      "    22064    0.065    0.000    0.074    0.000 managers.py:1819(<listcomp>)\n",
      "    22064    0.058    0.000    1.720    0.000 managers.py:1823(_consolidate_inplace)\n",
      "  8577572    1.204    0.000    1.204    0.000 managers.py:183(blklocs)\n",
      "  4260752    0.343    0.000    0.343    0.000 managers.py:1838(ndim)\n",
      " 14574813    2.291    0.000    2.291    0.000 managers.py:1847(__init__)\n",
      "  7134027    5.345    0.000    7.350    0.000 managers.py:1860(from_blocks)\n",
      "   327737    0.325    0.000    2.326    0.000 managers.py:1873(from_array)\n",
      "  7408011    1.055    0.000    1.055    0.000 managers.py:1944(_block)\n",
      "   248687    0.114    0.000    0.130    0.000 managers.py:2000(dtype)\n",
      "    11635    0.015    0.000    0.041    0.000 managers.py:2007(external_values)\n",
      "  7770974    5.031    0.000    6.078    0.000 managers.py:2011(internal_values)\n",
      "     9742    0.004    0.000    0.005    0.000 managers.py:2063(set_values)\n",
      "        2    0.000    0.000    0.000    0.000 managers.py:2119(create_block_manager_from_column_arrays)\n",
      "       45    0.000    0.000    0.000    0.000 managers.py:2175(_grouping_func)\n",
      "        2    0.000    0.000    0.000    0.000 managers.py:2191(_form_blocks)\n",
      "  7428993    3.053    0.000   13.247    0.000 managers.py:223(set_axis)\n",
      "        7    0.000    0.000    0.000    0.000 managers.py:2249(_stack_arrays)\n",
      "    21852    0.123    0.000    1.341    0.000 managers.py:2262(_consolidate)\n",
      "   174818    0.050    0.000    0.477    0.000 managers.py:2267(<lambda>)\n",
      "    65556    0.271    0.000    0.654    0.000 managers.py:2279(_merge_blocks)\n",
      "   120749    0.036    0.000    0.043    0.000 managers.py:228(is_single_block)\n",
      "    21852    0.018    0.000    0.023    0.000 managers.py:2288(<listcomp>)\n",
      "    21852    0.006    0.000    0.006    0.000 managers.py:2297(<listcomp>)\n",
      "      422    0.001    0.000    0.001    0.000 managers.py:2314(_fast_count_smallints)\n",
      "    65595    0.074    0.000    0.091    0.000 managers.py:2323(_preprocess_slice_or_indexer)\n",
      "    87815    0.013    0.000    0.013    0.000 managers.py:233(items)\n",
      "   262200    0.383    0.000   16.697    0.000 managers.py:276(get_dtypes)\n",
      "   262200    2.045    0.000    2.145    0.000 managers.py:277(<listcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 managers.py:280(arrays)\n",
      "        4    0.000    0.000    0.000    0.000 managers.py:292(<listcomp>)\n",
      "  7177940   16.265    0.000  125.808    0.000 managers.py:306(apply)\n",
      "  7177940    0.718    0.000    0.718    0.000 managers.py:333(<dictcomp>)\n",
      "    21850    0.033    0.000   19.424    0.001 managers.py:428(fillna)\n",
      "    32775    0.049    0.000    0.991    0.000 managers.py:442(astype)\n",
      "  4282815    4.277    0.000   27.673    0.000 managers.py:620(copy)\n",
      "    44124    0.020    0.000    0.165    0.000 managers.py:646(copy_func)\n",
      "    22062    0.017    0.000    0.182    0.000 managers.py:649(<listcomp>)\n",
      "    87448    0.294    0.000   52.536    0.001 managers.py:683(reindex_indexer)\n",
      "    21853    0.191    0.000    4.560    0.000 managers.py:747(<listcomp>)\n",
      "    65595    6.515    0.000   47.472    0.001 managers.py:768(_slice_take_blocks_ax0)\n",
      "    87448    0.292    0.000   54.496    0.001 managers.py:929(take)\n",
      "   131679    0.015    0.000    0.015    0.000 managers.py:982(__init__)\n",
      "  4297411    1.375    0.000   18.745    0.000 missing.py:106(isna)\n",
      "   131191    0.022    0.000    0.022    0.000 missing.py:121(clean_fill_method)\n",
      "  4297411    4.064    0.000   17.370    0.000 missing.py:189(_isna)\n",
      "  4195305    6.159    0.000    9.427    0.000 missing.py:266(_isna_array)\n",
      "   284440    0.175    0.000    0.222    0.000 missing.py:455(array_equivalent)\n",
      "      209    0.000    0.000    0.002    0.000 missing.py:553(_array_equivalent_object)\n",
      "  5769440    3.703    0.000   17.589    0.000 missing.py:625(na_value_for_dtype)\n",
      "    68821    0.033    0.000    0.113    0.000 missing.py:679(is_valid_na_for_dtype)\n",
      "       93    0.000    0.000    0.000    0.000 missing.py:730(isna_all)\n",
      "      186    0.000    0.000    0.000    0.000 missing.py:759(<genexpr>)\n",
      "   131191    0.067    0.000    0.088    0.000 missing.py:949(clean_reindex_fill_method)\n",
      "  6240994    0.694    0.000    0.694    0.000 multiarray.py:1080(copyto)\n",
      "    22900    0.003    0.000    0.003    0.000 multiarray.py:1393(may_share_memory)\n",
      "  3542951    0.337    0.000    0.337    0.000 multiarray.py:153(concatenate)\n",
      "    68399    0.008    0.000    0.008    0.000 multiarray.py:346(where)\n",
      "    91193    0.010    0.000    0.010    0.000 multiarray.py:669(result_type)\n",
      "      525    0.000    0.000    0.000    0.000 multiarray.py:741(dot)\n",
      "   302088    0.022    0.000    0.022    0.000 multiarray.py:85(empty_like)\n",
      "   373592    0.035    0.000    0.035    0.000 multiarray.py:892(bincount)\n",
      "    21306    0.006    0.000    0.006    0.000 multiclass.py:112(<genexpr>)\n",
      "    11340    0.002    0.000    0.003    0.000 multiclass.py:114(<genexpr>)\n",
      "   337680    1.038    0.000    7.062    0.000 multiclass.py:124(is_multilabel)\n",
      "   321300    0.167    0.000   21.542    0.000 multiclass.py:196(check_classification_targets)\n",
      "     7560    0.007    0.000    0.064    0.000 multiclass.py:21(_unique_multiclass)\n",
      "   337680    3.700    0.000   22.321    0.000 multiclass.py:223(type_of_target)\n",
      "     3780    0.023    0.000    0.494    0.000 multiclass.py:42(unique_labels)\n",
      "    11340    0.004    0.000    0.383    0.000 multiclass.py:79(<genexpr>)\n",
      "     5670    0.010    0.000    0.036    0.000 nanfunctions.py:187(_divide_by_count)\n",
      "     5670    0.013    0.000    0.017    0.000 nanfunctions.py:68(_replace_nan)\n",
      "     5670    0.001    0.000    0.001    0.000 nanfunctions.py:947(_nanmean_dispatcher)\n",
      "     5670    0.014    0.000    0.111    0.000 nanfunctions.py:952(nanmean)\n",
      "    10920    0.002    0.000    0.002    0.000 nanops.py:1500(_maybe_null_out)\n",
      "    43695    0.005    0.000    0.005    0.000 nanops.py:198(_get_fill_value)\n",
      "    43695    0.022    0.000    0.122    0.000 nanops.py:220(_maybe_get_mask)\n",
      "    43695    0.166    0.000    0.689    0.000 nanops.py:264(_get_values)\n",
      "    43695    0.028    0.000    0.044    0.000 nanops.py:353(_na_ok_dtype)\n",
      "    10920    0.021    0.000    0.457    0.000 nanops.py:406(new_func)\n",
      "    10920    0.013    0.000    0.437    0.000 nanops.py:472(newfunc)\n",
      "    32775    0.063    0.000    0.796    0.000 nanops.py:499(nanany)\n",
      "    10920    0.032    0.000    0.424    0.000 nanops.py:609(nansum)\n",
      "    32760    0.015    0.000    0.021    0.000 nanops.py:82(check)\n",
      "    10920    0.052    0.000    0.625    0.000 nanops.py:86(_f)\n",
      "    43680    0.024    0.000    0.045    0.000 nanops.py:89(<genexpr>)\n",
      "     4834    0.009    0.000    0.014    0.000 numeric.py:1330(normalize_axis_tuple)\n",
      "   379995    0.701    0.000    0.913    0.000 numeric.py:136(ones)\n",
      "     4834    0.002    0.000    0.004    0.000 numeric.py:1380(<listcomp>)\n",
      "      842    0.000    0.000    0.000    0.000 numeric.py:1389(_moveaxis_dispatcher)\n",
      "      842    0.002    0.000    0.006    0.000 numeric.py:1393(moveaxis)\n",
      "      842    0.000    0.000    0.000    0.000 numeric.py:1455(<listcomp>)\n",
      "   114916    0.053    0.000    0.081    0.000 numeric.py:1855(isscalar)\n",
      "     5670    0.001    0.000    0.001    0.000 numeric.py:199(_ones_like_dispatcher)\n",
      "     5670    0.010    0.000    0.011    0.000 numeric.py:203(ones_like)\n",
      "     3780    0.000    0.000    0.000    0.000 numeric.py:2245(_isclose_dispatcher)\n",
      "     3780    0.016    0.000    0.102    0.000 numeric.py:2249(isclose)\n",
      "     3780    0.018    0.000    0.058    0.000 numeric.py:2330(within_tol)\n",
      "    98772    0.009    0.000    0.009    0.000 numeric.py:2374(_array_equal_dispatcher)\n",
      "    98772    0.117    0.000    0.265    0.000 numeric.py:2378(array_equal)\n",
      "  5849554    6.614    0.000   10.504    0.000 numeric.py:274(full)\n",
      "      105    0.000    0.000    0.000    0.000 numeric.py:63(_zeros_like_dispatcher)\n",
      "      105    0.001    0.000    0.003    0.000 numeric.py:67(zeros_like)\n",
      "   198342    0.065    0.000    0.095    0.000 numerictypes.py:283(issubclass_)\n",
      "    99171    0.089    0.000    0.190    0.000 numerictypes.py:357(issubdtype)\n",
      "      105    0.000    0.000    0.000    0.000 ops.py:1188(_is_indexed_like)\n",
      "        3    0.000    0.000    0.000    0.000 ops.py:1204(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 ops.py:1218(_slabels)\n",
      "        3    0.000    0.000    0.000    0.000 ops.py:1223(_sort_idx)\n",
      "      318    0.001    0.000    0.037    0.000 ops.py:1228(__iter__)\n",
      "        3    0.000    0.000    0.025    0.008 ops.py:1241(_sorted_data)\n",
      "      315    0.001    0.000    0.011    0.000 ops.py:1258(_chop)\n",
      "        3    0.000    0.000    0.000    0.000 ops.py:1269(_get_splitter)\n",
      "  2840503    1.404    0.000    1.538    0.000 ops.py:685(__init__)\n",
      "  5681012    0.594    0.000    0.594    0.000 ops.py:699(groupings)\n",
      "      212    0.003    0.000    0.037    0.000 ops.py:714(get_iterator)\n",
      "        3    0.000    0.000    0.003    0.001 ops.py:729(_get_splitter)\n",
      "        3    0.000    0.000    0.000    0.000 ops.py:739(group_keys_seq)\n",
      "        1    0.000    0.000    0.136    0.136 ops.py:750(apply)\n",
      "        3    0.000    0.000    0.000    0.000 ops.py:826(levels)\n",
      "        3    0.000    0.000    0.000    0.000 ops.py:828(<listcomp>)\n",
      "  2840503    2.366    0.000  268.149    0.000 ops.py:871(group_info)\n",
      "  2840503    5.488    0.000  265.408    0.000 ops.py:886(_get_compressed_codes)\n",
      "     3150    0.010    0.000    0.023    0.000 optimize.py:218(_check_optimize_result)\n",
      "   738150    0.224    0.000    1.994    0.000 parallel.py:105(__init__)\n",
      "   738150    0.084    0.000    0.084    0.000 parallel.py:109(with_config)\n",
      "   160125    0.041    0.000    0.041    0.000 parallel.py:110(_get_config_param)\n",
      "   738150    1.476    0.000  313.856    0.000 parallel.py:113(__call__)\n",
      "    10500    0.165    0.000    0.616    0.000 parallel.py:1176(__init__)\n",
      "   738150    0.294    0.000    0.461    0.000 parallel.py:12(_with_config)\n",
      "    10500    0.018    0.000    0.031    0.000 parallel.py:1219(<dictcomp>)\n",
      "     6825    0.008    0.000    0.083    0.000 parallel.py:129(get_active_backend)\n",
      "21000/10500    0.056    0.000    0.116    0.000 parallel.py:1329(_initialize_backend)\n",
      "    17325    0.076    0.000    0.160    0.000 parallel.py:142(_get_active_backend)\n",
      "    10500    0.007    0.000    0.008    0.000 parallel.py:1465(_get_batch_size)\n",
      "   748650    0.103    0.000    0.103    0.000 parallel.py:1491(print_progress)\n",
      "   759150    1.118    0.000  321.947    0.000 parallel.py:1764(_get_sequential_output)\n",
      "    10500    0.034    0.000    0.039    0.000 parallel.py:1808(_reset_run_tracking)\n",
      "    10500    0.143    0.000  322.252    0.031 parallel.py:1847(__call__)\n",
      "    10500    0.019    0.000  322.284    0.031 parallel.py:42(__call__)\n",
      "   748650    0.367    0.000    6.863    0.000 parallel.py:61(<genexpr>)\n",
      "   738150    0.604    0.000    2.860    0.000 parallel.py:69(delayed)\n",
      "     6825    0.015    0.000    0.100    0.000 parallel.py:901(effective_n_jobs)\n",
      "   738150    0.288    0.000    2.282    0.000 parallel.py:95(delayed_function)\n",
      "     3150    0.002    0.000    0.002    0.000 process.py:198(daemon)\n",
      "     3150    0.001    0.000    0.001    0.000 process.py:37(current_process)\n",
      "  1423099    0.729    0.000    3.500    0.000 putmask.py:104(validate_putmask)\n",
      "  1491498    0.514    0.000    0.774    0.000 putmask.py:118(extract_bool_array)\n",
      "    68399    0.017    0.000    0.017    0.000 putmask.py:132(setitem_datetimelike_compat)\n",
      "    10500    0.005    0.000    0.005    0.000 queue.py:206(_init)\n",
      "    10500    0.038    0.000    0.109    0.000 queue.py:34(__init__)\n",
      "   738675    0.475    0.000    1.674    0.000 random.py:800(getrandbits)\n",
      "        2    0.000    0.000    0.000    0.000 range.py:166(_simple_new)\n",
      "       46    0.000    0.000    0.000    0.000 range.py:892(__len__)\n",
      "    19484    0.010    0.000    0.027    0.000 series.py:1099(_get_value)\n",
      "  7113047    4.202    0.000   11.347    0.000 series.py:1314(_set_as_cached)\n",
      "  7428993    0.573    0.000    0.573    0.000 series.py:1323(_clear_item_cache)\n",
      "      105    0.000    0.000    0.013    0.000 series.py:2131(unique)\n",
      "    32760    0.111    0.000    2.454    0.000 series.py:3075(_construct_result)\n",
      "14574815/14574813   26.051    0.000  142.157    0.000 series.py:368(__init__)\n",
      "    32775    0.054    0.000    5.033    0.000 series.py:4520(apply)\n",
      "    43695    0.163    0.000    1.921    0.000 series.py:4632(_reduce)\n",
      "        2    0.000    0.000    0.003    0.001 series.py:521(_init_dict)\n",
      "  2938810    0.352    0.000    0.352    0.000 series.py:574(_constructor)\n",
      "   248687    0.068    0.000    0.199    0.000 series.py:594(dtype)\n",
      "    11460    0.002    0.000    0.006    0.000 series.py:607(dtypes)\n",
      "    32760    0.183    0.000    5.429    0.000 series.py:6086(_cmp_method)\n",
      " 17567353    5.427    0.000    8.971    0.000 series.py:621(name)\n",
      "  7592838    4.609    0.000   16.446    0.000 series.py:671(name)\n",
      "    11635    0.008    0.000    0.049    0.000 series.py:676(values)\n",
      "  7770974    2.237    0.000    8.314    0.000 series.py:718(_values)\n",
      "    87390    0.022    0.000    0.150    0.000 series.py:783(__len__)\n",
      "    38610    0.034    0.000    0.089    0.000 series.py:869(__array__)\n",
      "      210    0.000    0.000    0.000    0.000 series.py:973(_ixs)\n",
      "    19484    0.018    0.000    0.064    0.000 series.py:992(__getitem__)\n",
      "   576907    0.043    0.000    0.043    0.000 shape_base.py:19(_atleast_1d_dispatcher)\n",
      "    23742    0.011    0.000    0.015    0.000 shape_base.py:207(_arrays_for_stack_dispatcher)\n",
      "    23742    0.013    0.000    0.028    0.000 shape_base.py:215(_vhstack_dispatcher)\n",
      "    21852    0.086    0.000    0.133    0.000 shape_base.py:219(vstack)\n",
      "   576907    0.506    0.000    0.651    0.000 shape_base.py:23(atleast_1d)\n",
      "     1890    0.005    0.000    0.009    0.000 shape_base.py:292(hstack)\n",
      "     3150    0.000    0.000    0.000    0.000 shape_base.py:508(_expand_dims_dispatcher)\n",
      "     3150    0.012    0.000    0.028    0.000 shape_base.py:512(expand_dims)\n",
      "     3150    0.002    0.000    0.002    0.000 shape_base.py:600(<listcomp>)\n",
      "    25002    0.002    0.000    0.002    0.000 shape_base.py:77(_atleast_2d_dispatcher)\n",
      "    25002    0.038    0.000    0.048    0.000 shape_base.py:81(atleast_2d)\n",
      "     3675    0.001    0.000    0.001    0.000 sklearn.py:1103(_can_use_inplace_predict)\n",
      "     3675    0.006    0.000    0.034    0.000 sklearn.py:1108(_get_iteration_range)\n",
      "     3675    0.024    0.000    1.121    0.000 sklearn.py:1121(predict)\n",
      "     3675    0.006    0.000    0.029    0.000 sklearn.py:1287(best_iteration)\n",
      "     3150    0.008    0.000    0.026    0.000 sklearn.py:1414(__init__)\n",
      "     3150    0.065    0.000   82.467    0.026 sklearn.py:1423(fit)\n",
      "     3150    0.049    0.000    1.158    0.000 sklearn.py:1540(predict)\n",
      "     3150    0.001    0.000    0.005    0.000 sklearn.py:1636(classes_)\n",
      "      525    0.001    0.000    0.005    0.000 sklearn.py:1713(__init__)\n",
      "     3675    0.012    0.000    4.471    0.001 sklearn.py:514(_wrap_evaluation_matrices)\n",
      "    18375    0.002    0.000    0.002    0.000 sklearn.py:602(<genexpr>)\n",
      "     3675    0.021    0.000    0.021    0.000 sklearn.py:629(__init__)\n",
      "     7350    0.002    0.000    0.003    0.000 sklearn.py:723(__sklearn_is_fitted__)\n",
      "     7350    0.004    0.000    0.007    0.000 sklearn.py:726(get_booster)\n",
      "7350/3675    0.031    0.000    0.978    0.000 sklearn.py:772(get_params)\n",
      "     3675    0.002    0.000    0.002    0.000 sklearn.py:79(_can_use_qdm)\n",
      "     3675    0.035    0.000    1.018    0.000 sklearn.py:795(get_xgb_params)\n",
      "     3675    0.001    0.000    0.001    0.000 sklearn.py:818(get_num_boosting_rounds)\n",
      "     3675    0.007    0.000    0.008    0.000 sklearn.py:864(_configure_fit)\n",
      "     3675    0.013    0.000    4.452    0.001 sklearn.py:950(_create_dmatrix)\n",
      "     3675    0.001    0.000    0.001    0.000 sklearn.py:961(_set_evaluation_result)\n",
      "      525    0.007    0.000   26.088    0.050 sklearn.py:965(fit)\n",
      "       52    0.011    0.000    0.011    0.000 socket.py:621(send)\n",
      "      105    0.001    0.000    0.003    0.000 sorting.py:369(nargsort)\n",
      "        3    0.000    0.000    0.000    0.000 sorting.py:630(get_group_index_sorter)\n",
      "  9003367   17.931    0.000   47.084    0.000 take.py:120(_take_nd_ndarray)\n",
      "  9003367    2.594    0.000    2.594    0.000 take.py:325(_get_take_nd_function)\n",
      "  9003367    4.171    0.000   14.290    0.000 take.py:564(_take_preprocess_indexer_and_fill_value)\n",
      "  9003367    9.075    0.000   67.838    0.000 take.py:58(take_nd)\n",
      "       52    0.000    0.000    0.000    0.000 threading.py:1118(_wait_for_tstate_lock)\n",
      "       52    0.000    0.000    0.000    0.000 threading.py:1185(is_alive)\n",
      "     3150    0.003    0.000    0.004    0.000 threading.py:1446(current_thread)\n",
      "    31500    0.062    0.000    0.062    0.000 threading.py:236(__init__)\n",
      "       52    0.000    0.000    0.000    0.000 threading.py:568(is_set)\n",
      "    10500    0.012    0.000    0.012    0.000 threading.py:90(RLock)\n",
      "     3675    0.000    0.000    0.000    0.000 training.py:159(<listcomp>)\n",
      "     3675    0.001    0.000    0.001    0.000 training.py:31(_configure_custom_metric)\n",
      "     3675    0.445    0.000  102.342    0.028 training.py:51(train)\n",
      "      105    0.000    0.000    0.000    0.000 typing.py:1297(__instancecheck__)\n",
      "    58800    0.024    0.000    0.027    0.000 typing.py:1358(__eq__)\n",
      "    66150    0.026    0.000    0.032    0.000 typing.py:1364(__hash__)\n",
      "      105    0.000    0.000    0.000    0.000 typing.py:1572(__subclasscheck__)\n",
      "    58800    0.061    0.000    0.094    0.000 typing.py:1611(__getitem__)\n",
      " 11996708    0.810    0.000    0.810    0.000 typing.py:2246(cast)\n",
      "   135975    0.075    0.000    0.134    0.000 typing.py:349(inner)\n",
      "     1890    0.000    0.000    0.000    0.000 ufunclike.py:14(_dispatcher)\n",
      "     1890    0.007    0.000    0.007    0.000 ufunclike.py:71(isposinf)\n",
      "      210    0.000    0.000    0.001    0.000 utils.py:1081(_median_nancheck)\n",
      "    87448    0.428    0.000    0.742    0.000 utils.py:241(maybe_convert_indices)\n",
      "    21850    0.016    0.000    0.033    0.000 utils.py:373(check_key_length)\n",
      "    21840    0.089    0.000    0.326    0.000 utils.py:421(check_array_indexer)\n",
      "     1486    0.000    0.000    0.001    0.000 utils.py:64(is_list_like_indexer)\n",
      "    10500    0.042    0.000    0.053    0.000 uuid.py:139(__init__)\n",
      "    10500    0.009    0.000    0.009    0.000 uuid.py:334(hex)\n",
      "    10500    0.028    0.000    0.128    0.000 uuid.py:721(uuid4)\n",
      "     7350    0.021    0.000    1.047    0.000 validation.py:1020(check_X_y)\n",
      "     7350    0.011    0.000    0.299    0.000 validation.py:1169(_check_y)\n",
      "    17640    0.030    0.000    0.482    0.000 validation.py:1192(column_or_1d)\n",
      "  1109325   22.797    0.000   60.889    0.000 validation.py:1249(check_random_state)\n",
      "   782580    0.735    0.000    4.926    0.000 validation.py:1366(_is_fitted)\n",
      "   782580    2.360    0.000    3.941    0.000 validation.py:1398(<listcomp>)\n",
      "   771655    0.610    0.000    5.827    0.000 validation.py:1404(check_is_fitted)\n",
      "   370650    0.584    0.000   20.693    0.000 validation.py:1787(_check_sample_weight)\n",
      "    47475    0.229    0.000    0.621    0.000 validation.py:1987(_get_feature_names)\n",
      "  2163150    0.237    0.000    0.237    0.000 validation.py:2016(<genexpr>)\n",
      "     9720    0.003    0.000    0.005    0.000 validation.py:267(_is_arraylike)\n",
      "     9720    0.004    0.000    0.017    0.000 validation.py:272(_is_arraylike_not_scalar)\n",
      "   414975    0.464    0.000    0.788    0.000 validation.py:277(_num_features)\n",
      "   823755    1.268    0.000    2.566    0.000 validation.py:330(_num_samples)\n",
      "    14460    0.038    0.000    0.305    0.000 validation.py:393(check_consistent_length)\n",
      "    14460    0.010    0.000    0.126    0.000 validation.py:404(<listcomp>)\n",
      "  1116555    0.469    0.000    0.642    0.000 validation.py:581(_ensure_no_complex_data)\n",
      "  1116555    0.119    0.000    0.125    0.000 validation.py:591(_check_estimator_name)\n",
      "  2136105    2.914    0.000   11.552    0.000 validation.py:600(_pandas_dtype_needs_early_conversion)\n",
      "  1080630    0.315    0.000    0.460    0.000 validation.py:639(_is_extension_array_dtype)\n",
      "  1113405    6.956    0.000   89.528    0.000 validation.py:644(check_array)\n",
      "  2130375    0.246    0.000    0.350    0.000 validation.py:781(is_sparse)\n",
      "  2163150    0.446    0.000   11.956    0.000 validation.py:791(<genexpr>)\n",
      "  2163150    0.309    0.000    0.445    0.000 validation.py:794(<genexpr>)\n",
      "   423555    2.255    0.000    9.327    0.000 validation.py:92(_assert_all_finite)\n",
      "       22    0.000    0.000    0.000    0.000 warnings.py:117(_formatwarnmsg)\n",
      "  5121450    2.855    0.000   10.210    0.000 warnings.py:165(simplefilter)\n",
      "  5121450    4.165    0.000    7.111    0.000 warnings.py:181(_add_filter)\n",
      "       22    0.000    0.000    0.010    0.000 warnings.py:20(_showwarnmsg_impl)\n",
      "       22    0.000    0.000    0.000    0.000 warnings.py:35(_formatwarnmsg_impl)\n",
      "       22    0.000    0.000    0.000    0.000 warnings.py:403(__init__)\n",
      "  5121450    1.693    0.000    1.693    0.000 warnings.py:440(__init__)\n",
      "  5121450    4.325    0.000    4.643    0.000 warnings.py:466(__enter__)\n",
      "  5121450    2.713    0.000    2.984    0.000 warnings.py:487(__exit__)\n",
      "       22    0.000    0.000    0.010    0.000 warnings.py:96(_showwarnmsg)\n",
      "  3180346    0.457    0.000    0.457    0.000 {built-in method __new__ of type object at 0x1014bbd60}\n",
      "  4941899    1.307    0.000    2.166    0.000 {built-in method _abc._abc_instancecheck}\n",
      "  2360535    0.464    0.000    0.464    0.000 {built-in method _abc._abc_subclasscheck}\n",
      "  1877925    0.127    0.000    0.127    0.000 {built-in method _ctypes.POINTER}\n",
      "  4505025    0.374    0.000    0.374    0.000 {built-in method _ctypes.byref}\n",
      "    34650    0.003    0.000    0.003    0.000 {built-in method _operator.ge}\n",
      "    11025    0.001    0.000    0.001    0.000 {built-in method _operator.gt}\n",
      "     7984    0.001    0.000    0.001    0.000 {built-in method _operator.index}\n",
      "     6825    0.001    0.000    0.001    0.000 {built-in method _operator.le}\n",
      "    38850    0.004    0.000    0.004    0.000 {built-in method _operator.lt}\n",
      "    14175    0.005    0.000    0.005    0.000 {built-in method _thread.allocate_lock}\n",
      "     3150    0.001    0.000    0.001    0.000 {built-in method _thread.get_ident}\n",
      " 15364350    0.883    0.000    0.883    0.000 {built-in method _warnings._filters_mutated}\n",
      "       22    0.000    0.000    0.010    0.000 {built-in method _warnings.warn}\n",
      "     7560    0.004    0.000    0.004    0.000 {built-in method builtins.abs}\n",
      "12171728/12171598    5.033    0.000   16.060    0.000 {built-in method builtins.all}\n",
      " 10318128    3.900    0.000   25.878    0.000 {built-in method builtins.any}\n",
      " 29778945    1.855    0.000    1.855    0.000 {built-in method builtins.callable}\n",
      "        1    0.000    0.000 1694.967 1694.967 {built-in method builtins.exec}\n",
      "182161660/182128885   13.194    0.000   13.715    0.000 {built-in method builtins.getattr}\n",
      "85715478/85713588    7.229    0.000   28.651    0.000 {built-in method builtins.hasattr}\n",
      " 48347424    3.399    0.000    3.399    0.000 {built-in method builtins.hash}\n",
      "  6256520    0.397    0.000    0.397    0.000 {built-in method builtins.id}\n",
      "623039089/618439201   58.775    0.000   98.685    0.000 {built-in method builtins.isinstance}\n",
      " 36332956    2.561    0.000    2.561    0.000 {built-in method builtins.issubclass}\n",
      "     8477    0.001    0.000    0.001    0.000 {built-in method builtins.iter}\n",
      "164527734/122080127   18.472    0.000   26.800    0.000 {built-in method builtins.len}\n",
      "  3679400    0.618    0.000    0.618    0.000 {built-in method builtins.max}\n",
      "   353337    0.076    0.000    0.076    0.000 {built-in method builtins.min}\n",
      "  2313746    0.515    0.000    7.955    0.000 {built-in method builtins.next}\n",
      "       40    0.000    0.000    0.003    0.000 {built-in method builtins.print}\n",
      " 11571000    0.858    0.000    0.858    0.000 {built-in method builtins.setattr}\n",
      "  2289874    0.992    0.000    1.473    0.000 {built-in method builtins.sorted}\n",
      "      528    0.000    0.000    0.001    0.000 {built-in method builtins.sum}\n",
      "   782580    0.122    0.000    0.122    0.000 {built-in method builtins.vars}\n",
      "   749175    0.089    0.000    0.089    0.000 {built-in method from_bytes}\n",
      "     3780    0.000    0.000    0.000    0.000 {built-in method from_iterable}\n",
      "    54629    0.064    0.000    0.064    0.000 {built-in method fromkeys}\n",
      "     1890    0.001    0.000    0.001    0.000 {built-in method math.isnan}\n",
      "  5596858    2.751    0.000    2.751    0.000 {built-in method numpy.arange}\n",
      "  1216983   11.912    0.000   11.912    0.000 {built-in method numpy.array}\n",
      "  2139908    0.177    0.000    0.177    0.000 {built-in method numpy.asanyarray}\n",
      "32097474/32004324    5.363    0.000    9.338    0.000 {built-in method numpy.asarray}\n",
      "   318150    0.173    0.000    0.173    0.000 {built-in method numpy.ascontiguousarray}\n",
      "     3150    0.019    0.000    0.019    0.000 {built-in method numpy.core._multiarray_umath.c_einsum}\n",
      "     7429    0.002    0.000    0.002    0.000 {built-in method numpy.core._multiarray_umath.normalize_axis_index}\n",
      " 19144646    6.261    0.000    6.261    0.000 {built-in method numpy.empty}\n",
      "  5185820    0.373    0.000    0.373    0.000 {built-in method numpy.geterrobj}\n",
      "  2592910    0.477    0.000    0.477    0.000 {built-in method numpy.seterrobj}\n",
      "   436572    0.130    0.000    0.130    0.000 {built-in method numpy.zeros}\n",
      "  6177348    0.979    0.000    0.979    0.000 {built-in method pandas._libs.missing.checknull}\n",
      "      102    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "   749175    1.160    0.000    1.160    0.000 {built-in method posix.urandom}\n",
      "  1895135    0.137    0.000    0.137    0.000 {built-in method sys.getrecursionlimit}\n",
      "    54610    0.038    0.000    0.038    0.000 {built-in method time.time}\n",
      "     7350    0.002    0.000    0.002    0.000 {function BaseEstimator.__getstate__ at 0x16e6d7560}\n",
      "        1    0.000    0.000    0.000    0.000 {function FrozenList.__getitem__ at 0x109b9c180}\n",
      "   738675   30.656    0.000   30.656    0.000 {function SeedSequence.generate_state at 0x105fe5300}\n",
      " 24086480    1.342    0.000    1.342    0.000 {method '__contains__' of 'frozenset' objects}\n",
      "    10602    0.002    0.000    0.002    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "   367500    0.033    0.000    0.033    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "     7350    0.013    0.000    0.026    0.000 {method '__reduce_ex__' of 'object' objects}\n",
      "    65598    0.595    0.000    2.950    0.000 {method '_rebuild_blknos_and_blklocs' of 'pandas._libs.internals.BlockManager' objects}\n",
      "       52    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "  2860873    0.235    0.000    0.235    0.000 {method 'add' of 'set' objects}\n",
      "  3169604    0.752    0.000    0.752    0.000 {method 'add_index_reference' of 'pandas._libs.internals.BlockValuesRefs' objects}\n",
      "     4200    0.003    0.000    0.009    0.000 {method 'all' of 'numpy.generic' objects}\n",
      "   185200    0.073    0.000    0.400    0.000 {method 'all' of 'numpy.ndarray' objects}\n",
      "     6720    0.005    0.000    0.013    0.000 {method 'any' of 'numpy.generic' objects}\n",
      "  1922908    0.547    0.000    3.048    0.000 {method 'any' of 'numpy.ndarray' objects}\n",
      "       52    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      " 45475725    2.641    0.000    2.641    0.000 {method 'append' of 'list' objects}\n",
      "  1376550    0.144    0.000    0.144    0.000 {method 'append' of 'pandas._libs.internals.BlockPlacement' objects}\n",
      "     3150    0.003    0.000    0.003    0.000 {method 'argmax' of 'numpy.ndarray' objects}\n",
      "  8861613    3.805    0.000    3.805    0.000 {method 'argsort' of 'numpy.ndarray' objects}\n",
      "  9398154    1.714    0.000    1.714    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
      "   367500  159.058    0.000  159.150    0.000 {method 'build' of 'sklearn.tree._tree.DepthFirstTreeBuilder' objects}\n",
      "  4282813    2.813    0.000    2.813    0.000 {method 'clear' of 'dict' objects}\n",
      "     3150    0.002    0.000    0.011    0.000 {method 'clip' of 'numpy.ndarray' objects}\n",
      "  4263895    0.418    0.000    0.418    0.000 {method 'copy' of 'dict' objects}\n",
      "  7260217    3.431    0.000    3.431    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
      "    10500    0.004    0.000    0.004    0.000 {method 'count' of 'list' objects}\n",
      "   321825    0.803    0.000    0.803    0.000 {method 'cumsum' of 'numpy.ndarray' objects}\n",
      "   381150    0.047    0.000    0.047    0.000 {method 'decode' of 'bytes' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "  2667000    0.223    0.000    0.223    0.000 {method 'encode' of 'str' objects}\n",
      "    21000    0.002    0.000    0.002    0.000 {method 'end' of 're.Match' objects}\n",
      " 17507280    1.603    0.000    1.603    0.000 {method 'endswith' of 'str' objects}\n",
      "    72074    0.007    0.000    0.007    0.000 {method 'extend' of 'list' objects}\n",
      "  2840503   13.397    0.000   13.397    0.000 {method 'factorize' of 'pandas._libs.hashtable.StringHashTable' objects}\n",
      "   698010    0.332    0.000    0.332    0.000 {method 'flatten' of 'numpy.ndarray' objects}\n",
      "    65578    0.029    0.000    0.029    0.000 {method 'format' of 'str' objects}\n",
      "     7350    0.007    0.000    0.007    0.000 {method 'from_buffer' of '_ctypes.PyCArrayType' objects}\n",
      " 69975428    3.897    0.000    3.897    0.000 {method 'get' of 'dict' objects}\n",
      "   131190    0.776    0.000    0.776    0.000 {method 'get_indexer' of 'pandas._libs.index.IndexEngine' objects}\n",
      " 11394547    2.042    0.000    2.042    0.000 {method 'get_loc' of 'pandas._libs.index.IndexEngine' objects}\n",
      "      315    0.006    0.000    0.008    0.000 {method 'get_slice' of 'pandas._libs.internals.BlockManager' objects}\n",
      "     2400    0.000    0.000    0.000    0.000 {method 'group' of 're.Match' objects}\n",
      "  1376550    0.407    0.000    0.407    0.000 {method 'has_reference' of 'pandas._libs.internals.BlockValuesRefs' objects}\n",
      "  5122292    0.502    0.000    0.502    0.000 {method 'insert' of 'list' objects}\n",
      " 24086480    1.506    0.000    1.506    0.000 {method 'isidentifier' of 'str' objects}\n",
      "      842    0.000    0.000    0.000    0.000 {method 'item' of 'numpy.ndarray' objects}\n",
      "  5432493    0.385    0.000    0.385    0.000 {method 'items' of 'dict' objects}\n",
      "    32010    0.005    0.000    0.005    0.000 {method 'items' of 'mappingproxy' objects}\n",
      "    61425    0.005    0.000    0.005    0.000 {method 'join' of 'str' objects}\n",
      "    54947    0.007    0.000    0.007    0.000 {method 'keys' of 'dict' objects}\n",
      "     3150    0.001    0.000    0.001    0.000 {method 'lower' of 'str' objects}\n",
      "    21000    0.020    0.000    0.020    0.000 {method 'match' of 're.Pattern' objects}\n",
      "  2928125    1.633    0.000    5.430    0.000 {method 'max' of 'numpy.ndarray' objects}\n",
      "     1860    0.001    0.000    0.025    0.000 {method 'mean' of 'numpy.ndarray' objects}\n",
      "    22367    0.029    0.000    0.029    0.000 {method 'nonzero' of 'numpy.ndarray' objects}\n",
      "      420    0.004    0.000    0.004    0.000 {method 'partition' of 'numpy.ndarray' objects}\n",
      "  4042500    0.343    0.000    0.343    0.000 {method 'partition' of 'str' objects}\n",
      "    26061    0.002    0.000    0.002    0.000 {method 'pop' of 'dict' objects}\n",
      "     8191    0.001    0.000    0.001    0.000 {method 'pop' of 'set' objects}\n",
      "   367500    1.192    0.000    1.292    0.000 {method 'predict' of 'sklearn.tree._tree.Tree' objects}\n",
      "   735000    2.093    0.000    3.981    0.000 {method 'randint' of 'numpy.random.mtrand.RandomState' objects}\n",
      "    55249    0.020    0.000    0.020    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "  9262951   12.449    0.000   12.449    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "  5121450    2.150    0.000    2.150    0.000 {method 'remove' of 'list' objects}\n",
      "     3150    0.006    0.000    0.006    0.000 {method 'repeat' of 'numpy.ndarray' objects}\n",
      "     4500    0.002    0.000    0.002    0.000 {method 'reset' of '_contextvars.ContextVar' objects}\n",
      "  4343522    1.426    0.000    1.426    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "  1934510    0.226    0.000    0.226    0.000 {method 'rpartition' of 'str' objects}\n",
      "      240    0.001    0.000    0.001    0.000 {method 'search' of 're.Pattern' objects}\n",
      "     8820    0.020    0.000    0.020    0.000 {method 'searchsorted' of 'numpy.ndarray' objects}\n",
      "     4500    0.003    0.000    0.003    0.000 {method 'set' of '_contextvars.ContextVar' objects}\n",
      "   379440    0.394    0.000    0.394    0.000 {method 'sort' of 'numpy.ndarray' objects}\n",
      "   695488    0.104    0.000    0.104    0.000 {method 'split' of 'str' objects}\n",
      "   287539    0.036    0.000    0.036    0.000 {method 'startswith' of 'bytes' objects}\n",
      "  4425495    0.383    0.000    0.383    0.000 {method 'startswith' of 'str' objects}\n",
      "     6300    0.003    0.000    0.003    0.000 {method 'strip' of 'bytes' objects}\n",
      "       22    0.000    0.000    0.000    0.000 {method 'strip' of 'str' objects}\n",
      "   657456    0.226    0.000    1.465    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
      "  3262259    1.633    0.000    1.633    0.000 {method 'take' of 'numpy.ndarray' objects}\n",
      "   194730    0.022    0.000    0.022    0.000 {method 'tobytes' of 'numpy.ndarray' objects}\n",
      "     9240    0.002    0.000    0.002    0.000 {method 'tolist' of 'numpy.ndarray' objects}\n",
      "    55469    0.015    0.000    0.015    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
      "      105    0.005    0.000    0.005    0.000 {method 'unique' of 'pandas._libs.hashtable.StringHashTable' objects}\n",
      "  1528155    0.154    0.000    0.154    0.000 {method 'update' of 'dict' objects}\n",
      "        7    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}\n",
      "    11762    0.002    0.000    0.002    0.000 {method 'values' of 'dict' objects}\n",
      "  1868345    0.191    0.000    0.191    0.000 {method 'values' of 'mappingproxy' objects}\n",
      "      102    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "  2841026    0.252    0.000    0.252    0.000 {pandas._libs.algos.ensure_object}\n",
      " 20715321    1.432    0.000    1.432    0.000 {pandas._libs.algos.ensure_platform_int}\n",
      "        3    0.000    0.000    0.000    0.000 {pandas._libs.algos.groupsort_indexer}\n",
      "  2709400    2.080    0.000    2.080    0.000 {pandas._libs.algos.take_1d_float64_float64}\n",
      "  3102793    2.532    0.000    2.532    0.000 {pandas._libs.algos.take_1d_int64_int64}\n",
      "    44015    0.065    0.000    0.065    0.000 {pandas._libs.algos.take_2d_axis0_float64_float64}\n",
      "   131460    0.111    0.000    0.111    0.000 {pandas._libs.algos.take_2d_axis0_int64_int64}\n",
      "    43910    0.039    0.000    0.039    0.000 {pandas._libs.algos.take_2d_axis0_object_object}\n",
      "  2774953    2.877    0.000    2.877    0.000 {pandas._libs.algos.take_2d_axis1_float64_float64}\n",
      "   174983    0.157    0.000    0.157    0.000 {pandas._libs.algos.take_2d_axis1_int64_int64}\n",
      "    21853    0.026    0.000    0.026    0.000 {pandas._libs.algos.take_2d_axis1_object_object}\n",
      "  1442250    0.382    0.000    0.382    0.000 {pandas._libs.internals.get_blkno_placements}\n",
      "      209    0.002    0.000    0.002    0.000 {pandas._libs.lib.array_equivalent_object}\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.dicts_to_array}\n",
      "    54638    0.066    0.000    0.066    0.000 {pandas._libs.lib.dtypes_all_equal}\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.fast_unique_multiple_list_gen}\n",
      "        3    0.000    0.000    0.000    0.000 {pandas._libs.lib.generate_slices}\n",
      "  5834257    9.392    0.000   16.411    0.000 {pandas._libs.lib.infer_dtype}\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_all_arraylike}\n",
      "    87445    0.016    0.000    0.016    0.000 {pandas._libs.lib.is_bool_list}\n",
      "  1486006    0.105    0.000    0.105    0.000 {pandas._libs.lib.is_bool}\n",
      " 14226097    1.001    0.000    1.001    0.000 {pandas._libs.lib.is_float}\n",
      " 18594424    1.372    0.000    1.372    0.000 {pandas._libs.lib.is_integer}\n",
      " 10162543    0.782    0.000    0.782    0.000 {pandas._libs.lib.is_iterator}\n",
      " 25453810    5.629    0.000    6.278    0.000 {pandas._libs.lib.is_list_like}\n",
      "  4616165    0.448    0.000    0.448    0.000 {pandas._libs.lib.is_scalar}\n",
      " 10118275    0.823    0.000    0.823    0.000 {pandas._libs.lib.item_from_zerodim}\n",
      "    32775    0.524    0.000    0.974    0.000 {pandas._libs.lib.map_infer}\n",
      "  5813104   11.410    0.000   21.805    0.000 {pandas._libs.lib.maybe_convert_objects}\n",
      "    32760    1.719    0.000    1.719    0.000 {pandas._libs.ops.scalar_compare}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "\n",
    "cProfile.run(\"main_pipeline(train_data_clean, test_data_clean, features, cv_folds, target_col='t_current')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6576151121605667"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1114/60) / (1694/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
