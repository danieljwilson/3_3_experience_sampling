{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61fb9a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42a5d05",
   "metadata": {},
   "source": [
    "### Variable Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5108426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Files of interest\n",
    "##    - HealthKitSamples\n",
    "##    - HealthKitActivitySummaries (not using for now)\n",
    "##    - AppleLocationVisits (not using for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e694beda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input Directory\n",
    "directory = \"../cumulative_data_811-910\"\n",
    "h_samples_path = \"../daily_data/RK.8D1DBFAD.DJW Thesis_20220626-20220627/HealthKitSamples_20220626-20220627.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c6018fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output Directory\n",
    "out_dir = \"../indv_table_exports/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28acb070",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Good Subjects\n",
    "good_subjects = ['01801252-3a7e-4f5f-8b6d-49e8da3902f3',\n",
    "                 'd26d4b78-7fcf-488e-b687-2d1c93c47b74',\n",
    "                 '531d7f6d-b880-4a0b-b467-80005a316f1c']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d3b2e4",
   "metadata": {},
   "source": [
    "### Some handy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0faf652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert time from UTC to ET\n",
    "def fix_date_to_ET(end_date):\n",
    "    if pd.to_datetime(end_date, format= '%Y-%m-%d', utc=True).tz_convert('US/Eastern').hour < 5:\n",
    "        return pd.to_datetime(end_date, format= '%Y-%m-%d', utc=True).tz_convert('US/Eastern').date() - datetime.timedelta(days=1)\n",
    "    else:\n",
    "        return pd.to_datetime(end_date, format= '%Y-%m-%d', utc=True).tz_convert('US/Eastern').date()\n",
    "\n",
    "def fix_columns_by_category(dataframe, categories):\n",
    "    df = dataframe\n",
    "    for item in categories:\n",
    "        if item not in df.columns.to_list():\n",
    "            df[item] = 'NaN'\n",
    "    return df\n",
    "\n",
    "def pivot_df(dataframe, pos: list, col, val):\n",
    "    df = dataframe\n",
    "    df = df.pivot_table(index=pos,\n",
    "                    columns=col, \n",
    "                    values=val).reset_index()\n",
    "    return df\n",
    "    \n",
    "def get_sleep_df(dataframe):\n",
    "    df_sleep = dataframe\n",
    "    df_sleep = df_sleep.loc[df_sleep.Type.isin(['SleepAnalysisInterval'])].reset_index(drop=True)\n",
    "\n",
    "    # Add date column\n",
    "    df_sleep['SleepDay'] = df_sleep.apply(lambda x: fix_date_to_ET(x.Date), axis=1)\n",
    "    \n",
    "    # Calculate and append sleep duration to df\n",
    "    # Will calculate the duration of each InBed and Asleep Value\n",
    "    df_sleep['Duration'] = 0\n",
    "    for i in range(len(df_sleep)):\n",
    "        m = datetime.datetime.fromisoformat(df_sleep.loc[0, 'Date'])\n",
    "        n = datetime.datetime.fromisoformat(df_sleep.loc[0, 'StartDate'])\n",
    "        df_sleep.loc[i, 'Duration'] = (m - n)/60;\n",
    "    \n",
    "    # Get sum for each value (InBed, Asleep) for each participant for each SLEEP day\n",
    "    df_sleep = pd.DataFrame(df_sleep.groupby(['SleepDay','ParticipantIdentifier', 'Value'])['Duration'].sum()).reset_index()\n",
    "    \n",
    "    # Make separate columns for InBed and Asleep values\n",
    "    indices = ['SleepDay', 'ParticipantIdentifier']\n",
    "    df_sleep = pivot_df(df_sleep, indices, \"Value\", \"Duration\")\n",
    "    \n",
    "    # Get rid of index name (set to \"Value\")\n",
    "    df_sleep.columns.name = None\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    df_sleep.rename(columns={'SleepDay': 'StudyDay','Asleep': 'Passive_Asleep','InBed' : 'Passive_InBed'}, inplace=True)\n",
    "    df_sleep = fix_columns_by_category(df_sleep, ['Passive_Asleep', 'Passive_InBed'])\n",
    "    \n",
    "    return df_sleep\n",
    "\n",
    "def get_heart_rate_df(dataframe, categories):\n",
    "    df = dataframe\n",
    "    df_heart = df.loc[df.Type.isin(categories)].reset_index(drop=True)\n",
    "\n",
    "    # cast Value to numeric\n",
    "    df_heart.Value = pd.to_numeric(df_heart.Value)\n",
    "\n",
    "    # Get mean for each type for each participant for each day\n",
    "    df_heart = pd.DataFrame(df_heart.groupby(['StudyDay','ParticipantIdentifier', 'Type'])['Value'].mean()).reset_index()\n",
    "\n",
    "    # Make separate columns for type of HeartRate data\n",
    "    indices = ['StudyDay', 'ParticipantIdentifier']\n",
    "    df_heart = pivot_df(df_heart, indices, 'Type', 'Value')\n",
    "    \n",
    "    # Fix column name\n",
    "    df_heart = fix_columns_by_category(df_heart, categories)\n",
    "\n",
    "    # Get rid of index name (set to \"Type\")\n",
    "    df_heart.columns.name = None\n",
    "\n",
    "    # Rename columns\n",
    "    df_heart.rename(columns={'HeartRateVariability': 'Passive_HeartRate_Variability',\n",
    "                       'RestingHeartRate' : 'Passive_HeartRate_Resting',\n",
    "                       'WalkingHeartRateAverage':'Passive_HeartRate_AverageWalking'\n",
    "                      }, inplace=True)\n",
    "    return df_heart\n",
    "    \n",
    "def get_activity_df(dataframe, mean_categories, sum_categories):\n",
    "    df = dataframe\n",
    "    \n",
    "    # Get activities that need to be summed, and those that need to be averaged in separate DataFrames\n",
    "    df_mean = df.loc[df.Type.isin(mean_categories)].reset_index(drop=True)\n",
    "    df_sum = df.loc[df.Type.isin(sum_categories)].reset_index(drop=True)\n",
    "    \n",
    "    # cast Value to numeric\n",
    "    df_mean.Value = pd.to_numeric(df_mean.Value)\n",
    "    df_sum.Value = pd.to_numeric(df_sum.Value)\n",
    "    \n",
    "    # Calculate sums and means\n",
    "    df_mean = pd.DataFrame(df_mean.groupby(['StudyDay','ParticipantIdentifier', 'Type'])['Value'].mean()).reset_index()\n",
    "    df_sum = pd.DataFrame(df_sum.groupby(['StudyDay','ParticipantIdentifier', 'Type'])['Value'].sum()).reset_index()\n",
    "    \n",
    "    # Pivot take according to activity categories\n",
    "    # Long to wide\n",
    "    indices = ['StudyDay', 'ParticipantIdentifier']\n",
    "    df_mean = pivot_df(df_mean, indices, 'Type', 'Value')\n",
    "    df_sum = pivot_df(df_sum, indices, 'Type', 'Value')\n",
    "    \n",
    "    # Accountfor missing columns\n",
    "    df_mean = fix_columns_by_category(df_mean, activity_mean_categories)\n",
    "    df_sum = fix_columns_by_category(df_sum, activity_sum_categories)\n",
    "    \n",
    "    # Rename columns\n",
    "    df_mean.rename(columns={'WalkingSpeed': 'Passive_Activity_AverageWalkingSpeed'\n",
    "                           }, inplace=True)\n",
    "    \n",
    "    df_sum.rename(columns={'ActiveEnergyBurned': 'Passive_Activity_ActiveEnergyBurned',\n",
    "                        'RestingEnergyBurned' : 'Passive_Activity_RestingEnergyBurned',\n",
    "                        'DistanceWalkingRunning' :'Passive_Activity_DistanceWalkingRunning',\n",
    "                        'DistanceCycling' : 'Passive_Activity_DistanceCycling',\n",
    "                        'AppleStandTime': 'Passive_Activity_AppleStandTime'\n",
    "                       }, inplace=True)\n",
    "    \n",
    "    df_activity = df_sum\n",
    "    df_activity = df_activity.merge(df_mean, how='left', on=['ParticipantIdentifier', 'StudyDay'])\n",
    "    return df_activity\n",
    "\n",
    "def get_other_df(dataframe, categories):\n",
    "    df = dataframe\n",
    "    df_other = df.loc[df.Type.isin(categories)].reset_index(drop=True)\n",
    "\n",
    "    # cast Value to float\n",
    "    df_other.Value = pd.to_numeric(df_other.Value)\n",
    "\n",
    "    # Get mean for each type for each participant for each day\n",
    "    df_other = pd.DataFrame(df_other.groupby(['StudyDay','ParticipantIdentifier', 'Type'])['Value'].mean()).reset_index()\n",
    "\n",
    "    # convert from long to wide\n",
    "    df_other = pivot_df(df_other, ['StudyDay', 'ParticipantIdentifier'], 'Type', 'Value')\n",
    "    \n",
    "    df_other = fix_columns_by_category(df_other, categories)\n",
    "\n",
    "    # Get rid of index name (set to \"Type\")\n",
    "    df_other.columns.name = None\n",
    "\n",
    "    # Rename columns\n",
    "    df_other.rename(columns={'HeadphoneAudioExposure': 'Passive_Audio_HeadphoneExposure',\n",
    "                       'EnvironmentalAudioExposure' : 'Passive_Audio_EnvironmentalExposure',\n",
    "                      }, inplace=True)\n",
    "    return df_other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f437beef",
   "metadata": {},
   "source": [
    "###  Make HealthKitSamples Dataframe for all results till today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bebd7c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make HealthKitSamples Dataframe for all results till today\n",
    "\n",
    "survey_file_name = \"\"\n",
    "path = directory + \"/\"\n",
    "for f_name in os.listdir(path):\n",
    "    if f_name.startswith(\"HealthKitSamples\"):\n",
    "        survey_file_name = f_name\n",
    "        break\n",
    "path = path + '/' + survey_file_name\n",
    "\n",
    "current_df = pd.read_csv(path) \n",
    "current_df[\"StudyDay\"] = current_df.apply(lambda x: fix_date_to_ET(x.Date), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3037e02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## From here we need to get Sleep Data, HeartRate Data, Activity Data, Other Data\n",
    "df_samples = current_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4983b9d7",
   "metadata": {},
   "source": [
    "### Get Sleep, Heart, Activity, and Other Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c80adee3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fix_date_to_ET() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/57/9mrlx9kx6xsfb5tsnbtdb9d40000gn/T/ipykernel_86110/1332166379.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get sleep data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_sleep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sleep_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Get heart data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mheart_categories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"RestingHeartRate\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"WalkingHeartRateAverage\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HeartRateVariability\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/57/9mrlx9kx6xsfb5tsnbtdb9d40000gn/T/ipykernel_86110/1139121188.py\u001b[0m in \u001b[0;36mget_sleep_df\u001b[0;34m(dataframe)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Add date column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mdf_sleep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix_date_to_ET\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_sleep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SleepDay'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Calculate and append sleep duration to df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fix_date_to_ET() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# Get sleep data\n",
    "df_sleep = get_sleep_df(df_samples)\n",
    "\n",
    "# Get heart data\n",
    "heart_categories = [\"RestingHeartRate\", \"WalkingHeartRateAverage\", \"HeartRateVariability\"]\n",
    "df_heart = get_heart_rate_df(df_samples, heart_categories)\n",
    "\n",
    "# Get activity data\n",
    "activity_mean_categories = ['WalkingSpeed']\n",
    "activity_sum_categories = ['ActiveEnergyBurned', 'RestingEnergyBurned', 'DistanceWalkingRunning',\n",
    "                  'DistanceCycling', 'AppleStandTime']\n",
    "df_activity = get_activity_df(df_samples, activity_mean_categories, activity_sum_categories)\n",
    "\n",
    "# Get other data\n",
    "other_data_categories = ['HeadphoneAudioExposure', 'EnvironmentalAudioExposure']\n",
    "df_other = get_other_df(df_samples, other_data_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e19923",
   "metadata": {},
   "source": [
    "### Participant List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83e12320",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/57/9mrlx9kx6xsfb5tsnbtdb9d40000gn/T/ipykernel_86110/2029461375.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_participants\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/StudyParticipants_20220910.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_participants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CustomFields\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_participants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CustomFields\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mparticipant_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_participants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "df_participants = pd.read_csv(directory + '/StudyParticipants_20220910.csv')\n",
    "df_participants[\"CustomFields\"] = df_participants[\"CustomFields\"].apply(json.loads)\n",
    "\n",
    "participant_list = []\n",
    "for index, row in df_participants.iterrows():\n",
    "    if row[\"CustomFields\"][\"exp_version\"] == \"app_pilot_1\":\n",
    "        participant_list.append(row[\"ParticipantIdentifier\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a85e3aa",
   "metadata": {},
   "source": [
    "### Merge the 4 dataframes to get Passive Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed2114cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the 4 Data Frames\n",
    "df_passive = df_sleep\n",
    "df_passive = df_passive.merge(df_heart, how='left', on=['ParticipantIdentifier', 'StudyDay'])\n",
    "df_passive = df_passive.merge(df_activity, how='left', on=['ParticipantIdentifier', 'StudyDay'])\n",
    "df_passive = df_passive.merge(df_other, how='left', on=['ParticipantIdentifier', 'StudyDay'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a178e3b1",
   "metadata": {},
   "source": [
    "### Keep data of good subjects and export passive Dataframe as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7f51da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep data for the good participants\n",
    "df = df_passive\n",
    "df_passive_good = df[df.ParticipantIdentifier.isin(good_subjects)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "902afa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export CSV File\n",
    "df_passive_good.to_csv('passive.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5999fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################Just Testing###########################################\n",
    "# df_sleep_good\n",
    "df = df_sleep\n",
    "df_sleep_good = df[df.ParticipantIdentifier.isin(good_subjects)].reset_index(drop=True)\n",
    "\n",
    "# df_heart_good\n",
    "# No data for one of the good participants\n",
    "df = df_heart\n",
    "df_heart_good = df[df.ParticipantIdentifier.isin(good_subjects)].reset_index(drop=True)\n",
    "\n",
    "# df_activity_good\n",
    "df = df_activity\n",
    "df_activity_good = df[df.ParticipantIdentifier.isin(good_subjects)].reset_index(drop=True)\n",
    "\n",
    "# df_other_good\n",
    "df = df_other\n",
    "df_other_good = df[df.ParticipantIdentifier.isin(good_subjects)].reset_index(drop=True) \n",
    "####################################Just Testing###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80021eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
