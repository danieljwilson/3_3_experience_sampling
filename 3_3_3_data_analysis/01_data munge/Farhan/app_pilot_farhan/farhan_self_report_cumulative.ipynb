{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bead6fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import datetime\n",
    "import json\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b17dc77",
   "metadata": {},
   "source": [
    "### Variable Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b613dd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concerned with survey_question_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "65aa083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input Directory\n",
    "directory = \"../cumulative_data_811-910\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "18634ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output Directory\n",
    "out_dir = \"../indv_table_exports/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "70e5abf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Good Participants\n",
    "good_subjects = ['01801252-3a7e-4f5f-8b6d-49e8da3902f3',\n",
    "                 'd26d4b78-7fcf-488e-b687-2d1c93c47b74',\n",
    "                 '531d7f6d-b880-4a0b-b467-80005a316f1c']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e321e21c",
   "metadata": {},
   "source": [
    "### Some handy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "202ac802",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to fix date from UTC to ET\n",
    "def fix_date_to_ET(end_date):\n",
    "    if pd.to_datetime(end_date, format= '%Y-%m-%d', utc=True).tz_convert('US/Eastern').hour < 5:\n",
    "        return pd.to_datetime(end_date, format= '%Y-%m-%d', utc=True).tz_convert('US/Eastern').date() - datetime.timedelta(days=1)\n",
    "    else:\n",
    "        return pd.to_datetime(end_date, format= '%Y-%m-%d', utc=True).tz_convert('US/Eastern').date()\n",
    "            \n",
    "def fix_columns_by_category(dataframe, categories):\n",
    "    df = dataframe\n",
    "    for item in categories:\n",
    "        if item not in df.columns.to_list():\n",
    "            df[item] = 'NaN'\n",
    "    return df\n",
    "\n",
    "def pivot_df(dataframe, pos: list, col, val):\n",
    "    df = dataframe\n",
    "    df = df.pivot_table(index=pos,\n",
    "                    columns=col, \n",
    "                    values=val).reset_index()\n",
    "    return df\n",
    "\n",
    "def get_time_diff(d2, d1):\n",
    "    return (d2 - d1).days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141c8f6a",
   "metadata": {},
   "source": [
    "### Dataframe Construction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3fb871b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to extract Affect scores\n",
    "def get_affect_df(dataframe):\n",
    "    df = dataframe\n",
    "    df_affect = df.loc[df.ResultIdentifier.str.startswith('affect_'), :]\n",
    "    df_affect = df_affect[['ParticipantIdentifier', 'ResultIdentifier', 'Answers', 'StudyDay']]\n",
    "    \n",
    "    # cast Value to numeric\n",
    "    df_affect.Answers = pd.to_numeric(df_affect.Answers)\n",
    "\n",
    "    # Make separate columns for each affect score\n",
    "    # Convert from long to wide\n",
    "    indices = ['StudyDay', 'ParticipantIdentifier']\n",
    "    df_affect = pivot_df(df_affect, indices, 'ResultIdentifier', 'Answers')\n",
    "    \n",
    "    # Add columns that may not have been present in given dataset\n",
    "    indices = ['affect_neg_angry', 'affect_neg_ashamed', 'affect_neg_bored', 'affect_neg_depressed', \n",
    "               'affect_neg_embarrassed', 'affect_neg_frustrated', 'affect_neg_guilty', 'affect_neg_lazy',\n",
    "               'affect_neg_lonelyIsolated', 'affect_neg_nervousAnxious', 'affect_neg_sad', 'affect_neg_stressed',\n",
    "               'affect_pos_amused', 'affect_pos_appreciated', 'affect_pos_excited', 'affect_pos_focused', \n",
    "               'affect_pos_happy', 'affect_pos_hopeful', 'affect_pos_motivated', 'affect_pos_relaxedCalm']\n",
    "    df_affect = fix_columns_by_category(df_affect, indices)\n",
    "    \n",
    "    # Rename columns (add prefix SR for self report)\n",
    "    keep_same = {'StudyDay', 'ParticipantIdentifier'}\n",
    "    df_affect.columns = ['SR_' + str(col) if col not in keep_same else col for col in df_affect.columns]\n",
    "\n",
    "    return df_affect\n",
    "\n",
    "## Function to get goal, past24, next24 dataframe\n",
    "def get_goals_df(survey_dataframe):\n",
    "    df_survey = survey_dataframe\n",
    "    df = df_survey.loc[df_survey.ResultIdentifier.str.startswith('DAILY_'), :]\n",
    "    df = df[['ParticipantIdentifier', 'ResultIdentifier', 'Answers', 'StudyDay']].reset_index()\n",
    "\n",
    "    ## Drop duplicate rows # This is hacky ## Show this to daniel ## Date conversion problem\n",
    "    df = df.drop_duplicates(subset=['ParticipantIdentifier', 'ResultIdentifier', 'StudyDay'], keep=\"first\")\n",
    "    \n",
    "    ## Make columns for each measure found in the ResultIdentifier column\n",
    "    indices = ['StudyDay', 'ParticipantIdentifier']\n",
    "    df = df.pivot_table(index=indices,\n",
    "                        columns='ResultIdentifier', \n",
    "                        values='Answers',\n",
    "                        aggfunc=lambda x: ' '.join(x)).reset_index()\n",
    "    \n",
    "    ## Dataframe containing goals\n",
    "    df_goals = df\n",
    "    \n",
    "    ## Extract dfs of only past24 and next24 data\n",
    "    past_24_col = [col for col in df_goals if (col.startswith('DAILY_past24') or col in indices)]\n",
    "    next_24_col = [col for col in df_goals if (col.startswith('DAILY_next24') or col in indices)]\n",
    "\n",
    "    df_past24 = df[past_24_col]\n",
    "    df_next24 = df[next_24_col]\n",
    "    \n",
    "    return df_goals, df_past24, df_next24\n",
    "\n",
    "## Function to calculate gap for one participant\n",
    "def get_participant_gap_df(df_next24i, df_past24i):\n",
    "    ## This will store the final gap df\n",
    "    df_gap = []\n",
    "    \n",
    "    ## List of some important column names\n",
    "    ## Will prove useful during iterations\n",
    "    gap_cols = ['drinks', 'exercise', 'leisureNonSolo', 'leisureSolo', 'nonoccupation', \n",
    "                'occupation', 'sleep', 'socialMedia']\n",
    "    next_cols = ['DAILY_next24_drinks', 'DAILY_next24_exercise', 'DAILY_next24_leisureNonSolo', 'DAILY_next24_leisureSolo',\n",
    "                       'DAILY_next24_nonoccupation', 'DAILY_next24_occupation', 'DAILY_next24_sleep', 'DAILY_next24_socialMedia']\n",
    "    past_cols = ['DAILY_past24_drinks', 'DAILY_past24_exercise', 'DAILY_past24_leisureNonSolo', 'DAILY_past24_leisureSolo',\n",
    "                       'DAILY_past24_nonoccupation', 'DAILY_past24_occupation', 'DAILY_past24_sleep', 'DAILY_past24_socialMedia']                   \n",
    "\n",
    "    \n",
    "    ## Input dataframes\n",
    "    df_next24 = df_next24i\n",
    "    df_past24 = df_past24i\n",
    "    \n",
    "    ## Loop over each row in df_next24\n",
    "    for i in range(len(df_next24)):\n",
    "        \n",
    "        ## This will hold gap results for one row\n",
    "        row_gap_dict = {}\n",
    "\n",
    "        ## Append participant ID and StudyDay\n",
    "        row_gap_dict['StudyDay'] = df_next24.at[i, 'StudyDay']\n",
    "        row_gap_dict['ParticipantIdentifier'] = df_next24.at[i, 'ParticipantIdentifier']\n",
    "\n",
    "        for item in gap_cols:\n",
    "\n",
    "            if i == 0:\n",
    "                ## There is no previous day for gap to be calculated\n",
    "                row_gap_dict[item + '_gap'] = 'NaN'\n",
    "                \n",
    "            elif df_next24.at[i, next_cols[gap_cols.index(item)] + '_goal'] == 'False':\n",
    "                ## This was not set as a goal\n",
    "                row_gap_dict[item + '_gap'] = 'NaN'\n",
    "                \n",
    "            else:\n",
    "\n",
    "                ## get the date of the previous row in past24 dataframe\n",
    "                past_row_date = df_past24.at[i - 1, 'StudyDay']\n",
    "\n",
    "                ## Get current row date of the next24 dataframe\n",
    "                current_date = df_next24.at[i, 'StudyDay']\n",
    "\n",
    "                ## Calculate time difference in days\n",
    "                delta = get_time_diff(current_date, past_row_date)\n",
    "\n",
    "                ## If the previous day does not exist, gap is NaN\n",
    "                if delta != 1:\n",
    "                    row_gap_dict[item + '_gap'] = 'NaN'\n",
    "                else:\n",
    "                    ## Calculate gap as required information exists\n",
    "                    today = float(df_next24.at[i, next_cols[gap_cols.index(item)]])\n",
    "                    yesterday = float(df_past24.at[i - 1, past_cols[gap_cols.index(item)]])\n",
    "                    gap = yesterday - today\n",
    "                    row_gap_dict[item + '_gap'] = gap\n",
    "\n",
    "        df_gap.append(row_gap_dict)\n",
    "    df_gap = pd.DataFrame(df_gap)\n",
    "    return df_gap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0971c551",
   "metadata": {},
   "source": [
    "### Got all SurveyQuestionResults till date in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "437a2e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Got all SurveyQuestionResults till date in a dataframe\n",
    "\n",
    "survey_file_name = \"\"\n",
    "path = directory + \"/\"\n",
    "for f_name in os.listdir(path):\n",
    "    if f_name.startswith(\"SurveyQuestionResults\"):\n",
    "        survey_file_name = f_name\n",
    "        break\n",
    "path = path + '/' + survey_file_name\n",
    "\n",
    "current_df = pd.read_csv(path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c52b35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_df[\"StudyDay\"] = current_df.apply(lambda x: fix_date_to_ET(x.EndDate), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4a60b164",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_survey = current_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1743fe92",
   "metadata": {},
   "source": [
    "### Construct the Affect and Goals dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "93466abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Got Affect Dataframe\n",
    "df_affect = get_affect_df(df_survey)\n",
    "\n",
    "## Get goals, past24, and next_24 Dataframes\n",
    "df_goals, df_past24, df_next24 = get_goals_df(df_survey)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d12813",
   "metadata": {},
   "source": [
    "### Participant List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3a755176",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_participants = pd.read_csv(directory + '/StudyParticipants_20220910.csv')\n",
    "df_participants[\"CustomFields\"] = df_participants[\"CustomFields\"].apply(json.loads)\n",
    "\n",
    "participant_list = []\n",
    "for index, row in df_participants.iterrows():\n",
    "    if row[\"CustomFields\"][\"exp_version\"] == \"app_pilot_1\":\n",
    "        participant_list.append(row[\"ParticipantIdentifier\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5ab02f",
   "metadata": {},
   "source": [
    "### Construct the gap Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cc4777ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Will get this by concatenating gap dataframes from each good participant\n",
    "df_gap_list = []\n",
    "good_subjects = participant_list\n",
    "for item in good_subjects:\n",
    "    df_past24_temp = df_past24[df_past24.ParticipantIdentifier.isin([item])].reset_index(drop=True)\n",
    "    df_next24_temp = df_next24[df_next24.ParticipantIdentifier.isin([item])].reset_index(drop=True)\n",
    "    current_participant_df_gap = get_participant_gap_df(df_next24_temp, df_past24_temp)\n",
    "    \n",
    "    df_gap_list.append(current_participant_df_gap)\n",
    "\n",
    "df_gap = pd.concat(df_gap_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b98e62",
   "metadata": {},
   "source": [
    "### Combine the three dataframes to make SR Dataframe and Export CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7a8ae009",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge df_goals, df_affect, and df_gap Dataframes\n",
    "df_self_report = df_affect\n",
    "df_self_report = df_self_report.merge(df_affect, how='left', on=['ParticipantIdentifier', 'StudyDay'])\n",
    "df_self_report = df_self_report.merge(df_gap, how='left', on=['ParticipantIdentifier', 'StudyDay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3954f892",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export the self-report Dataframe as a CSV\n",
    "df_self_report.to_csv('self_report.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301420c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
