{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is being pulled automatically from RKStudio server and then saved to `3_3_2_processed_data` folder.\n",
    "\n",
    "\n",
    "**PROCESS**\n",
    "1. `launchd` runs the `.plist` file `/Library/LaunchAgents/thesis.djw.pull-rkstudio-data.plist` every day at 10:40am\n",
    "2. `thesis.djw.pull-rkstudio-data.plist` runs `.sh` script `/download/download_rkstudio_data.sh`\n",
    "3. `download_rkstudio_data.sh` runs `.py` script `/download/download_rkstudio_data.py`\n",
    "4. `download_rkstudio_data.py` downloads any **new** files from RK Studio, and saves to `.pkl` in `3_3_2_processed_data` folder.\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** \n",
    "- The `create_dict_df()` function in `download_rkstudio_data.py` is inefficient as it recreates the file from scratch each time it runs instead of just appending new data. If things get slow this could be a spot to address.\n",
    "- The `create_dict_df()` function is also simply replacing previous file with current file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/3_3_2_processed_data/\"\n",
    "\n",
    "in_file = open(save_path + \"app_data.pkl\", \"rb\")\n",
    "app_data = pickle.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to RKStudio exported data\n",
    "file_path = \"/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/3_3_1_raw_data/testing\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something wierd happened where we started getting additional files named like:\n",
    "\n",
    "`SurveyData/01801252-3a7e-4f5f-8b6d-49e8da3902f3/0b3181d1-4bb8-eb11-aaaa-0afb9334277d/reactionTime/DeviceMotion`\n",
    "\n",
    "These seemed perhaps to be `.json`? For example:\n",
    "\n",
    "```\n",
    "Index(['{\"items\":[{\"attitude\":{\"y\":-0.015030415521581996032',\n",
    "       'w:0.9316986828576702464', 'z:0.00000000000000011102230246251565056',\n",
    "       'x:0.362920855519224064}', 'timestamp:3568168.594124125184',\n",
    "       'rotationRate:{\"x\":0.03503423929214477312', 'y:-0.04006228968501091328',\n",
    "       'z:0.0013012606650590896128}',\n",
    "       'userAcceleration:{\"x\":-0.002143738791346550016',\n",
    "       'y:-0.0015905499458312988672',\n",
    "       ...\n",
    "       'z:-0.4993825852870940672}',\n",
    "       'userAcceleration:{\"x\":-0.2922154068946837504',\n",
    "       'y:0.2403054237365722112', 'z:-0.389307737350464}',\n",
    "       'gravity:{\"x\":0.09684188663959502848', 'y:-0.7316384911537170432',\n",
    "       'z:-0.6747791767120361472}', 'magneticField:{\"y\":0.884', 'z:0.885',\n",
    "       'x:0.884'],\n",
    "      dtype='object', length=30590)\n",
    "```\n",
    "\n",
    "I am assuming this is an error and there isn't anything meaningful here (we already have a score for the **Reaction Time** task), so am removing from the `app_data` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_dict(file_path, save_path):\n",
    "    # createstartswithty dictionary\n",
    "    app_data = {}\n",
    "\n",
    "    # create list of zip files\n",
    "    data_files = glob.glob(f'{file_path}/*.zip')\n",
    "    data_files.sort(reverse=True)\n",
    "    # move the first entry to the end as it has slighlty different syntax\n",
    "    data_files = data_files[1:]+data_files[0:1]\n",
    "\n",
    "    # extract all csv files from zip\n",
    "    for zip_file in data_files:\n",
    "        zf = zipfile.ZipFile(zip_file)\n",
    "\n",
    "        # list of .csv files in zip\n",
    "        file_names = zf.namelist()\n",
    "\n",
    "        # loop through .csv files\n",
    "        for file in file_names:\n",
    "                # added because there seemed to be some weird files being included\n",
    "                if not file.startswith('SurveyData/'):\n",
    "                    try:\n",
    "                        df = pd.read_csv(zf.open(file), parse_dates=True, low_memory=False)\n",
    "                        # clean up filename to use as key\n",
    "                        sep = '_'\n",
    "                        file = file.replace('.', '_')\n",
    "                        file = file.split(sep,1)[0]\n",
    "\n",
    "                    # some files are sometimes empty (e.g. notifications)\n",
    "                    except pd.errors.EmptyDataError:\n",
    "                        continue # will skip the rest of the block and move to next file\n",
    "\n",
    "                    # append each day to df\n",
    "                    try:\n",
    "                        app_data[file] = app_data[file].append(df, ignore_index=True)\n",
    "                    except KeyError:\n",
    "                        app_data[file] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_data = create_df_dict(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/3_3_2_processed_data/\"\n",
    "\n",
    "out_file = open(save_path + \"app_data.pkl\", \"wb\")\n",
    "pickle.dump(app_data, out_file)\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = open(save_path + \"app_data.pkl\", \"rb\")\n",
    "app_data = pickle.load(in_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
