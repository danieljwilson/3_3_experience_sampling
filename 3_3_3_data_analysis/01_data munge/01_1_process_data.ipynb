{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import datetime\n",
    "from dateutil import parser\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set run\n",
    "run_num = 2\n",
    "\n",
    "if run_num ==1:\n",
    "    # run 1\n",
    "    path = '/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/3_3_1_raw_data/run_1/app_data/'\n",
    "    save_path = '/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/3_3_2_processed_data/run_1/'\n",
    "    subjects_run1 = pd.read_csv(path + '../run1_subjects.csv')\n",
    "    subjects = subjects_run1.ParticipantIdentifier\n",
    "elif run_num ==2:\n",
    "    # run 2\n",
    "    path = '/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/3_3_1_raw_data/run_2/app_data/'\n",
    "    save_path = '/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/3_3_2_processed_data/run_2/'\n",
    "    subjects_run2 = pd.read_csv(path + '../run2_subjects.csv')\n",
    "    subjects = subjects_run2.ParticipantIdentifier\n",
    "    \n",
    "eda_reports_path = '/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/3_3_4_outputs/EDA/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erase df if it already exists\n",
    "if 'df' in globals():\n",
    "    del(df)\n",
    "    print('deleted existing df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:05<00:00, 10.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# loop through all days\n",
    "days = [i for i in os.listdir(path) if i.startswith('RK')]\n",
    "for day in tqdm(days):\n",
    "    files = os.listdir(path + day)\n",
    "    surveyQuestions = [i for i in files if i.startswith('SurveyQuestionResults')]\n",
    "    # there should be only one\n",
    "    for file in surveyQuestions:\n",
    "        if 'df' not in globals():\n",
    "            df = pd.read_csv(path + day + '/' + file)\n",
    "        else:\n",
    "            temp_df = pd.read_csv(path + day + '/' + file)\n",
    "            df = pd.concat([df,temp_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1124570, 8)"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>ResultIdentifier</th>\n",
       "      <th>Answers</th>\n",
       "      <th>EndDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5599c2a7-88a5-4cde-9f2a-41b4bd03d660</td>\n",
       "      <td>current_situation1_tasks</td>\n",
       "      <td>in_public</td>\n",
       "      <td>2023-04-06T07:15:45-04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5599c2a7-88a5-4cde-9f2a-41b4bd03d660</td>\n",
       "      <td>current_situation2_tasks</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-04-06T07:15:46-04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5599c2a7-88a5-4cde-9f2a-41b4bd03d660</td>\n",
       "      <td>task_motivation</td>\n",
       "      <td>10</td>\n",
       "      <td>2023-04-06T07:15:48-04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5599c2a7-88a5-4cde-9f2a-41b4bd03d660</td>\n",
       "      <td>affect_neg_frustrated_am</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-04-06T07:15:58-04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5599c2a7-88a5-4cde-9f2a-41b4bd03d660</td>\n",
       "      <td>affect_pos_relaxedCalm_am</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-04-06T07:16:01-04:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ParticipantIdentifier           ResultIdentifier    Answers  \\\n",
       "0  5599c2a7-88a5-4cde-9f2a-41b4bd03d660   current_situation1_tasks  in_public   \n",
       "1  5599c2a7-88a5-4cde-9f2a-41b4bd03d660   current_situation2_tasks      False   \n",
       "2  5599c2a7-88a5-4cde-9f2a-41b4bd03d660            task_motivation         10   \n",
       "3  5599c2a7-88a5-4cde-9f2a-41b4bd03d660   affect_neg_frustrated_am          1   \n",
       "4  5599c2a7-88a5-4cde-9f2a-41b4bd03d660  affect_pos_relaxedCalm_am          4   \n",
       "\n",
       "                     EndDate  \n",
       "0  2023-04-06T07:15:45-04:00  \n",
       "1  2023-04-06T07:15:46-04:00  \n",
       "2  2023-04-06T07:15:48-04:00  \n",
       "3  2023-04-06T07:15:58-04:00  \n",
       "4  2023-04-06T07:16:01-04:00  "
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select relevant columns\n",
    "df = df[['ParticipantIdentifier', 'ResultIdentifier', 'Answers', 'EndDate']]\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParticipantIdentifier     0\n",
       "ResultIdentifier          0\n",
       "Answers                  37\n",
       "EndDate                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows without valid EndDate value\n",
    "df = df.dropna(subset=['EndDate']).reset_index(drop=True)\n",
    "\n",
    "# Select relevant subjects\n",
    "df = df.loc[df.ParticipantIdentifier.isin(subjects)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1104412/1104412 [02:01<00:00, 9122.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# add trial date and time columns\n",
    "for i in tqdm(range(df.shape[0])):\n",
    "    dt = parser.parse(df.loc[i, 'EndDate'])\n",
    "    df.loc[i, 'datetime'] = dt\n",
    "    df.loc[i, 'trial_date'] = (dt + datetime.timedelta(hours = -4.75)).date() # trial day associated with sample (4:45am is when the day flips)\n",
    "    df.loc[i, 'time'] = dt.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "if run_num ==1:\n",
    "    # run 1\n",
    "    df.to_csv(save_path + 'run1_survey_results.csv', index=False)\n",
    "if run_num ==2:\n",
    "    # run 2\n",
    "    df.to_csv(save_path + 'run2_survey_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gap App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted existing df\n",
      "deleted affect df\n"
     ]
    }
   ],
   "source": [
    "# erase df if it already exists\n",
    "if 'df' in globals():\n",
    "    del(df)\n",
    "    print('deleted existing df')\n",
    "\n",
    "if 'df_daily_affect_wide' in globals():\n",
    "    del(df_daily_affect_wide)\n",
    "    print('deleted affect df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_num ==1:\n",
    "    # run 1\n",
    "    df = pd.read_csv(save_path + 'run1_survey_results.csv')\n",
    "if run_num ==2:\n",
    "    # run 2\n",
    "    df = pd.read_csv(save_path + 'run2_survey_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_affect = df.loc[df.ResultIdentifier.str.startswith('affect_')].reset_index(drop=True)\n",
    "df_affect_am = df.loc[(df.ResultIdentifier.str.startswith('affect_')) & (df.ResultIdentifier.str.endswith('am'))].reset_index(drop=True)\n",
    "df_affect_pm = df.loc[(df.ResultIdentifier.str.startswith('affect_')) & (~df.ResultIdentifier.str.endswith('am'))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to Wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_affect_pm_wide = df_affect_pm.pivot_table(index=[\"ParticipantIdentifier\", \"trial_date\"], \n",
    "                    columns='ResultIdentifier', \n",
    "                    values='Answers').reset_index()\n",
    "# get rid of name on index\n",
    "df_affect_pm_wide = df_affect_pm_wide.rename_axis(None, axis=1)\n",
    "\n",
    "df_affect_am_wide = df_affect_am.pivot_table(index=[\"ParticipantIdentifier\", \"trial_date\"], \n",
    "                    columns='ResultIdentifier', \n",
    "                    values='Answers').reset_index()\n",
    "# get rid of name on index\n",
    "df_affect_am_wide = df_affect_am_wide.rename_axis(None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>affect_neg_angry</th>\n",
       "      <th>affect_neg_ashamed</th>\n",
       "      <th>affect_neg_bored</th>\n",
       "      <th>affect_neg_depressed</th>\n",
       "      <th>affect_neg_embarrassed</th>\n",
       "      <th>affect_neg_frustrated</th>\n",
       "      <th>affect_neg_guilty</th>\n",
       "      <th>affect_neg_lazy</th>\n",
       "      <th>...</th>\n",
       "      <th>affect_neg_sad_am</th>\n",
       "      <th>affect_neg_stressed_am</th>\n",
       "      <th>affect_pos_amused_am</th>\n",
       "      <th>affect_pos_appreciated_am</th>\n",
       "      <th>affect_pos_excited_am</th>\n",
       "      <th>affect_pos_focused_am</th>\n",
       "      <th>affect_pos_happy_am</th>\n",
       "      <th>affect_pos_hopeful_am</th>\n",
       "      <th>affect_pos_motivated_am</th>\n",
       "      <th>affect_pos_relaxedCalm_am</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-01-30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ParticipantIdentifier  trial_date affect_neg_angry  \\\n",
       "0  0151d9f1-1644-4437-805e-02f5e244a690  2023-01-30              2.0   \n",
       "1  0151d9f1-1644-4437-805e-02f5e244a690  2023-01-31              2.0   \n",
       "2  0151d9f1-1644-4437-805e-02f5e244a690  2023-02-01              1.0   \n",
       "\n",
       "  affect_neg_ashamed affect_neg_bored affect_neg_depressed  \\\n",
       "0                1.0              2.0                  1.0   \n",
       "1                1.0              1.0                  1.0   \n",
       "2                3.0              3.0                  3.0   \n",
       "\n",
       "  affect_neg_embarrassed affect_neg_frustrated affect_neg_guilty  \\\n",
       "0                    1.0                   1.0               1.0   \n",
       "1                    1.0                   1.0               1.0   \n",
       "2                    3.0                   1.0               1.0   \n",
       "\n",
       "  affect_neg_lazy  ... affect_neg_sad_am affect_neg_stressed_am  \\\n",
       "0             2.0  ...               1.0                    4.0   \n",
       "1             1.0  ...               1.0                    4.0   \n",
       "2             2.0  ...               1.0                    2.0   \n",
       "\n",
       "  affect_pos_amused_am affect_pos_appreciated_am affect_pos_excited_am  \\\n",
       "0                  4.0                       4.0                   3.0   \n",
       "1                  2.0                       3.0                   3.0   \n",
       "2                  1.0                       3.0                   1.0   \n",
       "\n",
       "  affect_pos_focused_am affect_pos_happy_am affect_pos_hopeful_am  \\\n",
       "0                   3.0                 3.0                   4.0   \n",
       "1                   3.0                 3.0                   3.0   \n",
       "2                   3.0                 3.0                   3.0   \n",
       "\n",
       "  affect_pos_motivated_am affect_pos_relaxedCalm_am  \n",
       "0                     3.0                       4.0  \n",
       "1                     2.0                       4.0  \n",
       "2                     3.0                       2.0  \n",
       "\n",
       "[3 rows x 42 columns]"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join\n",
    "df_daily_affect_wide = df_affect_pm_wide.merge(df_affect_am_wide, how='left', on=['ParticipantIdentifier', 'trial_date'])\n",
    "\n",
    "df_daily_affect_wide.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset:   2%|▏         | 1/45 [00:00<00:01, 29.53it/s, Describe variable:affect_neg_ashamed]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 450/450 [00:21<00:00, 20.49it/s, Completed]                                                   \n",
      "Generate report structure: 100%|██████████| 1/1 [00:03<00:00,  3.91s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:03<00:00,  3.37s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 60.93it/s]\n"
     ]
    }
   ],
   "source": [
    "profile = ProfileReport(df_daily_affect_wide.iloc[:,2:], title=f\"Affect Run {run_num} | Pandas Profiling Report\")\n",
    "profile.to_file(eda_reports_path + f\"affect_report_run{run_num}.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**\n",
    "\n",
    "There are a number of variables where the maximum values are well above 5, which is the maximum option that should be available. These glitch entries should be removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>🧹 Process:</b><br>\n",
    "For our cleaning process we do the following:<br><br>\n",
    "\n",
    "<ol>\n",
    "    <li>Remove values greater than 5, given that the Likert scale only went to 5</li>\n",
    "    <br>\n",
    "    <li>Look for zero variance <b>columns</b> (affective measures) and <b>rows</b> (days) for subjects</li></h5>\n",
    "    <br>\n",
    "    👉 If the variance was zero for three or more columns then the subject was flagged (`affect_zeroVarCols_flag = True`)<br>\n",
    "    <br>\n",
    "    👉 If the variance was zero for more than 10% of a subjects completed days then the subject was flagged (`affect_zeroVarRows_flag = True`)\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Impossible Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of instances where the cell value is out of range (greater than 5)\n",
    "df_daily_affect_wide.iloc[:,2:][df_daily_affect_wide.iloc[:,2:] > 5].count().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all values below threshold with NaN\n",
    "df_daily_affect_wide.iloc[:,2:] = np.where(df_daily_affect_wide.iloc[:,2:]>5, np.nan, df_daily_affect_wide.iloc[:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recheck for instances above 5\n",
    "df_daily_affect_wide.iloc[:,2:][df_daily_affect_wide.iloc[:,2:] > 5].count().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 1650/1650 [01:36<00:00, 17.13it/s, Completed]                                                         \n",
      "Generate report structure: 100%|██████████| 1/1 [00:04<00:00,  4.23s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:12<00:00, 12.67s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 22.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# Rerun profiling\n",
    "profile = ProfileReport(df_daily_affect_wide.iloc[:,2:],\n",
    "                        title=f\"Affect Run {run_num} | Pandas Profiling Report\",\n",
    "                        infer_dtypes = False)\n",
    "profile.to_file(eda_reports_path + f\"affect_report_clean_run{run_num}.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are a number of participants who have no variance in a given category.\n",
    "\n",
    "This is obviously a problem for some analyses..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>ZeroVariance</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1081454a-03ff-445c-9602-ac9fe9e3e5cf</td>\n",
       "      <td>affect_neg_angry</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1081454a-03ff-445c-9602-ac9fe9e3e5cf</td>\n",
       "      <td>affect_neg_ashamed</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>852c24f8-36d6-4bbd-b79f-7f6fe64d1275</td>\n",
       "      <td>affect_neg_ashamed</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1081454a-03ff-445c-9602-ac9fe9e3e5cf</td>\n",
       "      <td>affect_neg_bored</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>739f2417-2416-4646-b108-e73bb870d326</td>\n",
       "      <td>affect_neg_bored</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>ec83dfe2-3df1-44dc-a1ef-3a199327c229</td>\n",
       "      <td>affect_pos_motivated_am</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>02f48bee-6e86-437c-9394-10ae57dadd14</td>\n",
       "      <td>affect_pos_relaxedCalm_am</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>4c1d752c-a092-433b-8a13-36a9677eeb1c</td>\n",
       "      <td>affect_pos_relaxedCalm_am</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>c57c38e4-e887-40d2-ab8b-8ae62f5dfaa8</td>\n",
       "      <td>affect_pos_relaxedCalm_am</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>fb6c8f5a-f92d-4af8-9f87-73ffd4e21f98</td>\n",
       "      <td>affect_pos_relaxedCalm_am</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ParticipantIdentifier               ZeroVariance  Count\n",
       "0    1081454a-03ff-445c-9602-ac9fe9e3e5cf           affect_neg_angry     60\n",
       "1    1081454a-03ff-445c-9602-ac9fe9e3e5cf         affect_neg_ashamed     60\n",
       "2    852c24f8-36d6-4bbd-b79f-7f6fe64d1275         affect_neg_ashamed     72\n",
       "3    1081454a-03ff-445c-9602-ac9fe9e3e5cf           affect_neg_bored     60\n",
       "4    739f2417-2416-4646-b108-e73bb870d326           affect_neg_bored     85\n",
       "..                                    ...                        ...    ...\n",
       "223  ec83dfe2-3df1-44dc-a1ef-3a199327c229    affect_pos_motivated_am     32\n",
       "224  02f48bee-6e86-437c-9394-10ae57dadd14  affect_pos_relaxedCalm_am     79\n",
       "225  4c1d752c-a092-433b-8a13-36a9677eeb1c  affect_pos_relaxedCalm_am     28\n",
       "226  c57c38e4-e887-40d2-ab8b-8ae62f5dfaa8  affect_pos_relaxedCalm_am     82\n",
       "227  fb6c8f5a-f92d-4af8-9f87-73ffd4e21f98  affect_pos_relaxedCalm_am     75\n",
       "\n",
       "[228 rows x 3 columns]"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop 'trial_date' column\n",
    "data = df_daily_affect_wide.drop(columns='trial_date', errors='ignore')\n",
    "\n",
    "# Group by 'ParticipantIdentifier' and compute the variance\n",
    "grouped_variance = data.groupby('ParticipantIdentifier').var()\n",
    "\n",
    "# Filter the grouped_variance dataframe to only include columns with 0 variance for any participant\n",
    "zero_variance_df = grouped_variance[grouped_variance == 0].dropna(how='all')\n",
    "\n",
    "# Melt the dataframe to have ParticipantIdentifier, Column with 0 variance\n",
    "melted_zero_variance_df = zero_variance_df.reset_index().melt(id_vars=['ParticipantIdentifier'], value_name='Variance')\n",
    "final_zero_variance_df = melted_zero_variance_df.dropna(subset=['Variance']).drop(columns='Variance')\n",
    "\n",
    "# Count the number of values present in the variable column for each participant\n",
    "value_counts = data.groupby('ParticipantIdentifier').count()\n",
    "\n",
    "# Merge the value counts with the final_zero_variance_df\n",
    "merged_df = final_zero_variance_df.merge(value_counts, on='ParticipantIdentifier', how='left')\n",
    "\n",
    "# Extract only the relevant columns\n",
    "result_df = merged_df[['ParticipantIdentifier', 'variable', 'affect_neg_angry']]\n",
    "result_df.columns = ['ParticipantIdentifier', 'ZeroVariance', 'Count']\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some subjects had mulitple categories without any variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>affect_zeroVar_cols</th>\n",
       "      <th>total_count</th>\n",
       "      <th>affect_zeroVarCols_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1081454a-03ff-445c-9602-ac9fe9e3e5cf</td>\n",
       "      <td>27</td>\n",
       "      <td>60</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02f48bee-6e86-437c-9394-10ae57dadd14</td>\n",
       "      <td>20</td>\n",
       "      <td>79</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>852c24f8-36d6-4bbd-b79f-7f6fe64d1275</td>\n",
       "      <td>9</td>\n",
       "      <td>72</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f8f71506-9382-40c7-99db-5c170b2a9abb</td>\n",
       "      <td>9</td>\n",
       "      <td>83</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>739f2417-2416-4646-b108-e73bb870d326</td>\n",
       "      <td>8</td>\n",
       "      <td>85</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>630ece82-994f-4aef-b2e3-46760583e453</td>\n",
       "      <td>8</td>\n",
       "      <td>81</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fb6c8f5a-f92d-4af8-9f87-73ffd4e21f98</td>\n",
       "      <td>8</td>\n",
       "      <td>75</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c2bfc053-7c57-4ec9-aa69-2fcba2aaba5d</td>\n",
       "      <td>8</td>\n",
       "      <td>66</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e883a6d9-ec85-44eb-9366-9928c15fbe95</td>\n",
       "      <td>7</td>\n",
       "      <td>85</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2ca5c7c8-3834-4c79-a416-ff7f9b9e8140</td>\n",
       "      <td>7</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>295ec94c-40aa-4d89-adfd-8513dd8174aa</td>\n",
       "      <td>7</td>\n",
       "      <td>81</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>54f5e348-8c82-44b6-8da0-595012cf1ba2</td>\n",
       "      <td>6</td>\n",
       "      <td>85</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3a434888-eca8-49df-9157-825dba458eb2</td>\n",
       "      <td>6</td>\n",
       "      <td>82</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0a06ff99-9b73-4f6a-8b36-cdf27b4c22fd</td>\n",
       "      <td>6</td>\n",
       "      <td>69</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9f0105f6-8198-4bee-8717-7df0d8903e76</td>\n",
       "      <td>5</td>\n",
       "      <td>81</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>66242a73-d777-49fa-9e11-566005a97f3a</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>f14a17bf-6d39-4cdd-b1b5-a9379db5aa4c</td>\n",
       "      <td>5</td>\n",
       "      <td>77</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>c57c38e4-e887-40d2-ab8b-8ae62f5dfaa8</td>\n",
       "      <td>5</td>\n",
       "      <td>82</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3c00c8d4-afe1-4be0-9031-fafcf74ad9ab</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>117f2d92-eb60-4ed8-a99d-08ddbb775655</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4c1d752c-a092-433b-8a13-36a9677eeb1c</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fee5cd07-329a-4f07-bb1a-913dfa09e3b4</td>\n",
       "      <td>4</td>\n",
       "      <td>83</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>06af7782-cd70-4938-8e67-b6d98b34b665</td>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>b62d508b-4768-4dc4-9bf3-bc8f59bf2388</td>\n",
       "      <td>4</td>\n",
       "      <td>84</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4f4440e7-3a38-4fa7-9271-9730806e441a</td>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>e3ace276-145e-49a3-8ca1-43e4ab34f2e5</td>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>860ba768-a23c-4b33-be56-722b45b846c9</td>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>08e76051-ee6e-4872-896f-4ed3857afc0f</td>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>d4d304f4-de42-4c30-b647-c4ee78777a1b</td>\n",
       "      <td>3</td>\n",
       "      <td>84</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>47528a97-b4d9-4248-9681-4978e8171088</td>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>69979026-b13a-44d6-aa95-35b24badd593</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>fc490430-6a41-4853-a2cf-ae0b15265cb6</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>91cf3a82-4d29-4b9e-82a0-89eec2191231</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>55e8ee4e-922c-48bd-947f-a719dee73230</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>42d753dd-c35f-42a6-8e3c-8d7e2f52a31a</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ad8c4632-d429-4a81-82b8-1a130ae3f96b</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>9d5c19e4-da3f-4760-b769-0ed24d80c917</td>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>d0b352ae-a07c-4f8c-86b6-60d108e6596b</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>16c59234-ebc4-4cd7-b4cf-e105bcdb882c</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ad7fb561-1111-49bf-9663-6ab339aa53ad</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>eb85d5b5-00f0-4fb0-8dd7-982b5c8b9a29</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>68794228-9bbc-4199-b58c-192307df77f2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5599c2a7-88a5-4cde-9f2a-41b4bd03d660</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4e465685-8d64-4b22-8b6c-9409f9eb3c02</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1dd79a79-dd14-4932-b81b-16f95bbcd796</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>928a69c5-f0f3-4a0d-a436-b64c5fe57d52</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>878dce73-328a-482b-aa8f-cfb9802e9a67</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>b50ef395-6d97-4314-b397-e5d755595dc2</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>38b86bfc-579d-4155-93e0-f44afdca101a</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ec83dfe2-3df1-44dc-a1ef-3a199327c229</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ParticipantIdentifier  affect_zeroVar_cols  total_count  \\\n",
       "0   1081454a-03ff-445c-9602-ac9fe9e3e5cf                   27           60   \n",
       "1   02f48bee-6e86-437c-9394-10ae57dadd14                   20           79   \n",
       "2   852c24f8-36d6-4bbd-b79f-7f6fe64d1275                    9           72   \n",
       "3   f8f71506-9382-40c7-99db-5c170b2a9abb                    9           83   \n",
       "4   739f2417-2416-4646-b108-e73bb870d326                    8           85   \n",
       "5   630ece82-994f-4aef-b2e3-46760583e453                    8           81   \n",
       "6   fb6c8f5a-f92d-4af8-9f87-73ffd4e21f98                    8           75   \n",
       "7   c2bfc053-7c57-4ec9-aa69-2fcba2aaba5d                    8           66   \n",
       "8   e883a6d9-ec85-44eb-9366-9928c15fbe95                    7           85   \n",
       "9   2ca5c7c8-3834-4c79-a416-ff7f9b9e8140                    7           63   \n",
       "10  295ec94c-40aa-4d89-adfd-8513dd8174aa                    7           81   \n",
       "11  54f5e348-8c82-44b6-8da0-595012cf1ba2                    6           85   \n",
       "12  3a434888-eca8-49df-9157-825dba458eb2                    6           82   \n",
       "13  0a06ff99-9b73-4f6a-8b36-cdf27b4c22fd                    6           69   \n",
       "14  9f0105f6-8198-4bee-8717-7df0d8903e76                    5           81   \n",
       "15  66242a73-d777-49fa-9e11-566005a97f3a                    5           46   \n",
       "16  f14a17bf-6d39-4cdd-b1b5-a9379db5aa4c                    5           77   \n",
       "17  c57c38e4-e887-40d2-ab8b-8ae62f5dfaa8                    5           82   \n",
       "18  3c00c8d4-afe1-4be0-9031-fafcf74ad9ab                    4           67   \n",
       "19  117f2d92-eb60-4ed8-a99d-08ddbb775655                    4           65   \n",
       "20  4c1d752c-a092-433b-8a13-36a9677eeb1c                    4           28   \n",
       "21  fee5cd07-329a-4f07-bb1a-913dfa09e3b4                    4           83   \n",
       "22  06af7782-cd70-4938-8e67-b6d98b34b665                    4           75   \n",
       "23  b62d508b-4768-4dc4-9bf3-bc8f59bf2388                    4           84   \n",
       "24  4f4440e7-3a38-4fa7-9271-9730806e441a                    3           85   \n",
       "25  e3ace276-145e-49a3-8ca1-43e4ab34f2e5                    3           69   \n",
       "26  860ba768-a23c-4b33-be56-722b45b846c9                    3           47   \n",
       "27  08e76051-ee6e-4872-896f-4ed3857afc0f                    3           85   \n",
       "28  d4d304f4-de42-4c30-b647-c4ee78777a1b                    3           84   \n",
       "29  47528a97-b4d9-4248-9681-4978e8171088                    3           74   \n",
       "30  69979026-b13a-44d6-aa95-35b24badd593                    2           85   \n",
       "31  fc490430-6a41-4853-a2cf-ae0b15265cb6                    2           65   \n",
       "32  91cf3a82-4d29-4b9e-82a0-89eec2191231                    2           77   \n",
       "33  55e8ee4e-922c-48bd-947f-a719dee73230                    2           85   \n",
       "34  42d753dd-c35f-42a6-8e3c-8d7e2f52a31a                    2           65   \n",
       "35  ad8c4632-d429-4a81-82b8-1a130ae3f96b                    2           79   \n",
       "36  9d5c19e4-da3f-4760-b769-0ed24d80c917                    2           84   \n",
       "37  d0b352ae-a07c-4f8c-86b6-60d108e6596b                    2           39   \n",
       "38  16c59234-ebc4-4cd7-b4cf-e105bcdb882c                    2           40   \n",
       "39  ad7fb561-1111-49bf-9663-6ab339aa53ad                    1           21   \n",
       "40  eb85d5b5-00f0-4fb0-8dd7-982b5c8b9a29                    1           54   \n",
       "41  68794228-9bbc-4199-b58c-192307df77f2                    1           15   \n",
       "42  5599c2a7-88a5-4cde-9f2a-41b4bd03d660                    1           84   \n",
       "43  4e465685-8d64-4b22-8b6c-9409f9eb3c02                    1           68   \n",
       "44  1dd79a79-dd14-4932-b81b-16f95bbcd796                    1           84   \n",
       "45  928a69c5-f0f3-4a0d-a436-b64c5fe57d52                    1           83   \n",
       "46  878dce73-328a-482b-aa8f-cfb9802e9a67                    1           85   \n",
       "47  0151d9f1-1644-4437-805e-02f5e244a690                    1           84   \n",
       "48  b50ef395-6d97-4314-b397-e5d755595dc2                    1           83   \n",
       "49  38b86bfc-579d-4155-93e0-f44afdca101a                    1           82   \n",
       "50  ec83dfe2-3df1-44dc-a1ef-3a199327c229                    1           32   \n",
       "\n",
       "    affect_zeroVarCols_flag  \n",
       "0                      True  \n",
       "1                      True  \n",
       "2                      True  \n",
       "3                      True  \n",
       "4                      True  \n",
       "5                      True  \n",
       "6                      True  \n",
       "7                      True  \n",
       "8                      True  \n",
       "9                      True  \n",
       "10                     True  \n",
       "11                     True  \n",
       "12                     True  \n",
       "13                     True  \n",
       "14                     True  \n",
       "15                     True  \n",
       "16                     True  \n",
       "17                     True  \n",
       "18                     True  \n",
       "19                     True  \n",
       "20                     True  \n",
       "21                     True  \n",
       "22                     True  \n",
       "23                     True  \n",
       "24                     True  \n",
       "25                     True  \n",
       "26                     True  \n",
       "27                     True  \n",
       "28                     True  \n",
       "29                     True  \n",
       "30                    False  \n",
       "31                    False  \n",
       "32                    False  \n",
       "33                    False  \n",
       "34                    False  \n",
       "35                    False  \n",
       "36                    False  \n",
       "37                    False  \n",
       "38                    False  \n",
       "39                    False  \n",
       "40                    False  \n",
       "41                    False  \n",
       "42                    False  \n",
       "43                    False  \n",
       "44                    False  \n",
       "45                    False  \n",
       "46                    False  \n",
       "47                    False  \n",
       "48                    False  \n",
       "49                    False  \n",
       "50                    False  "
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_var_cols = result_df.ParticipantIdentifier.value_counts().reset_index(name='affect_zeroVar_cols')\n",
    "# Remove rows where both morning and evening surveys have NaN values\n",
    "df_count = df_daily_affect_wide[~((df_daily_affect_wide['affect_neg_angry'].isnull()) & (df_daily_affect_wide['affect_neg_angry_am'].isnull()))]\n",
    "# Calculate how many completed days\n",
    "df_count =  df_count.groupby('ParticipantIdentifier').size().reset_index(name='total_count')\n",
    "\n",
    "# merge\n",
    "zero_var_cols = zero_var_cols.merge(df_count, on='ParticipantIdentifier', how='left')\n",
    "\n",
    "# add flag\n",
    "zero_var_cols['affect_zeroVarCols_flag'] = False\n",
    "zero_var_cols.loc[zero_var_cols.affect_zeroVar_cols > 2, 'affect_zeroVarCols_flag'] = True\n",
    "zero_var_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with main affect df\n",
    "df_daily_affect_wide = df_daily_affect_wide.merge(zero_var_cols.drop(columns=['total_count']), on='ParticipantIdentifier', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many subjects had at least one column with no variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(result_df.ParticipantIdentifier))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the subject who had 15 variables with no variance (run 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>affect_neg_angry</th>\n",
       "      <th>affect_neg_ashamed</th>\n",
       "      <th>affect_neg_bored</th>\n",
       "      <th>affect_neg_depressed</th>\n",
       "      <th>affect_neg_embarrassed</th>\n",
       "      <th>affect_neg_frustrated</th>\n",
       "      <th>affect_neg_guilty</th>\n",
       "      <th>affect_neg_lazy</th>\n",
       "      <th>...</th>\n",
       "      <th>affect_pos_amused_am</th>\n",
       "      <th>affect_pos_appreciated_am</th>\n",
       "      <th>affect_pos_excited_am</th>\n",
       "      <th>affect_pos_focused_am</th>\n",
       "      <th>affect_pos_happy_am</th>\n",
       "      <th>affect_pos_hopeful_am</th>\n",
       "      <th>affect_pos_motivated_am</th>\n",
       "      <th>affect_pos_relaxedCalm_am</th>\n",
       "      <th>affect_zeroVar_cols</th>\n",
       "      <th>affect_zeroVarCols_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ParticipantIdentifier, trial_date, affect_neg_angry, affect_neg_ashamed, affect_neg_bored, affect_neg_depressed, affect_neg_embarrassed, affect_neg_frustrated, affect_neg_guilty, affect_neg_lazy, affect_neg_lonelyIsolated, affect_neg_nervousAnxious, affect_neg_sad, affect_neg_stressed, affect_pos_amused, affect_pos_appreciated, affect_pos_excited, affect_pos_focused, affect_pos_happy, affect_pos_hopeful, affect_pos_motivated, affect_pos_relaxedCalm, affect_neg_angry_am, affect_neg_ashamed_am, affect_neg_bored_am, affect_neg_depressed_am, affect_neg_embarrassed_am, affect_neg_frustrated_am, affect_neg_guilty_am, affect_neg_lazy_am, affect_neg_lonelyIsolated_am, affect_neg_nervousAnxious_am, affect_neg_sad_am, affect_neg_stressed_am, affect_pos_amused_am, affect_pos_appreciated_am, affect_pos_excited_am, affect_pos_focused_am, affect_pos_happy_am, affect_pos_hopeful_am, affect_pos_motivated_am, affect_pos_relaxedCalm_am, affect_zeroVar_cols, affect_zeroVarCols_flag]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 44 columns]"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_daily_affect_wide.loc[df_daily_affect_wide.ParticipantIdentifier == '27f7805e-5951-47b4-9f42-4c6200001cc6', :].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But maybe variance within day is more important in terms of actually cleaning data. If someone enters the same value for every variable perhaps it is because they are not answering accurately and just trying to finish as quickly as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>zeroVar_count</th>\n",
       "      <th>total_count</th>\n",
       "      <th>affect_pct_zeroVarRows</th>\n",
       "      <th>affect_zeroVarRows_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3e1d1276-0e73-4457-9911-f189b0ed0778</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>4.705882</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>783dd47a-1180-4965-874e-eb405ee6143e</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>7.547170</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8c58f5aa-f20e-4c39-a38d-f9c9a44a6cee</td>\n",
       "      <td>7</td>\n",
       "      <td>84</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c61e40df-fa64-4037-838e-65d912521dc2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f55d6d94-8602-46cb-b3bd-53ea561eb296</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>5.714286</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ParticipantIdentifier  zeroVar_count  total_count  \\\n",
       "0  3e1d1276-0e73-4457-9911-f189b0ed0778              4           85   \n",
       "1  783dd47a-1180-4965-874e-eb405ee6143e              4           53   \n",
       "2  8c58f5aa-f20e-4c39-a38d-f9c9a44a6cee              7           84   \n",
       "3  c61e40df-fa64-4037-838e-65d912521dc2              5           10   \n",
       "4  f55d6d94-8602-46cb-b3bd-53ea561eb296              4           70   \n",
       "\n",
       "   affect_pct_zeroVarRows  affect_zeroVarRows_flag  \n",
       "0                4.705882                    False  \n",
       "1                7.547170                    False  \n",
       "2                8.333333                    False  \n",
       "3               50.000000                     True  \n",
       "4                5.714286                    False  "
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find rows with zero variance\n",
    "idx = np.where(df_daily_affect_wide.drop(columns=['ParticipantIdentifier', 'trial_date']).var(axis=1) == 0)[0]\n",
    "# calculate how many zero variance days per subject\n",
    "df_zeroVar = df_daily_affect_wide.iloc[idx,:].groupby('ParticipantIdentifier').size().reset_index(name='zeroVar_count')\n",
    "\n",
    "# Remove rows where both morning and evening surveys have NaN values\n",
    "df_count = df_daily_affect_wide[~((df_daily_affect_wide['affect_neg_angry'].isnull()) & (df_daily_affect_wide['affect_neg_angry_am'].isnull()))]\n",
    "# Calculate how many completed days\n",
    "df_count =  df_count.groupby('ParticipantIdentifier').size().reset_index(name='total_count')\n",
    "\n",
    "# merge\n",
    "df_zeroVar = df_zeroVar.merge(df_count, on='ParticipantIdentifier', how='left')\n",
    "df_zeroVar['affect_pct_zeroVarRows'] = (df_zeroVar.zeroVar_count / df_zeroVar.total_count) * 100\n",
    "\n",
    "# add flag\n",
    "df_zeroVar['affect_zeroVarRows_flag'] = False\n",
    "df_zeroVar.loc[df_zeroVar.affect_pct_zeroVarRows > 10, 'affect_zeroVarRows_flag'] = True\n",
    "df_zeroVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with main affect df\n",
    "df_daily_affect_wide = df_daily_affect_wide.merge(df_zeroVar.drop(columns=['zeroVar_count', 'total_count']), on='ParticipantIdentifier', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>affect_neg_angry</th>\n",
       "      <th>affect_neg_ashamed</th>\n",
       "      <th>affect_neg_bored</th>\n",
       "      <th>affect_neg_depressed</th>\n",
       "      <th>affect_neg_embarrassed</th>\n",
       "      <th>affect_neg_frustrated</th>\n",
       "      <th>affect_neg_guilty</th>\n",
       "      <th>affect_neg_lazy</th>\n",
       "      <th>...</th>\n",
       "      <th>affect_pos_excited_am</th>\n",
       "      <th>affect_pos_focused_am</th>\n",
       "      <th>affect_pos_happy_am</th>\n",
       "      <th>affect_pos_hopeful_am</th>\n",
       "      <th>affect_pos_motivated_am</th>\n",
       "      <th>affect_pos_relaxedCalm_am</th>\n",
       "      <th>affect_zeroVar_cols</th>\n",
       "      <th>affect_zeroVarCols_flag</th>\n",
       "      <th>affect_pct_zeroVarRows</th>\n",
       "      <th>affect_zeroVarRows_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>0ff91d6a-e400-403c-bd87-4cd1803bc5e7</td>\n",
       "      <td>2023-04-22</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4736</th>\n",
       "      <td>b50ef395-6d97-4314-b397-e5d755595dc2</td>\n",
       "      <td>2023-01-29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>042d7595-3fdc-4cf9-b288-c4b7961916d8</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>dfef360e-27cb-4d35-bb4a-d6633803eb96</td>\n",
       "      <td>2023-04-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0e14ee82-85d9-41c5-a27e-a0e9c4178117</td>\n",
       "      <td>2023-04-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ParticipantIdentifier  trial_date affect_neg_angry  \\\n",
       "843   0ff91d6a-e400-403c-bd87-4cd1803bc5e7  2023-04-22              3.0   \n",
       "4736  b50ef395-6d97-4314-b397-e5d755595dc2  2023-01-29              2.0   \n",
       "195   042d7595-3fdc-4cf9-b288-c4b7961916d8  2023-03-02              3.0   \n",
       "5566  dfef360e-27cb-4d35-bb4a-d6633803eb96  2023-04-14              1.0   \n",
       "764   0e14ee82-85d9-41c5-a27e-a0e9c4178117  2023-04-14              1.0   \n",
       "\n",
       "     affect_neg_ashamed affect_neg_bored affect_neg_depressed  \\\n",
       "843                 1.0              4.0                  5.0   \n",
       "4736                5.0              1.0                  5.0   \n",
       "195                 1.0              4.0                  5.0   \n",
       "5566                1.0              1.0                  1.0   \n",
       "764                 1.0              1.0                  1.0   \n",
       "\n",
       "     affect_neg_embarrassed affect_neg_frustrated affect_neg_guilty  \\\n",
       "843                     1.0                   4.0               2.0   \n",
       "4736                    1.0                   4.0               5.0   \n",
       "195                     2.0                   2.0               4.0   \n",
       "5566                    1.0                   1.0               1.0   \n",
       "764                     1.0                   2.0               1.0   \n",
       "\n",
       "     affect_neg_lazy  ... affect_pos_excited_am affect_pos_focused_am  \\\n",
       "843              3.0  ...                   NaN                   NaN   \n",
       "4736             4.0  ...                   NaN                   NaN   \n",
       "195              5.0  ...                   NaN                   NaN   \n",
       "5566             1.0  ...                   NaN                   NaN   \n",
       "764              2.0  ...                   1.0                   3.0   \n",
       "\n",
       "     affect_pos_happy_am affect_pos_hopeful_am affect_pos_motivated_am  \\\n",
       "843                  NaN                   NaN                     NaN   \n",
       "4736                 NaN                   NaN                     NaN   \n",
       "195                  NaN                   NaN                     NaN   \n",
       "5566                 NaN                   NaN                     NaN   \n",
       "764                  1.0                   1.0                     3.0   \n",
       "\n",
       "     affect_pos_relaxedCalm_am affect_zeroVar_cols affect_zeroVarCols_flag  \\\n",
       "843                        NaN                 NaN                     NaN   \n",
       "4736                       NaN                 1.0                   False   \n",
       "195                        NaN                 NaN                     NaN   \n",
       "5566                       NaN                 NaN                     NaN   \n",
       "764                        2.0                 NaN                     NaN   \n",
       "\n",
       "     affect_pct_zeroVarRows affect_zeroVarRows_flag  \n",
       "843                     NaN                     NaN  \n",
       "4736                    NaN                     NaN  \n",
       "195                     NaN                     NaN  \n",
       "5566                    NaN                     NaN  \n",
       "764                     NaN                     NaN  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_daily_affect_wide.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df with one participant ID for every trial_date\n",
    "\n",
    "# Create a series of dates from '2022-09-27' to '2022-12-20'\n",
    "if run_num == 1:\n",
    "    date_series = pd.date_range(start='2022-09-27', end='2022-12-20')\n",
    "elif run_num == 2:\n",
    "    date_series = pd.date_range(start='2023-01-30', end='2023-04-24')\n",
    "\n",
    "ids_series = subjects\n",
    "\n",
    "# Create a dataframe using a cartesian product of the two series\n",
    "df_complete_idDate = pd.DataFrame({\n",
    "    'ParticipantIdentifier': np.repeat(ids_series, len(date_series)),\n",
    "    'trial_date': date_series.tolist() * len(ids_series)\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "# Convert trial_date to datetime.date\n",
    "df_complete_idDate['trial_date'] = pd.to_datetime(df_complete_idDate['trial_date']).dt.date\n",
    "df_daily_affect_wide['trial_date'] = pd.to_datetime(df_daily_affect_wide['trial_date']).dt.date\n",
    "\n",
    "# Join with affect df\n",
    "df_daily_affect_wide = df_complete_idDate.merge(df_daily_affect_wide, how='left', on=['ParticipantIdentifier', 'trial_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "if run_num ==1:\n",
    "    # run 1\n",
    "    df_daily_affect_wide.to_csv(save_path + 'run1_affect.csv', index=False)\n",
    "if run_num ==2:\n",
    "    # run 2\n",
    "    df_daily_affect_wide.to_csv(save_path + 'run2_affect.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily General and Detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted existing df\n",
      "deleted daily self report df\n"
     ]
    }
   ],
   "source": [
    "# erase df if it already exists\n",
    "if 'df' in globals():\n",
    "    del(df)\n",
    "    print('deleted existing df')\n",
    "\n",
    "if 'df_daily_sr_wide' in globals():\n",
    "    del(df_daily_sr_wide)\n",
    "    print('deleted daily self report df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_num ==1:\n",
    "    # run 1\n",
    "    df = pd.read_csv(save_path + 'run1_survey_results.csv')\n",
    "if run_num ==2:\n",
    "    # run 2\n",
    "    df = pd.read_csv(save_path + 'run2_survey_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "past24_general = [\n",
    "    'DAILY_survey_situation1_surveys',\n",
    "    'DAILY_survey_situation2_surveys',\n",
    "    'DAILY_survey_missed',\n",
    "    'DAILY_past48to24_gap',\n",
    "    'DAILY_past48to24_gapCause',\n",
    "    'DAILY_past24_ideal',\n",
    "    'DAILY_past24_satisfaction',\n",
    "    'DAILY_past24_change',\n",
    "    'DAILY_past24_productivity',\n",
    "    'DAILY_past24_procrastination',\n",
    "    'DAILY_past24_punctuality',\n",
    "    'DAILY_past24_mentalEffort',\n",
    "    'DAILY_past24_physicalEffort',\n",
    "    'DAILY_past24_values',\n",
    "    'DAILY_past24_gap',\n",
    "    'DAILY_past24_gapCause',\n",
    "    'DAILY_past24_illness',\n",
    "    'DAILY_past24_fatigue',\n",
    "    'DAILY_past24_unusualEvents'\n",
    "]\n",
    "\n",
    "past24_categories = [\n",
    "    'DAILY_past24_sleep',\n",
    "    'DAILY_past24_occupation',\n",
    "    'DAILY_past24_nonoccupation',\n",
    "    'DAILY_past24_exercise',\n",
    "    'DAILY_past24_leisureSolo',\n",
    "    'DAILY_past24_leisureSoloMental',\n",
    "    'DAILY_past24_leisureSoloPhysical',\n",
    "    'DAILY_past24_leisureNonSolo',\n",
    "    'DAILY_past24_leisureNonSoloMental',\n",
    "    'DAILY_past24_leisureNonSoloPhysical',\n",
    "    'DAILY_past24_diet',\n",
    "    'DAILY_past24_socialMedia',\n",
    "    'DAILY_past24_drinks'\n",
    "]\n",
    "\n",
    "next24_categories = [\n",
    "    'DAILY_next24_sleep',\n",
    "    'DAILY_next24_occupation',\n",
    "    'DAILY_next24_nonoccupation',\n",
    "    'DAILY_next24_leisureSolo',\n",
    "    'DAILY_next24_leisureNonSolo',\n",
    "    'DAILY_next24_exercise',\n",
    "    'DAILY_next24_socialMedia',\n",
    "    'DAILY_next24_drinks',\n",
    "    'DAILY_next24_diet'\n",
    "]\n",
    "\n",
    "monthly_goals = [\n",
    "    'MONTHLY_ib_gap_change',\n",
    "    'MONTHLY_ib_gap_change_app',\n",
    "    'MONTHLY_goal_report1',\n",
    "    'MONTHLY_goal_set1_importance',\n",
    "    'MONTHLY_goal_set1_consequences',\n",
    "    'MONTHLY_goal_set1_motivationInternal',\n",
    "    'MONTHLY_goal_set1_motivationExternal',\n",
    "    'MONTHLY_goal_set1_confidence',\n",
    "    'MONTHLY_goal_set1_effort',\n",
    "    'MONTHLY_goal_report2',\n",
    "    'MONTHLY_goal_set2_importance',\n",
    "    'MONTHLY_goal_set2_consequences',\n",
    "    'MONTHLY_goal_set2_motivationInternal',\n",
    "    'MONTHLY_goal_set2_motivationExternal',\n",
    "    'MONTHLY_goal_set2_confidence',\n",
    "    'MONTHLY_goal_set2_effort',\n",
    "    'MONTHLY_goal_set2_interaction_eachOther'\n",
    "]\n",
    "\n",
    "monthly_ideals = [\n",
    "    'IDEAL_weekday_sleep',\n",
    "    'IDEAL_weekday_occupation',\n",
    "    'IDEAL_weekday_nonoccupation',\n",
    "    'IDEAL_weekday_leisureSolo',\n",
    "    'IDEAL_weekday_leisureNonSolo',\n",
    "    'IDEAL_weekday_exercise',\n",
    "    'IDEAL_weekday_socialMedia',\n",
    "    'IDEAL_weekday_drinks',\n",
    "    'IDEAL_weekend_sleep',\n",
    "    'IDEAL_weekend_occupation',\n",
    "    'IDEAL_weekend_nonoccupation',\n",
    "    'IDEAL_weekend_leisureSolo',\n",
    "    'IDEAL_weekend_leisureNonSolo',\n",
    "    'IDEAL_weekend_exercise',\n",
    "    'IDEAL_weekend_socialMedia',\n",
    "    'IDEAL_weekend_drinks'\n",
    "]\n",
    "\n",
    "if run_num == 1:\n",
    "    specific_goals = [\n",
    "        'DAILY_goal1_report',\n",
    "        'DAILY_goal1_importance',\n",
    "        'DAILY_goal1_consequences',\n",
    "        'DAILY_goal1_motivationInternal',\n",
    "        'DAILY_goal1_motivationExternal',\n",
    "        'DAILY_goal1_confidence',\n",
    "        'DAILY_goal1_effort',\n",
    "        'DAILY_goal1_interaction_week',\n",
    "        'DAILY_goal1_interaction_month',\n",
    "        'DAILY_goal2_report',\n",
    "        'DAILY_goal2_importance',\n",
    "        'DAILY_goal2_consequences',\n",
    "        'DAILY_goal2_motivationInternal',\n",
    "        'DAILY_goal2_motivationExternal',\n",
    "        'DAILY_goal2_confidence',\n",
    "        'DAILY_goal2_effort',\n",
    "        'DAILY_goal2_interaction_week',\n",
    "        'DAILY_goal2_interaction_month',\n",
    "        'DAILY_goal2_interaction_eachOther'\n",
    "    ]\n",
    "    \n",
    "    weekly_goals = [\n",
    "        'WEEKLY_goal_report1',\n",
    "        'WEEKLY_goal_set1_importance',\n",
    "        'WEEKLY_goal_set1_consequences',\n",
    "        'WEEKLY_goal_set1_motivationInternal',\n",
    "        'WEEKLY_goal_set1_motivationExternal',\n",
    "        'WEEKLY_goal_set1_confidence',\n",
    "        'WEEKLY_goal_set1_effort',\n",
    "        'WEEKLY_goal_set1_interaction_month',\n",
    "        'WEEKLY_goal_report2',\n",
    "        'WEEKLY_goal_set2_importance',\n",
    "        'WEEKLY_goal_set2_consequences',\n",
    "        'WEEKLY_goal_set2_motivationInternal',\n",
    "        'WEEKLY_goal_set2_motivationExternal',\n",
    "        'WEEKLY_goal_set2_confidence',\n",
    "        'WEEKLY_goal_set2_effort',\n",
    "        'WEEKLY_goal_set2_interaction_month',\n",
    "        'WEEKLY_goal_set2_interaction_eachOther'\n",
    "    ]\n",
    "\n",
    "elif run_num == 2:\n",
    "    specific_goals = [\n",
    "        'DAILY_goal1_report',\n",
    "        'DAILY_goal1_importance',\n",
    "        'DAILY_goal1_consequences',\n",
    "        'DAILY_goal1_motivationInternal',\n",
    "        'DAILY_goal1_motivationExternal',\n",
    "        'DAILY_goal1_confidence',\n",
    "        'DAILY_goal1_effort',\n",
    "        'DAILY_goal1_interaction_week1',\n",
    "        'DAILY_goal1_interaction_week2',\n",
    "        'DAILY_goal1_interaction_month1',\n",
    "        'DAILY_goal1_interaction_month2',\n",
    "        'DAILY_goal2_report',\n",
    "        'DAILY_goal2_importance',\n",
    "        'DAILY_goal2_consequences',\n",
    "        'DAILY_goal2_motivationInternal',\n",
    "        'DAILY_goal2_motivationExternal',\n",
    "        'DAILY_goal2_confidence',\n",
    "        'DAILY_goal2_effort',\n",
    "        'DAILY_goal2_interaction_week1',\n",
    "        'DAILY_goal2_interaction_week2',\n",
    "        'DAILY_goal2_interaction_month1',\n",
    "        'DAILY_goal2_interaction_month2',\n",
    "        'DAILY_goal2_interaction_eachOther'\n",
    "    ]\n",
    "    \n",
    "    weekly_goals = [\n",
    "        'WEEKLY_goal_report1',\n",
    "        'WEEKLY_goal_set1_importance',\n",
    "        'WEEKLY_goal_set1_consequences',\n",
    "        'WEEKLY_goal_set1_motivationInternal',\n",
    "        'WEEKLY_goal_set1_motivationExternal',\n",
    "        'WEEKLY_goal_set1_confidence',\n",
    "        'WEEKLY_goal_set1_effort',\n",
    "        'WEEKLY_goal_set1_interaction_month1',\n",
    "        'WEEKLY_goal_set1_interaction_month2',\n",
    "        'WEEKLY_goal_report2',\n",
    "        'WEEKLY_goal_set2_importance',\n",
    "        'WEEKLY_goal_set2_consequences',\n",
    "        'WEEKLY_goal_set2_motivationInternal',\n",
    "        'WEEKLY_goal_set2_motivationExternal',\n",
    "        'WEEKLY_goal_set2_confidence',\n",
    "        'WEEKLY_goal_set2_effort',\n",
    "        'WEEKLY_goal_set2_interaction_month1',\n",
    "        'WEEKLY_goal_set2_interaction_month2',\n",
    "        'WEEKLY_goal_set2_interaction_eachOther'\n",
    "    ]\n",
    "\n",
    "non_numeric_cols = [\n",
    "    'IDEAL_values_monthly1',\n",
    "    'IDEAL_values_monthly2',\n",
    "    'IDEAL_values_monthly3',\n",
    "    'DAILY_goal1_set',\n",
    "    'DAILY_goal2_set',\n",
    "    'WEEKLY_goal_set1',\n",
    "    'WEEKLY_goal_set2',\n",
    "    'MONTHLY_goal_set1',\n",
    "    'MONTHLY_goal_set2',\n",
    "    'DAILY_next24_diet',\n",
    "    'DAILY_past48to24_gapCause',\n",
    "    'DAILY_survey_situation1_surveys',\n",
    "    'DAILY_survey_situation2_surveys',\n",
    "    'DAILY_survey_missed',\n",
    "    'DAILY_past24_gapCause',\n",
    "    'ParticipantIdentifier',\n",
    "    'trial_date'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily_sr = df.loc[df.ResultIdentifier.isin(past24_general + \n",
    "                                              past24_categories + \n",
    "                                              next24_categories + \n",
    "                                              specific_goals +\n",
    "                                              non_numeric_cols)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to Wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert values in 'Answers' column to numeric where possible, else leave as string\n",
    "# df_daily_sr['Answers'] = pd.to_numeric(df_daily_sr['Answers'], errors='coerce').fillna(df_daily_sr['Answers'])\n",
    "\n",
    "# Pivot the data\n",
    "df_daily_sr_wide = df_daily_sr.pivot_table(index=[\"ParticipantIdentifier\", \"trial_date\"],\n",
    "                                           columns='ResultIdentifier',\n",
    "                                           values='Answers',\n",
    "                                           aggfunc=lambda x: ' '.join(map(str, x))).reset_index()\n",
    "# get rid of name on index\n",
    "df_daily_sr_wide = df_daily_sr_wide.rename_axis(None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to numeric where appropriate\n",
    "df_daily_sr_wide.loc[:,df_daily_sr_wide.columns[~df_daily_sr_wide.columns.isin(non_numeric_cols + ['ParticipantIdentifier', 'trial_date'])]] = df_daily_sr_wide.loc[:,df_daily_sr_wide.columns[~df_daily_sr_wide.columns.isin(non_numeric_cols)]].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break gap cause into two columns\n",
    "if run_num == 1:\n",
    "    df_daily_sr_wide[['DAILY_past24_gapCause_internal', 'DAILY_past24_gapCause_external', 'drop_col']] = df_daily_sr_wide.DAILY_past24_gapCause.str.split(\"_\", expand = True)\n",
    "    df_daily_sr_wide.drop(columns='drop_col', inplace=True)\n",
    "\n",
    "elif run_num == 2:\n",
    "    df_daily_sr_wide[['DAILY_past24_gapCause_internal', 'DAILY_past24_gapCause_external', 'drop_col', 'drop_col']] = df_daily_sr_wide.DAILY_past24_gapCause.str.split(\"_\", expand = True)\n",
    "    df_daily_sr_wide.drop(columns='drop_col', inplace=True)\n",
    "\n",
    "# convert to numeric 0-1\n",
    "cols = ['DAILY_past24_gapCause_internal', 'DAILY_past24_gapCause_external']\n",
    "df_daily_sr_wide[cols] = df_daily_sr_wide[cols].apply(pd.to_numeric, errors = 'coerce')\n",
    "df_daily_sr_wide[cols] = df_daily_sr_wide[cols]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPEAT FOR MISSED DAY DATA\n",
    "# Break gap cause into two columns\n",
    "df_daily_sr_wide[['DAILY_past48to24_gapCause_internal', 'DAILY_past48to24_gapCause_external']] = df_daily_sr_wide.DAILY_past48to24_gapCause.str.split(\"_\", expand = True)\n",
    "\n",
    "# convert to numeric 0-1\n",
    "cols = ['DAILY_past48to24_gapCause_internal', 'DAILY_past48to24_gapCause_external']\n",
    "df_daily_sr_wide[cols] = df_daily_sr_wide[cols].apply(pd.to_numeric, errors = 'coerce')\n",
    "df_daily_sr_wide[cols] = df_daily_sr_wide[cols]/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category Gap Calculation\n",
    "\n",
    "⚡ Make sure that we are not calculating gaps where there was no PREDICTION MADE\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>📝 Note:</b><br>\n",
    "    I am assuming that peoples' goals are directional in a way that MAY NOT BE ACCURATE for everyone.<br><br>\n",
    "    For example, I am assuming that people want to sleep more and drink less - in other words they have a <b>gap</b> if they have <b>more</b> drinks than planned, but for <b>sleep</b> the gap calculation is reversed since we assume a gap means that you had <b>fewer</b> hours of sleep than planned.<br><br>\n",
    "    While this may be accurate <i>in general</i> I would reasonably expect there to be exceptions.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate diet gap (since it is originally a success measure)\n",
    "df_daily_sr_wide['DAILY_gap_diet'] = 100 - df_daily_sr_wide.DAILY_past24_diet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the predicted amount from the day before and subtract the actual amount...\n",
    "for i in range(df_daily_sr_wide.shape[0]-1):\n",
    "    df_daily_sr_wide.loc[i+1, 'DAILY_gap_sleep'] =  df_daily_sr_wide.loc[i, 'DAILY_next24_sleep'] - df_daily_sr_wide.loc[i+1, 'DAILY_past24_sleep']\n",
    "    df_daily_sr_wide.loc[i+1, 'DAILY_gap_occupation'] =  df_daily_sr_wide.loc[i, 'DAILY_next24_occupation'] - df_daily_sr_wide.loc[i+1, 'DAILY_past24_occupation']    \n",
    "    df_daily_sr_wide.loc[i+1, 'DAILY_gap_nonoccupation'] =  df_daily_sr_wide.loc[i, 'DAILY_next24_nonoccupation'] - df_daily_sr_wide.loc[i+1, 'DAILY_past24_nonoccupation']    \n",
    "    df_daily_sr_wide.loc[i+1, 'DAILY_gap_leisureSolo'] =  df_daily_sr_wide.loc[i+1, 'DAILY_past24_leisureSolo'] - df_daily_sr_wide.loc[i, 'DAILY_next24_leisureSolo'] # reversed\n",
    "    df_daily_sr_wide.loc[i+1, 'DAILY_gap_leisureNonSolo'] =  df_daily_sr_wide.loc[i+1, 'DAILY_past24_leisureNonSolo']  - df_daily_sr_wide.loc[i, 'DAILY_next24_leisureNonSolo'] # reversed\n",
    "    df_daily_sr_wide.loc[i+1, 'DAILY_gap_exercise'] =  df_daily_sr_wide.loc[i, 'DAILY_next24_exercise'] - df_daily_sr_wide.loc[i+1, 'DAILY_past24_exercise']    \n",
    "    df_daily_sr_wide.loc[i+1, 'DAILY_gap_socialMedia'] =  df_daily_sr_wide.loc[i+1, 'DAILY_past24_socialMedia'] - df_daily_sr_wide.loc[i, 'DAILY_next24_socialMedia'] # reversed \n",
    "    df_daily_sr_wide.loc[i+1, 'DAILY_gap_drinks'] =  df_daily_sr_wide.loc[i+1, 'DAILY_past24_drinks'] - df_daily_sr_wide.loc[i, 'DAILY_next24_drinks'] # reversed\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 5281/5281 [04:37<00:00, 19.03it/s, Completed]                                                                             \n",
      "Generate report structure: 100%|██████████| 1/1 [00:12<00:00, 12.49s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:45<00:00, 45.73s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n"
     ]
    }
   ],
   "source": [
    "profile = ProfileReport(df_daily_sr_wide.iloc[:,2:], title=f\"Daily Reports Run {run_num} | Pandas Profiling Report\")\n",
    "profile.to_file(eda_reports_path + f\"daily_reports_run{run_num}.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are a number of participants who have no variance in a given category.\n",
    "\n",
    "This is obviously a problem for some analyses..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for variance in numeric cols only, leaving ParticipantIdentifier for grouping\n",
    "non_numeric_cols_alt = [item for item in non_numeric_cols if item != 'ParticipantIdentifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>dailySR_zeroVar_cols</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1081454a-03ff-445c-9602-ac9fe9e3e5cf</td>\n",
       "      <td>16</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3e1d1276-0e73-4457-9911-f189b0ed0778</td>\n",
       "      <td>9</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39ecc6ed-1f7e-4d59-8442-371fd16efb08</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06af7782-cd70-4938-8e67-b6d98b34b665</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fee5cd07-329a-4f07-bb1a-913dfa09e3b4</td>\n",
       "      <td>4</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5350441c-7181-463e-9165-5611b5bcab10</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>aa94f196-94ac-4e0e-b66d-5e2c06f717b7</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>4e465685-8d64-4b22-8b6c-9409f9eb3c02</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>4f4440e7-3a38-4fa7-9271-9730806e441a</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>69979026-b13a-44d6-aa95-35b24badd593</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ParticipantIdentifier  dailySR_zeroVar_cols  Count\n",
       "0   1081454a-03ff-445c-9602-ac9fe9e3e5cf                    16     60\n",
       "1   3e1d1276-0e73-4457-9911-f189b0ed0778                     9     85\n",
       "2   39ecc6ed-1f7e-4d59-8442-371fd16efb08                     8     28\n",
       "3   06af7782-cd70-4938-8e67-b6d98b34b665                     5     75\n",
       "4   fee5cd07-329a-4f07-bb1a-913dfa09e3b4                     4     83\n",
       "..                                   ...                   ...    ...\n",
       "70  5350441c-7181-463e-9165-5611b5bcab10                     1     85\n",
       "71  aa94f196-94ac-4e0e-b66d-5e2c06f717b7                     1     36\n",
       "72  4e465685-8d64-4b22-8b6c-9409f9eb3c02                     1     68\n",
       "73  4f4440e7-3a38-4fa7-9271-9730806e441a                     1     85\n",
       "74  69979026-b13a-44d6-aa95-35b24badd593                     1     85\n",
       "\n",
       "[75 rows x 3 columns]"
      ]
     },
     "execution_count": 725,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop 'trial_date' column\n",
    "data = df_daily_sr_wide.drop(columns=non_numeric_cols_alt, errors='ignore')\n",
    "\n",
    "# Group by 'ParticipantIdentifier' and compute the variance\n",
    "grouped_variance = data.groupby('ParticipantIdentifier').var()\n",
    "\n",
    "# Filter the grouped_variance dataframe to only include columns with 0 variance for any participant\n",
    "zero_variance_df = grouped_variance[grouped_variance == 0].dropna(how='all')\n",
    "\n",
    "# Melt the dataframe to have ParticipantIdentifier, Column with 0 variance\n",
    "melted_zero_variance_df = zero_variance_df.reset_index().melt(id_vars=['ParticipantIdentifier'], value_name='Variance')\n",
    "final_zero_variance_df = melted_zero_variance_df.dropna(subset=['Variance']).drop(columns='Variance')\n",
    "final_zero_variance_df = pd.DataFrame(final_zero_variance_df.groupby('ParticipantIdentifier').count()).reset_index().sort_values(by='variable', ascending=False)\n",
    "final_zero_variance_df = final_zero_variance_df.rename(columns={'variable': 'ZeroVariance'})\n",
    "\n",
    "# Count the number of values present in the variable column for each participant\n",
    "value_counts = data.groupby('ParticipantIdentifier').count()\n",
    "\n",
    "# Merge the value counts with the final_zero_variance_df\n",
    "merged_df = final_zero_variance_df.merge(value_counts, on='ParticipantIdentifier', how='left')\n",
    "\n",
    "# Extract only the relevant columns\n",
    "result_df = merged_df[['ParticipantIdentifier', 'ZeroVariance', 'DAILY_goal1_confidence']]\n",
    "result_df.columns = ['ParticipantIdentifier', 'dailySR_zeroVar_cols', 'Count']\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DAILY_past24_drinks</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DAILY_gap_drinks</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DAILY_next24_drinks</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAILY_next24_sleep</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DAILY_next24_socialMedia</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>DAILY_past24_occupation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>DAILY_past24_physicalEffort</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>DAILY_past24_procrastination</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>DAILY_past24_change</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>DAILY_past24_fatigue</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Variable   0\n",
       "0            DAILY_past24_drinks  53\n",
       "1               DAILY_gap_drinks  15\n",
       "2            DAILY_next24_drinks  15\n",
       "3             DAILY_next24_sleep   8\n",
       "4       DAILY_next24_socialMedia   8\n",
       "..                           ...  ..\n",
       "66       DAILY_past24_occupation   0\n",
       "67   DAILY_past24_physicalEffort   0\n",
       "68  DAILY_past24_procrastination   0\n",
       "69           DAILY_past24_change   0\n",
       "70          DAILY_past24_fatigue   0\n",
       "\n",
       "[71 rows x 2 columns]"
      ]
     },
     "execution_count": 726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can see that drinks have the most people with zero variance...\n",
    "pd.DataFrame(grouped_variance[grouped_variance == 0].dropna(how='all').eq(0).sum()).reset_index(names='Variable').sort_values(by=0, ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lw/ys_1b9sj08s904m4402qr0bm0000gn/T/ipykernel_2454/967441405.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result_df['dailySR_zeroVarCols_flag'] = False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>dailySR_zeroVar_cols</th>\n",
       "      <th>Count</th>\n",
       "      <th>dailySR_zeroVarCols_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1081454a-03ff-445c-9602-ac9fe9e3e5cf</td>\n",
       "      <td>16</td>\n",
       "      <td>60</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3e1d1276-0e73-4457-9911-f189b0ed0778</td>\n",
       "      <td>9</td>\n",
       "      <td>85</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39ecc6ed-1f7e-4d59-8442-371fd16efb08</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06af7782-cd70-4938-8e67-b6d98b34b665</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fee5cd07-329a-4f07-bb1a-913dfa09e3b4</td>\n",
       "      <td>4</td>\n",
       "      <td>83</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>fc490430-6a41-4853-a2cf-ae0b15265cb6</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>042d7595-3fdc-4cf9-b288-c4b7961916d8</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>9d5c19e4-da3f-4760-b769-0ed24d80c917</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>98f7c7df-3bbf-44bf-99be-e2995f557e91</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>69979026-b13a-44d6-aa95-35b24badd593</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ParticipantIdentifier  dailySR_zeroVar_cols  Count  \\\n",
       "0   1081454a-03ff-445c-9602-ac9fe9e3e5cf                    16     60   \n",
       "1   3e1d1276-0e73-4457-9911-f189b0ed0778                     9     85   \n",
       "2   39ecc6ed-1f7e-4d59-8442-371fd16efb08                     8     28   \n",
       "3   06af7782-cd70-4938-8e67-b6d98b34b665                     5     75   \n",
       "4   fee5cd07-329a-4f07-bb1a-913dfa09e3b4                     4     83   \n",
       "..                                   ...                   ...    ...   \n",
       "48  fc490430-6a41-4853-a2cf-ae0b15265cb6                     1     65   \n",
       "47  042d7595-3fdc-4cf9-b288-c4b7961916d8                     1     42   \n",
       "46  9d5c19e4-da3f-4760-b769-0ed24d80c917                     1     84   \n",
       "45  98f7c7df-3bbf-44bf-99be-e2995f557e91                     1     82   \n",
       "74  69979026-b13a-44d6-aa95-35b24badd593                     1     85   \n",
       "\n",
       "    dailySR_zeroVarCols_flag  \n",
       "0                       True  \n",
       "1                       True  \n",
       "2                       True  \n",
       "3                      False  \n",
       "4                      False  \n",
       "..                       ...  \n",
       "48                     False  \n",
       "47                     False  \n",
       "46                     False  \n",
       "45                     False  \n",
       "74                     False  \n",
       "\n",
       "[75 rows x 4 columns]"
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add flag for subjects with more than 5 zero variance columns\n",
    "flag_threshold = 5\n",
    "\n",
    "result_df['dailySR_zeroVarCols_flag'] = False\n",
    "result_df.loc[result_df.dailySR_zeroVar_cols > flag_threshold, 'dailySR_zeroVarCols_flag'] = True\n",
    "result_df.sort_values(by='dailySR_zeroVar_cols', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>DAILY_goal1_confidence</th>\n",
       "      <th>DAILY_goal1_consequences</th>\n",
       "      <th>DAILY_goal1_effort</th>\n",
       "      <th>DAILY_goal1_importance</th>\n",
       "      <th>DAILY_goal1_interaction_month1</th>\n",
       "      <th>DAILY_goal1_interaction_month2</th>\n",
       "      <th>DAILY_goal1_interaction_week1</th>\n",
       "      <th>DAILY_goal1_interaction_week2</th>\n",
       "      <th>...</th>\n",
       "      <th>DAILY_past48to24_gapCause_external</th>\n",
       "      <th>DAILY_gap_diet</th>\n",
       "      <th>DAILY_gap_sleep</th>\n",
       "      <th>DAILY_gap_occupation</th>\n",
       "      <th>DAILY_gap_nonoccupation</th>\n",
       "      <th>DAILY_gap_leisureSolo</th>\n",
       "      <th>DAILY_gap_leisureNonSolo</th>\n",
       "      <th>DAILY_gap_exercise</th>\n",
       "      <th>DAILY_gap_socialMedia</th>\n",
       "      <th>DAILY_gap_drinks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ParticipantIdentifier, trial_date, DAILY_goal1_confidence, DAILY_goal1_consequences, DAILY_goal1_effort, DAILY_goal1_importance, DAILY_goal1_interaction_month1, DAILY_goal1_interaction_month2, DAILY_goal1_interaction_week1, DAILY_goal1_interaction_week2, DAILY_goal1_motivationExternal, DAILY_goal1_motivationInternal, DAILY_goal1_report, DAILY_goal1_set, DAILY_goal2_confidence, DAILY_goal2_consequences, DAILY_goal2_effort, DAILY_goal2_importance, DAILY_goal2_interaction_eachOther, DAILY_goal2_interaction_month1, DAILY_goal2_interaction_month2, DAILY_goal2_interaction_week1, DAILY_goal2_interaction_week2, DAILY_goal2_motivationExternal, DAILY_goal2_motivationInternal, DAILY_goal2_report, DAILY_goal2_set, DAILY_next24_drinks, DAILY_next24_exercise, DAILY_next24_leisureNonSolo, DAILY_next24_leisureSolo, DAILY_next24_nonoccupation, DAILY_next24_occupation, DAILY_next24_sleep, DAILY_next24_socialMedia, DAILY_past24_change, DAILY_past24_diet, DAILY_past24_drinks, DAILY_past24_exercise, DAILY_past24_fatigue, DAILY_past24_gap, DAILY_past24_gapCause, DAILY_past24_ideal, DAILY_past24_illness, DAILY_past24_leisureNonSolo, DAILY_past24_leisureNonSoloMental, DAILY_past24_leisureNonSoloPhysical, DAILY_past24_leisureSolo, DAILY_past24_leisureSoloMental, DAILY_past24_leisureSoloPhysical, DAILY_past24_mentalEffort, DAILY_past24_nonoccupation, DAILY_past24_occupation, DAILY_past24_physicalEffort, DAILY_past24_procrastination, DAILY_past24_productivity, DAILY_past24_punctuality, DAILY_past24_satisfaction, DAILY_past24_sleep, DAILY_past24_socialMedia, DAILY_past24_unusualEvents, DAILY_past24_values, DAILY_past48to24_gap, DAILY_past48to24_gapCause, DAILY_survey_missed, DAILY_survey_situation1_surveys, DAILY_survey_situation2_surveys, IDEAL_values_monthly1, IDEAL_values_monthly2, IDEAL_values_monthly3, MONTHLY_goal_set1, MONTHLY_goal_set2, WEEKLY_goal_set1, WEEKLY_goal_set2, DAILY_past24_gapCause_internal, DAILY_past24_gapCause_external, DAILY_past48to24_gapCause_internal, DAILY_past48to24_gapCause_external, DAILY_gap_diet, DAILY_gap_sleep, DAILY_gap_occupation, DAILY_gap_nonoccupation, DAILY_gap_leisureSolo, DAILY_gap_leisureNonSolo, DAILY_gap_exercise, DAILY_gap_socialMedia, DAILY_gap_drinks]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 87 columns]"
      ]
     },
     "execution_count": 728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at subject with most zero var columns\n",
    "df_daily_sr_wide.loc[(df_daily_sr_wide['ParticipantIdentifier'] == '27329533-d0a4-4605-9da5-0eb857154cae') & (df_daily_sr_wide['DAILY_goal1_confidence'].notna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with main sr df\n",
    "df_daily_sr_wide = df_daily_sr_wide.merge(result_df.drop(columns=['Count']), on='ParticipantIdentifier', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add sr prefix\n",
    "# df_daily_sr_wide.columns[2:]\n",
    "\n",
    "df_daily_sr_wide.columns = ['ParticipantIdentifier', 'trial_date'] + ['sr_' + col for col in df_daily_sr_wide.columns[2:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df with one participant ID for every trial_date\n",
    "\n",
    "# Create a series of dates from '2022-09-27' to '2022-12-20'\n",
    "if run_num == 1:\n",
    "    date_series = pd.date_range(start='2022-09-27', end='2022-12-20')\n",
    "elif run_num == 2:\n",
    "    date_series = pd.date_range(start='2023-01-30', end='2023-04-24')\n",
    "\n",
    "ids_series = subjects\n",
    "\n",
    "# Create a dataframe using a cartesian product of the two series\n",
    "df_complete_idDate = pd.DataFrame({\n",
    "    'ParticipantIdentifier': np.repeat(ids_series, len(date_series)),\n",
    "    'trial_date': date_series.tolist() * len(ids_series)\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "# Convert trial_date to datetime.date\n",
    "df_complete_idDate['trial_date'] = pd.to_datetime(df_complete_idDate['trial_date']).dt.date\n",
    "df_daily_sr_wide['trial_date'] = pd.to_datetime(df_daily_sr_wide['trial_date']).dt.date\n",
    "\n",
    "# Join with affect df\n",
    "df_daily_sr_wide = df_complete_idDate.merge(df_daily_sr_wide, how='left', on=['ParticipantIdentifier', 'trial_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "if run_num ==1:\n",
    "    # run 1\n",
    "    df_daily_sr_wide.to_csv(save_path + 'run1_selfReport.csv', index=False)\n",
    "if run_num ==2:\n",
    "    # run 2\n",
    "    df_daily_sr_wide.to_csv(save_path + 'run2_selfReport.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily/Weekly Social Support\n",
    "\n",
    "**NOTE**: These were only collected in run 2\n",
    "\n",
    "Weekly support is a 12 item scale scored on a 5 point Likert-scale (0-4).\n",
    "It is based on the The [Interpersonal Support Evaluation List](https://www.cmu.edu/common-cold-project/measures-by-study/psychological-and-social-constructs/social-relationships-loneliness-measures/social-support.html), using the [ISEL-12 version](https://www.cmu.edu/common-cold-project/measures-by-study/psychological-and-social-constructs/social-relationships-loneliness-measures/isel_12_item.pdf).\n",
    "\n",
    "Daily social support is a custom measure developed by [Leo Huang](https://www.leohuangneuro.com/about-me), [Cendri Hutcherson](https://www.linkedin.com/in/cendri-hutcherson-3327a161/?originalSubdomain=ca), and [Daniel J Wilson](https://github.com/danieljwilson).\n",
    "\n",
    "The items fall under 3 categories 👇\n",
    "\n",
    "![Example Image](../../3_3_6_inputs/images/ss_daily_items.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Weekly Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_df = df.loc[df['ResultIdentifier'].str.startswith('ss_weekly_')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Munge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Answers numeric\n",
    "ss_df['Answers'] = pd.to_numeric(ss_df['Answers'], errors='coerce')\n",
    "\n",
    "# Reverse score the specified items\n",
    "reverse_items = ['ss_weekly_1', 'ss_weekly_4', 'ss_weekly_5', 'ss_weekly_7', 'ss_weekly_10', 'ss_weekly_12']\n",
    "ss_df.loc[ss_df['ResultIdentifier'].isin(reverse_items) & (ss_df['Answers'] != 0), 'Answers'] = 5 - ss_df['Answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total score for each participant\n",
    "total_scores = ss_df.groupby(['ParticipantIdentifier', 'trial_date'])['Answers'].sum().reset_index()\n",
    "total_scores.rename(columns={'Answers': 'ss_weekly_ISEL12_totalScore'}, inplace=True)\n",
    "\n",
    "# Calculate subscale scores\n",
    "appraisal_items = ['ss_weekly_1', 'ss_weekly_2', 'ss_weekly_3', 'ss_weekly_4']\n",
    "belonging_items = ['ss_weekly_5', 'ss_weekly_6', 'ss_weekly_7', 'ss_weekly_8']\n",
    "tangible_items = ['ss_weekly_9', 'ss_weekly_10', 'ss_weekly_11', 'ss_weekly_12']\n",
    "\n",
    "appraisal_scores = ss_df[ss_df['ResultIdentifier'].isin(appraisal_items)].groupby(['ParticipantIdentifier', 'trial_date'])['Answers'].sum().reset_index()\n",
    "appraisal_scores.rename(columns={'Answers': 'ss_weekly_ISEL12_appraisal'}, inplace=True)\n",
    "\n",
    "belonging_scores = ss_df[ss_df['ResultIdentifier'].isin(belonging_items)].groupby(['ParticipantIdentifier', 'trial_date'])['Answers'].sum().reset_index()\n",
    "belonging_scores.rename(columns={'Answers': 'ss_weekly_ISEL12_belonging'}, inplace=True)\n",
    "\n",
    "tangible_scores = ss_df[ss_df['ResultIdentifier'].isin(tangible_items)].groupby(['ParticipantIdentifier', 'trial_date'])['Answers'].sum().reset_index()\n",
    "tangible_scores.rename(columns={'Answers': 'ss_weekly_ISEL12_tangible'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "ss_df = total_scores.merge(appraisal_scores, on=['ParticipantIdentifier', 'trial_date']).merge(belonging_scores, on=['ParticipantIdentifier', 'trial_date']).merge(tangible_scores, on=['ParticipantIdentifier', 'trial_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 29/29 [00:00<00:00, 30.28it/s, Completed]                                                       \n",
      "Generate report structure: 100%|██████████| 1/1 [00:00<00:00,  2.10it/s]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 219.48it/s]\n"
     ]
    }
   ],
   "source": [
    "profile = ProfileReport(ss_df.iloc[:,2:], title=f\"ISEL 12 Social Support Weekly Run {run_num} | Pandas Profiling Report\")\n",
    "profile.to_file(eda_reports_path + f\"ss_weekly_run{run_num}.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "if run_num ==1:\n",
    "    # run 1\n",
    "    print('No social support weekly measure for run 1...')\n",
    "if run_num ==2:\n",
    "    # run 2\n",
    "    ss_df.to_csv(save_path + 'run2_ss_weekly.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Daily Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily_ss = df.loc[df['ResultIdentifier'].str.startswith('ss_')].reset_index(drop=True)\n",
    "\n",
    "# Remove weekly measures\n",
    "df_daily_ss = df_daily_ss.loc[~df_daily_ss['ResultIdentifier'].str.contains('_weekly_')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to Wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert values in 'Answers' column to numeric where possible, else leave as string\n",
    "# df_daily_sr['Answers'] = pd.to_numeric(df_daily_sr['Answers'], errors='coerce').fillna(df_daily_sr['Answers'])\n",
    "\n",
    "# Pivot the data\n",
    "df_daily_ss_wide = df_daily_ss.pivot_table(index=[\"ParticipantIdentifier\", \"trial_date\"],\n",
    "                                           columns='ResultIdentifier',\n",
    "                                           values='Answers',\n",
    "                                           aggfunc=lambda x: ' '.join(map(str, x))).reset_index()\n",
    "# get rid of name on index\n",
    "df_daily_ss_wide = df_daily_ss_wide.rename_axis(None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>ss_desired_appraisal</th>\n",
       "      <th>ss_desired_belonging</th>\n",
       "      <th>ss_desired_tangible</th>\n",
       "      <th>ss_received_appraisal</th>\n",
       "      <th>ss_received_appraisal_satisfaction</th>\n",
       "      <th>ss_received_belonging</th>\n",
       "      <th>ss_received_belonging_satisfaction</th>\n",
       "      <th>ss_received_tangible</th>\n",
       "      <th>ss_received_tangible_satisfaction</th>\n",
       "      <th>ss_sought_appraisal</th>\n",
       "      <th>ss_sought_belonging</th>\n",
       "      <th>ss_sought_tangible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-01-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-02-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ParticipantIdentifier  trial_date ss_desired_appraisal  \\\n",
       "0  0151d9f1-1644-4437-805e-02f5e244a690  2023-01-30                  1.0   \n",
       "1  0151d9f1-1644-4437-805e-02f5e244a690  2023-01-31                  0.0   \n",
       "2  0151d9f1-1644-4437-805e-02f5e244a690  2023-02-01                  0.0   \n",
       "3  0151d9f1-1644-4437-805e-02f5e244a690  2023-02-02                  0.0   \n",
       "4  0151d9f1-1644-4437-805e-02f5e244a690  2023-02-03                  0.0   \n",
       "\n",
       "  ss_desired_belonging ss_desired_tangible ss_received_appraisal  \\\n",
       "0                  1.0                 0.0                   0.0   \n",
       "1                  0.0                 0.0                   0.0   \n",
       "2                  1.0                 0.0                   0.0   \n",
       "3                  0.0                 0.0                   1.0   \n",
       "4                  0.0                 0.0                   2.0   \n",
       "\n",
       "  ss_received_appraisal_satisfaction ss_received_belonging  \\\n",
       "0                                NaN                   0.0   \n",
       "1                                NaN                   1.0   \n",
       "2                                NaN                   0.0   \n",
       "3                                4.0                   1.0   \n",
       "4                                5.0                   2.0   \n",
       "\n",
       "  ss_received_belonging_satisfaction ss_received_tangible  \\\n",
       "0                                NaN                  2.0   \n",
       "1                                6.0                  0.0   \n",
       "2                                NaN                  0.0   \n",
       "3                                4.0                  0.0   \n",
       "4                                5.0                  1.0   \n",
       "\n",
       "  ss_received_tangible_satisfaction ss_sought_appraisal ss_sought_belonging  \\\n",
       "0                               4.0                 0.0                 0.0   \n",
       "1                               NaN                 0.0                 0.0   \n",
       "2                               NaN                 0.0                 0.0   \n",
       "3                               NaN                 0.0                 0.0   \n",
       "4                               2.0                 0.0                 0.0   \n",
       "\n",
       "  ss_sought_tangible  \n",
       "0                0.0  \n",
       "1                0.0  \n",
       "2                0.0  \n",
       "3                0.0  \n",
       "4                0.0  "
      ]
     },
     "execution_count": 812,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_daily_ss_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to numeric where appropriate\n",
    "df_daily_ss_wide.loc[:,df_daily_ss_wide.columns[~df_daily_ss_wide.columns.isin(non_numeric_cols + ['ParticipantIdentifier', 'trial_date'])]] = df_daily_ss_wide.loc[:,df_daily_ss_wide.columns[~df_daily_ss_wide.columns.isin(non_numeric_cols)]].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/ydata_profiling/utils/dataframe.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={\"index\": \"df_index\"}, inplace=True)\n",
      "Summarize dataset: 100%|██████████| 166/166 [00:08<00:00, 19.90it/s, Completed]                                                                    \n",
      "Generate report structure: 100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:01<00:00,  1.25s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 168.22it/s]\n"
     ]
    }
   ],
   "source": [
    "profile = ProfileReport(df_daily_ss_wide.iloc[:,2:], title=f\"Social Support Daily Run {run_num} | Pandas Profiling Report\")\n",
    "profile.to_file(eda_reports_path + f\"ss_daily_run{run_num}.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "if run_num ==1:\n",
    "    # run 1\n",
    "    print('No social support daily measure for run 1...')\n",
    "if run_num ==2:\n",
    "    # run 2\n",
    "    df_daily_ss_wide.to_csv(save_path + 'run2_ss_daily.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Food Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted existing df\n",
      "deleted daily food_df\n"
     ]
    }
   ],
   "source": [
    "# erase df if it already exists\n",
    "if 'df' in globals():\n",
    "    del(df)\n",
    "    print('deleted existing df')\n",
    "\n",
    "if 'food_df' in globals():\n",
    "    del(food_df)\n",
    "    print('deleted daily food_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_num ==1:\n",
    "    # run 1\n",
    "    df = pd.read_csv(save_path + 'run1_survey_results.csv')\n",
    "if run_num ==2:\n",
    "    # run 2\n",
    "    df = pd.read_csv(save_path + 'run2_survey_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Select Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df = df.loc[df['ResultIdentifier'].str.startswith('rating_')].reset_index(drop=True)\n",
    "hunger =  df.loc[df['ResultIdentifier']=='Hunger_Screen'].reset_index(drop=True)\n",
    "hunger.rename(columns={\"Answers\": \"task_food_hunger_level\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to Wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe from long to wide format\n",
    "food_df_wide = food_df.pivot_table(index=[\"ParticipantIdentifier\", \"trial_date\"], \n",
    "                              columns='ResultIdentifier', \n",
    "                              values='Answers', \n",
    "                              aggfunc='first').reset_index()\n",
    "\n",
    "# get rid of name on index\n",
    "food_df_wide = food_df_wide.rename_axis(None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>task_food_1_rating</th>\n",
       "      <th>task_food_1_rt</th>\n",
       "      <th>task_food_1_item</th>\n",
       "      <th>task_food_1_category</th>\n",
       "      <th>task_food_10_rating</th>\n",
       "      <th>task_food_10_rt</th>\n",
       "      <th>task_food_10_item</th>\n",
       "      <th>task_food_10_category</th>\n",
       "      <th>...</th>\n",
       "      <th>task_food_7_item</th>\n",
       "      <th>task_food_7_category</th>\n",
       "      <th>task_food_8_rating</th>\n",
       "      <th>task_food_8_rt</th>\n",
       "      <th>task_food_8_item</th>\n",
       "      <th>task_food_8_category</th>\n",
       "      <th>task_food_9_rating</th>\n",
       "      <th>task_food_9_rt</th>\n",
       "      <th>task_food_9_item</th>\n",
       "      <th>task_food_9_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-01-30</td>\n",
       "      <td>-5</td>\n",
       "      <td>6712</td>\n",
       "      <td>carrotSalad</td>\n",
       "      <td>hu</td>\n",
       "      <td>3</td>\n",
       "      <td>2451</td>\n",
       "      <td>breakfastTacos</td>\n",
       "      <td>ht</td>\n",
       "      <td>...</td>\n",
       "      <td>grapeNuts</td>\n",
       "      <td>hu</td>\n",
       "      <td>-4</td>\n",
       "      <td>2477</td>\n",
       "      <td>pancakes</td>\n",
       "      <td>ut</td>\n",
       "      <td>1</td>\n",
       "      <td>2615</td>\n",
       "      <td>hardBoiledEgg</td>\n",
       "      <td>hu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>3104</td>\n",
       "      <td>bagel</td>\n",
       "      <td>ht</td>\n",
       "      <td>-1</td>\n",
       "      <td>2682</td>\n",
       "      <td>pizza</td>\n",
       "      <td>ut</td>\n",
       "      <td>...</td>\n",
       "      <td>eggMcMuffin</td>\n",
       "      <td>ut</td>\n",
       "      <td>-3</td>\n",
       "      <td>1964</td>\n",
       "      <td>cocaCola</td>\n",
       "      <td>ut</td>\n",
       "      <td>1</td>\n",
       "      <td>2298</td>\n",
       "      <td>viennoisChocolat</td>\n",
       "      <td>ut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3448</td>\n",
       "      <td>fruitSalad</td>\n",
       "      <td>ht</td>\n",
       "      <td>-4</td>\n",
       "      <td>3877</td>\n",
       "      <td>ovaltine</td>\n",
       "      <td>hu</td>\n",
       "      <td>...</td>\n",
       "      <td>chilaquiles</td>\n",
       "      <td>ut</td>\n",
       "      <td>1</td>\n",
       "      <td>4292</td>\n",
       "      <td>hasbrowns</td>\n",
       "      <td>ut</td>\n",
       "      <td>0</td>\n",
       "      <td>7124</td>\n",
       "      <td>omelette2</td>\n",
       "      <td>ht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-02-02</td>\n",
       "      <td>1</td>\n",
       "      <td>3462</td>\n",
       "      <td>crepe2</td>\n",
       "      <td>ut</td>\n",
       "      <td>-2</td>\n",
       "      <td>2375</td>\n",
       "      <td>fruitSalad</td>\n",
       "      <td>ht</td>\n",
       "      <td>...</td>\n",
       "      <td>croissant</td>\n",
       "      <td>ut</td>\n",
       "      <td>-3</td>\n",
       "      <td>2475</td>\n",
       "      <td>fruitLoops</td>\n",
       "      <td>ut</td>\n",
       "      <td>-5</td>\n",
       "      <td>1825</td>\n",
       "      <td>ovaltine</td>\n",
       "      <td>hu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>-5</td>\n",
       "      <td>2245</td>\n",
       "      <td>sardines</td>\n",
       "      <td>hu</td>\n",
       "      <td>-4</td>\n",
       "      <td>1776</td>\n",
       "      <td>Kimchi</td>\n",
       "      <td>hu</td>\n",
       "      <td>...</td>\n",
       "      <td>pancakes</td>\n",
       "      <td>ut</td>\n",
       "      <td>-1</td>\n",
       "      <td>2327</td>\n",
       "      <td>fruitSalad</td>\n",
       "      <td>ht</td>\n",
       "      <td>-2</td>\n",
       "      <td>2176</td>\n",
       "      <td>shreddedWheat</td>\n",
       "      <td>hu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ParticipantIdentifier  trial_date  task_food_1_rating  \\\n",
       "0  0151d9f1-1644-4437-805e-02f5e244a690  2023-01-30                  -5   \n",
       "1  0151d9f1-1644-4437-805e-02f5e244a690  2023-01-31                   2   \n",
       "2  0151d9f1-1644-4437-805e-02f5e244a690  2023-02-01                   1   \n",
       "3  0151d9f1-1644-4437-805e-02f5e244a690  2023-02-02                   1   \n",
       "4  0151d9f1-1644-4437-805e-02f5e244a690  2023-02-03                  -5   \n",
       "\n",
       "   task_food_1_rt task_food_1_item task_food_1_category  task_food_10_rating  \\\n",
       "0            6712      carrotSalad                   hu                    3   \n",
       "1            3104            bagel                   ht                   -1   \n",
       "2            3448       fruitSalad                   ht                   -4   \n",
       "3            3462           crepe2                   ut                   -2   \n",
       "4            2245         sardines                   hu                   -4   \n",
       "\n",
       "   task_food_10_rt task_food_10_item task_food_10_category  ...  \\\n",
       "0             2451    breakfastTacos                    ht  ...   \n",
       "1             2682             pizza                    ut  ...   \n",
       "2             3877          ovaltine                    hu  ...   \n",
       "3             2375        fruitSalad                    ht  ...   \n",
       "4             1776            Kimchi                    hu  ...   \n",
       "\n",
       "   task_food_7_item  task_food_7_category task_food_8_rating task_food_8_rt  \\\n",
       "0         grapeNuts                    hu                 -4           2477   \n",
       "1       eggMcMuffin                    ut                 -3           1964   \n",
       "2       chilaquiles                    ut                  1           4292   \n",
       "3         croissant                    ut                 -3           2475   \n",
       "4          pancakes                    ut                 -1           2327   \n",
       "\n",
       "   task_food_8_item  task_food_8_category task_food_9_rating task_food_9_rt  \\\n",
       "0          pancakes                    ut                  1           2615   \n",
       "1          cocaCola                    ut                  1           2298   \n",
       "2         hasbrowns                    ut                  0           7124   \n",
       "3        fruitLoops                    ut                 -5           1825   \n",
       "4        fruitSalad                    ht                 -2           2176   \n",
       "\n",
       "   task_food_9_item  task_food_9_category  \n",
       "0     hardBoiledEgg                    hu  \n",
       "1  viennoisChocolat                    ut  \n",
       "2         omelette2                    ht  \n",
       "3          ovaltine                    hu  \n",
       "4     shreddedWheat                    hu  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 737,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Filter out columns that start with \"rating_\"\n",
    "rating_columns = [col for col in food_df_wide.columns if col.startswith('rating_')]\n",
    "\n",
    "# Define a function to extract required information from the 'name' value\n",
    "def extract_name_info(json_data):\n",
    "    # Check if 'name' key exists in json_data and is of type string\n",
    "    name_str = json_data.get('name', \"\")\n",
    "    \n",
    "    if not isinstance(name_str, str):\n",
    "        return None, None\n",
    "\n",
    "    # Extract task_food_item\n",
    "    item_start = name_str.rfind('_') + 1\n",
    "    item_end = name_str.rfind('.jpg')\n",
    "    task_food_item = name_str[item_start:item_end] if item_start != -1 and item_end != -1 else None\n",
    "    \n",
    "    # Extract task_food_category\n",
    "    category_start = name_str.rfind('/') + 1\n",
    "    category_end = name_str.rfind('_')\n",
    "    task_food_category = name_str[category_start:category_end] if category_start != -1 and category_end != -1 else None\n",
    "    \n",
    "    return task_food_item, task_food_category\n",
    "\n",
    "# Modify the function to handle potential strings in columns\n",
    "def parse_json(entry):\n",
    "    try:\n",
    "        return json.loads(entry)\n",
    "    except (TypeError, json.JSONDecodeError):\n",
    "        return {}\n",
    "\n",
    "# Re-parse the JSON strings using the modified function\n",
    "for col in rating_columns:\n",
    "    food_df_wide[col] = food_df_wide[col].apply(parse_json)\n",
    "\n",
    "# Re-extract the required values using the modified function\n",
    "for col in rating_columns:\n",
    "    # Extract required information\n",
    "    food_df_wide[col + '_rating'] = food_df_wide[col].apply(lambda x: x.get('rating', None))\n",
    "    food_df_wide[col + '_rt'] = food_df_wide[col].apply(lambda x: x.get('reactionTime', None))\n",
    "    food_df_wide[col + '_item'], food_df_wide[col + '_category'] = zip(*food_df_wide[col].apply(extract_name_info))\n",
    "\n",
    "# Drop the original \"rating_\" columns as they are not needed anymore\n",
    "food_df_wide = food_df_wide.drop(columns=rating_columns)\n",
    "\n",
    "# Convert all 'task_food_rating' columns to dtype int\n",
    "rating_cols_to_convert = [col for col in food_df_wide.columns if '_rating' in col]\n",
    "\n",
    "for col in rating_cols_to_convert:\n",
    "    food_df_wide[col] = food_df_wide[col].astype(np.int64)  # Using 'Int64' to handle potential NaN values\n",
    "\n",
    "# Rename columns that start with 'rating' to start with 'task_food'\n",
    "food_df_wide.columns = ['task_food' + col[len('rating'):] if col.startswith('rating') else col for col in food_df_wide.columns]\n",
    "\n",
    "food_df_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>task_food_1_rating</th>\n",
       "      <th>task_food_1_rt</th>\n",
       "      <th>task_food_1_item</th>\n",
       "      <th>task_food_1_category</th>\n",
       "      <th>task_food_10_rating</th>\n",
       "      <th>task_food_10_rt</th>\n",
       "      <th>task_food_10_item</th>\n",
       "      <th>task_food_10_category</th>\n",
       "      <th>...</th>\n",
       "      <th>task_food_7_category</th>\n",
       "      <th>task_food_8_rating</th>\n",
       "      <th>task_food_8_rt</th>\n",
       "      <th>task_food_8_item</th>\n",
       "      <th>task_food_8_category</th>\n",
       "      <th>task_food_9_rating</th>\n",
       "      <th>task_food_9_rt</th>\n",
       "      <th>task_food_9_item</th>\n",
       "      <th>task_food_9_category</th>\n",
       "      <th>task_food_hunger_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-01-30</td>\n",
       "      <td>-5</td>\n",
       "      <td>6712</td>\n",
       "      <td>carrotSalad</td>\n",
       "      <td>hu</td>\n",
       "      <td>3</td>\n",
       "      <td>2451</td>\n",
       "      <td>breakfastTacos</td>\n",
       "      <td>ht</td>\n",
       "      <td>...</td>\n",
       "      <td>hu</td>\n",
       "      <td>-4</td>\n",
       "      <td>2477</td>\n",
       "      <td>pancakes</td>\n",
       "      <td>ut</td>\n",
       "      <td>1</td>\n",
       "      <td>2615</td>\n",
       "      <td>hardBoiledEgg</td>\n",
       "      <td>hu</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>3104</td>\n",
       "      <td>bagel</td>\n",
       "      <td>ht</td>\n",
       "      <td>-1</td>\n",
       "      <td>2682</td>\n",
       "      <td>pizza</td>\n",
       "      <td>ut</td>\n",
       "      <td>...</td>\n",
       "      <td>ut</td>\n",
       "      <td>-3</td>\n",
       "      <td>1964</td>\n",
       "      <td>cocaCola</td>\n",
       "      <td>ut</td>\n",
       "      <td>1</td>\n",
       "      <td>2298</td>\n",
       "      <td>viennoisChocolat</td>\n",
       "      <td>ut</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3448</td>\n",
       "      <td>fruitSalad</td>\n",
       "      <td>ht</td>\n",
       "      <td>-4</td>\n",
       "      <td>3877</td>\n",
       "      <td>ovaltine</td>\n",
       "      <td>hu</td>\n",
       "      <td>...</td>\n",
       "      <td>ut</td>\n",
       "      <td>1</td>\n",
       "      <td>4292</td>\n",
       "      <td>hasbrowns</td>\n",
       "      <td>ut</td>\n",
       "      <td>0</td>\n",
       "      <td>7124</td>\n",
       "      <td>omelette2</td>\n",
       "      <td>ht</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-02-02</td>\n",
       "      <td>1</td>\n",
       "      <td>3462</td>\n",
       "      <td>crepe2</td>\n",
       "      <td>ut</td>\n",
       "      <td>-2</td>\n",
       "      <td>2375</td>\n",
       "      <td>fruitSalad</td>\n",
       "      <td>ht</td>\n",
       "      <td>...</td>\n",
       "      <td>ut</td>\n",
       "      <td>-3</td>\n",
       "      <td>2475</td>\n",
       "      <td>fruitLoops</td>\n",
       "      <td>ut</td>\n",
       "      <td>-5</td>\n",
       "      <td>1825</td>\n",
       "      <td>ovaltine</td>\n",
       "      <td>hu</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>-5</td>\n",
       "      <td>2245</td>\n",
       "      <td>sardines</td>\n",
       "      <td>hu</td>\n",
       "      <td>-4</td>\n",
       "      <td>1776</td>\n",
       "      <td>Kimchi</td>\n",
       "      <td>hu</td>\n",
       "      <td>...</td>\n",
       "      <td>ut</td>\n",
       "      <td>-1</td>\n",
       "      <td>2327</td>\n",
       "      <td>fruitSalad</td>\n",
       "      <td>ht</td>\n",
       "      <td>-2</td>\n",
       "      <td>2176</td>\n",
       "      <td>shreddedWheat</td>\n",
       "      <td>hu</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ParticipantIdentifier  trial_date  task_food_1_rating  \\\n",
       "0  0151d9f1-1644-4437-805e-02f5e244a690  2023-01-30                  -5   \n",
       "1  0151d9f1-1644-4437-805e-02f5e244a690  2023-01-31                   2   \n",
       "2  0151d9f1-1644-4437-805e-02f5e244a690  2023-02-01                   1   \n",
       "3  0151d9f1-1644-4437-805e-02f5e244a690  2023-02-02                   1   \n",
       "4  0151d9f1-1644-4437-805e-02f5e244a690  2023-02-03                  -5   \n",
       "\n",
       "   task_food_1_rt task_food_1_item task_food_1_category  task_food_10_rating  \\\n",
       "0            6712      carrotSalad                   hu                    3   \n",
       "1            3104            bagel                   ht                   -1   \n",
       "2            3448       fruitSalad                   ht                   -4   \n",
       "3            3462           crepe2                   ut                   -2   \n",
       "4            2245         sardines                   hu                   -4   \n",
       "\n",
       "   task_food_10_rt task_food_10_item task_food_10_category  ...  \\\n",
       "0             2451    breakfastTacos                    ht  ...   \n",
       "1             2682             pizza                    ut  ...   \n",
       "2             3877          ovaltine                    hu  ...   \n",
       "3             2375        fruitSalad                    ht  ...   \n",
       "4             1776            Kimchi                    hu  ...   \n",
       "\n",
       "   task_food_7_category  task_food_8_rating task_food_8_rt task_food_8_item  \\\n",
       "0                    hu                  -4           2477         pancakes   \n",
       "1                    ut                  -3           1964         cocaCola   \n",
       "2                    ut                   1           4292        hasbrowns   \n",
       "3                    ut                  -3           2475       fruitLoops   \n",
       "4                    ut                  -1           2327       fruitSalad   \n",
       "\n",
       "   task_food_8_category  task_food_9_rating task_food_9_rt  task_food_9_item  \\\n",
       "0                    ut                   1           2615     hardBoiledEgg   \n",
       "1                    ut                   1           2298  viennoisChocolat   \n",
       "2                    ut                   0           7124         omelette2   \n",
       "3                    ut                  -5           1825          ovaltine   \n",
       "4                    ht                  -2           2176     shreddedWheat   \n",
       "\n",
       "   task_food_9_category  task_food_hunger_level  \n",
       "0                    hu                     3.0  \n",
       "1                    ut                     3.0  \n",
       "2                    ht                     2.0  \n",
       "3                    hu                     0.0  \n",
       "4                    hu                     0.0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 738,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add hunger value\n",
    "food_df_wide = food_df_wide.merge(hunger[['ParticipantIdentifier', 'trial_date', 'task_food_hunger_level']],\n",
    "                                  on=['ParticipantIdentifier', 'trial_date'],\n",
    "                                  how='left')\n",
    "\n",
    "# Convert hunger to int\n",
    "food_df_wide['task_food_hunger_level'] = food_df_wide['task_food_hunger_level'].astype(np.float32)\n",
    "\n",
    "food_df_wide.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 1032/1032 [00:47<00:00, 21.55it/s, Completed]                                             \n",
      "Generate report structure: 100%|██████████| 1/1 [00:11<00:00, 11.50s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:07<00:00,  7.85s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 17.94it/s]\n"
     ]
    }
   ],
   "source": [
    "profile = ProfileReport(food_df_wide.iloc[:,2:], title=f\"Food Task Run {run_num} | Pandas Profiling Report\")\n",
    "profile.to_file(eda_reports_path + f\"task_food_run{run_num}.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean\n",
    "\n",
    "We had numerous outlier RT values.\n",
    "\n",
    "We used the $z$ transform method to flag outliers (in the column `task_food_rt_flag`) based on Berger and Kiefer ([2021](https://doi.org/10.3389/fpsyg.2021.675558)) where they tested multiple methods of removing outliers from rt data.\n",
    "\n",
    "We also set the flag threshold to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean outlier rt values\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Step 1: Filter out rt cols\n",
    "rt_columns = [col for col in food_df_wide.columns if col.endswith('_rt')]\n",
    "\n",
    "# Step 2: Compute the z-scores for these columns\n",
    "for col in rt_columns:\n",
    "    z_col_name = col + '_z'\n",
    "    food_df_wide[z_col_name] = zscore(food_df_wide[col], nan_policy='omit')\n",
    "\n",
    "# Step 3: Check each row for values above a threshold in the '_z' columns\n",
    "threshold = 3  # Define a threshold value\n",
    "z_columns = [col + '_z' for col in rt_columns]\n",
    "food_df_wide['task_food_rt_flag'] = food_df_wide[z_columns].apply(lambda row: any(abs(val) > threshold for val in row), axis=1)\n",
    "\n",
    "z_columns_to_drop = [col for col in food_df_wide.columns if col.endswith('_z')]\n",
    "wide_df = food_df_wide.drop(columns=z_columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df with one participant ID for every trial_date\n",
    "\n",
    "# Create a series of dates from '2022-09-27' to '2022-12-20'\n",
    "if run_num == 1:\n",
    "    date_series = pd.date_range(start='2022-09-27', end='2022-12-20')\n",
    "elif run_num == 2:\n",
    "    date_series = pd.date_range(start='2023-01-30', end='2023-04-24')\n",
    "\n",
    "ids_series = subjects\n",
    "\n",
    "# Create a dataframe using a cartesian product of the two series\n",
    "df_complete_idDate = pd.DataFrame({\n",
    "    'ParticipantIdentifier': np.repeat(ids_series, len(date_series)),\n",
    "    'trial_date': date_series.tolist() * len(ids_series)\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "# Convert trial_date to datetime.date\n",
    "df_complete_idDate['trial_date'] = pd.to_datetime(df_complete_idDate['trial_date']).dt.date\n",
    "food_df_wide['trial_date'] = pd.to_datetime(food_df_wide['trial_date']).dt.date\n",
    "\n",
    "# Join with affect df\n",
    "food_df_wide = df_complete_idDate.merge(food_df_wide, how='left', on=['ParticipantIdentifier', 'trial_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "if run_num == 1:\n",
    "    # run 1\n",
    "    print('Task was not part of run 1...')\n",
    "if run_num == 2:\n",
    "    # run 2\n",
    "    food_df_wide.to_csv(save_path + 'run2_task_food.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The n-back sequence was created as follows (where `n` indicates whether it is 2-back or 3-back)\n",
    "\n",
    "```javascript\n",
    "function constructSequence(n) {\n",
    "    const ls = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10];\n",
    "    let number = 0;\n",
    "    let char = \"\";\n",
    "    const alphabet = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'];\n",
    "    const sequence = []\n",
    "    for (let i = 0; i < SEQ_LEN; i++) {\n",
    "        number = ls[Math.floor(Math.random() * ls.length)];\n",
    "        if (i >= n && number <= 2) {\n",
    "            char = sequence[i - n];\n",
    "            //console.log(\"in if ===>\", char, sequence, i, n)\n",
    "        } else {\n",
    "            char = alphabet[Math.floor(Math.random() * alphabet.length)];\n",
    "            //console.log(\"in else ==>\", char)\n",
    "        }\n",
    "        sequence.push(char)\n",
    "\n",
    "    }\n",
    "    return sequence;\n",
    "}\n",
    "```\n",
    "\n",
    "Given that `ls` has a length of 11 this means that on average there is a 3/11 chance of having a match (for positions 3 and onward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_num ==1:\n",
    "    # run 1\n",
    "    df = pd.read_csv(save_path + 'run1_survey_results.csv')\n",
    "if run_num ==2:\n",
    "    # run 2\n",
    "    df = pd.read_csv(save_path + 'run2_survey_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [],
   "source": [
    "nback_df = df.loc[df.ResultIdentifier == 'task_custom_nBack_results'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only need this as bids were being overwritten when the bid was NOT accepted with a 0 bid...\n",
    "# this was fixed on Feb 7, but using the actual bid value will also continue to work...\n",
    "\n",
    "nback_df_bids = df.loc[df.ResultIdentifier == 'task_custom_nBack_diffSelect'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"bid\":70,\"randomNumber\":74,\"correctness\":0.9545454545454546,\"earnings\":74,\"mode\":\"hard\",\"matched\":4,\"missed\":0,\"sequence\":[\"T\",\"F\",\"A\",\"O\",\"K\",\"A\",\"C\",\"G\",\"R\",\"Z\",\"E\",\"T\",\"R\",\"Y\",\"T\",\"S\",\"Z\",\"R\",\"G\",\"Z\",\"B\",\"G\",\"A\",\"W\",\"B\"],\"falseAlarm\":1,\"indexOfMatchClicked\":[6,15,18,20,22]}'"
      ]
     },
     "execution_count": 873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nback_df.Answers[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse json to create columns\n",
    "for i in range(nback_df.shape[0]):\n",
    "    nback_df.loc[i, 'task_nback_bid'] = json.loads(nback_df_bids.Answers[i])['bid']\n",
    "    nback_df.loc[i, 'task_nback_rndNum'] = json.loads(nback_df.Answers[i])['randomNumber']    \n",
    "    nback_df.loc[i, 'task_nback_mode'] = json.loads(nback_df.Answers[i])['mode']\n",
    "    nback_df.loc[i, 'task_nback_matched'] = json.loads(nback_df.Answers[i])['matched']    \n",
    "    nback_df.loc[i, 'task_nback_missed'] = json.loads(nback_df.Answers[i])['missed']    \n",
    "    nback_df.loc[i, 'task_nback_falseAlarm'] = json.loads(nback_df.Answers[i])['falseAlarm']\n",
    "    nback_df.loc[i, 'task_nback_trialCount'] = len(json.loads(nback_df.Answers[i])['sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [],
   "source": [
    "nback_df = nback_df.drop(['ResultIdentifier', 'Answers', 'EndDate', 'datetime'], axis=1)\n",
    "nback_df = nback_df.rename(columns={\"time\": \"task_nback_time\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the following metrics for Binary Classification:\n",
    "\n",
    "1. **Accuracy**: \n",
    "   The proportion of correctly predicted classifications in the total predictions made.\n",
    "   $$\n",
    "   \\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}\n",
    "   $$\n",
    "\n",
    "2. **Precision** (or Positive Predictive Value):\n",
    "   The proportion of positive identifications that were actually correct.\n",
    "   $$\n",
    "   \\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\n",
    "   $$\n",
    "\n",
    "3. **Recall** (or Sensitivity or True Positive Rate):\n",
    "   The proportion of actual positives that were identified correctly.\n",
    "   $$\n",
    "   \\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n",
    "   $$\n",
    "\n",
    "4. **Specificity** (or True Negative Rate):\n",
    "   The proportion of actual negatives that were identified correctly.\n",
    "   $$\n",
    "   \\text{Specificity} = \\frac{\\text{TN}}{\\text{TN} + \\text{FP}}\n",
    "   $$\n",
    "\n",
    "5. **False Alarm Rate** (or Fall-Out):\n",
    "   The proportion of actual negatives that were incorrectly classified as positive.\n",
    "   $$\n",
    "   \\text{False Alarm Rate} = \\frac{\\text{FP}}{\\text{TN} + \\text{FP}}\n",
    "   $$\n",
    "\n",
    "6. **F1 Score**:\n",
    "   The harmonic mean of precision and recall, giving a balance between the two.\n",
    "   $$\n",
    "   \\text{F1 Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "   $$\n",
    "\n",
    "7. **Matthews Correlation Coefficient (MCC)**:\n",
    "   A metric that takes into account true and false positives and negatives and is generally regarded as a balanced measure which can be used even if the classes are of very different sizes.\n",
    "   $$\n",
    "   \\text{MCC} = \\frac{\\text{TP} \\times \\text{TN} - \\text{FP} \\times \\text{FN}}{\\sqrt{(\\text{TP} + \\text{FP})(\\text{TP} + \\text{FN})(\\text{TN} + \\text{FP})(\\text{TN} + \\text{FN})}}\n",
    "   $$\n",
    "\n",
    "8. **Bias (C or criterion)**:\n",
    "   A metric from signal detection theory that indicates the participant's response bias. A positive value indicates a bias toward saying \"no\" (\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: invalid value encountered in sqrt\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "truePos = nback_df.task_nback_matched\n",
    "trueNeg = nback_df.task_nback_trialCount - nback_df.task_nback_matched - nback_df.task_nback_missed - nback_df.task_nback_falseAlarm\n",
    "falsePos = nback_df.task_nback_falseAlarm\n",
    "falseNeg = nback_df.task_nback_missed\n",
    "\n",
    "# proportion of correct classifications in total predictions made\n",
    "nback_df['task_nback_accuracy'] = (truePos + trueNeg) / (truePos + trueNeg + falsePos + falseNeg)\n",
    "# positive predictive value (hit rate)\n",
    "nback_df['task_nback_precision'] = truePos / (truePos + falsePos)\n",
    "# true positive rate (sensitivity)\n",
    "nback_df['task_nback_recall'] = truePos / (truePos + falseNeg)\n",
    "# true negative rate (false_alarm_rate)\n",
    "nback_df['task_nback_specificity'] = trueNeg / (trueNeg + falsePos)\n",
    "# Proportion of times the participant incorrectly indicates an n-back match when there wasn't one.\n",
    "nback_df['task_nback_falseAlarmRate'] = falsePos / (trueNeg + falsePos)\n",
    "# Harmonic mean of precision and recall, giving a balance between the two\n",
    "nback_df['task_nback_F1'] = 2 * ((nback_df['task_nback_precision'] * nback_df['task_nback_recall'])/(nback_df['task_nback_precision'] + nback_df['task_nback_recall']))\n",
    "# Matthews Correlation Coefficient (MCC):\n",
    "# It takes into account true and false positives and negatives and is generally regarded as a balanced measure which can be used even if the classes are of very different sizes.\n",
    "nback_df['task_nback_MCC'] = ((truePos * trueNeg) - (falsePos * falseNeg)) / (np.sqrt((truePos + falsePos)*(truePos + falseNeg) * (trueNeg + falsePos) * (trueNeg + falseNeg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lw/ys_1b9sj08s904m4402qr0bm0000gn/T/ipykernel_2454/2420366107.py:14: RuntimeWarning: invalid value encountered in add\n",
      "  C = -0.5 * (z_hit + z_fa)\n"
     ]
    }
   ],
   "source": [
    "# metric from signal detection theory\n",
    "# indicates the participant's response bias. \n",
    "# A positive value indicates a bias toward saying \"no\" (conservative)\n",
    "# A negative value indicates a bias toward saying \"yes\" (liberal).\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "def calculate_criterion(hit_rate, false_alarm_rate):\n",
    "    # Calculate the Z scores for the hit rate and false alarm rate\n",
    "    z_hit = norm.ppf(hit_rate)\n",
    "    z_fa = norm.ppf(false_alarm_rate)\n",
    "    \n",
    "    # Calculate the criterion C\n",
    "    C = -0.5 * (z_hit + z_fa)\n",
    "    \n",
    "    return C\n",
    "\n",
    "nback_df['task_nback_bias'] = calculate_criterion(nback_df['task_nback_precision'], nback_df['task_nback_falseAlarmRate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [],
   "source": [
    "# People that chose the easy mode (2-back instead of 3 back) were assigned a bid of ZERO\n",
    "# However, this suggests that they would have done the easy task for nothing, which is NOT the case\n",
    "# as they would not have done it for the max possible (100) points\n",
    "# I arbitrarily assign subjects in the easy condition a bid of 200\n",
    "\n",
    "nback_df.loc[nback_df.task_nback_bid == 0, 'task_nback_bid'] = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset:  20%|██        | 4/20 [00:00<00:00, 40.98it/s, Describe variable:task_nback_matched]   /Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/numpy/core/_methods.py:173: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/numpy/core/_methods.py:173: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n",
      "Summarize dataset:  25%|██▌       | 5/20 [00:00<00:00, 46.00it/s, Describe variable:task_nback_matched]/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/numpy/core/_methods.py:49: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/numpy/core/_methods.py:152: RuntimeWarning: invalid value encountered in reduce\n",
      "  arrmean = umr_sum(arr, axis, dtype, keepdims=True, where=where)\n",
      "Summarize dataset:  77%|███████▋  | 17/22 [00:00<00:00, 46.00it/s, Calculate auto correlation]                /Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/ydata_profiling/model/correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.\n",
      "To hide this warning, disable the calculation\n",
      "(using `df.profile_report(correlations={\"auto\": {\"calculate\": False}})`\n",
      "If this is problematic for your use case, please report this as an issue:\n",
      "https://github.com/ydataai/ydata-profiling/issues\n",
      "(include the error message: 'cannot specify integer `bins` when input data contains infinity')\n",
      "  warnings.warn(\n",
      "Summarize dataset: 100%|██████████| 194/194 [00:08<00:00, 22.21it/s, Completed]                                                   \n",
      "Generate report structure: 100%|██████████| 1/1 [00:01<00:00,  1.78s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 69.57it/s]\n"
     ]
    }
   ],
   "source": [
    "profile = ProfileReport(nback_df.iloc[:,3:], title= f\"n-Back Task Run {run_num} | Pandas Profiling Report\")\n",
    "profile.to_file(eda_reports_path + f\"nback_report_run{run_num}.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTES**\n",
    "\n",
    "Looking at the data it is clear that something wonky went on in some trials where people have matched values up to 67, and missed values of -56. \n",
    "\n",
    "Can calculate a super low probability number of matches and delete trials with any values above that - as well as any trials with negative \"missed\" values.\n",
    "\n",
    "False alarm also has a max of 136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: invalid value encountered in sqrt\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  35,   37,   42,   70,   99,  104,  115,  121,  135,  160,  177,\n",
       "         198,  409,  677,  743,  745,  823,  841, 1148, 1422, 2655, 2814,\n",
       "        2899, 3027, 3121, 3278, 3333, 3337, 3354, 3364, 3390, 3396, 3416,\n",
       "        3424, 3486, 3501, 3555, 3561, 3571, 3572, 3618, 3623, 3694, 3765,\n",
       "        3769, 3817, 3819, 3979, 4016, 4020, 4029, 4048, 4063, 4105, 4165,\n",
       "        4167, 4203, 4216, 4235, 4280, 4308, 4314, 4320, 4343, 4377, 4384,\n",
       "        4405, 4435, 4444, 4454, 4520, 4582, 4610, 4620, 4676, 4730, 4738,\n",
       "        4752, 4816, 4822, 4838, 4863, 4873, 4916, 4949, 4961, 4993, 5028,\n",
       "        5150, 5160, 5162, 5176, 5204, 5212, 5213, 5219, 5279, 5294, 5348,\n",
       "        5354, 5371, 5439, 5520, 5524, 5530, 5534, 5585, 5608, 5617, 5726,\n",
       "        5804, 5807, 5808, 5812, 5870, 5877, 5878, 5890, 5941, 5972, 6006,\n",
       "        6009, 6012, 6016, 6018, 6066, 6069, 6083, 6084, 6303, 6314]),)"
      ]
     },
     "execution_count": 880,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.sqrt((truePos + falsePos)*(truePos + falseNeg) * (trueNeg + falsePos) * (trueNeg + falseNeg)).isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParticipantIdentifier        64b148b2-590e-4f87-bcca-c7f633421fb3\n",
       "trial_date                                             2023-04-06\n",
       "task_nback_time                                          23:02:29\n",
       "task_nback_bid                                               90.0\n",
       "task_nback_rndNum                                            82.0\n",
       "task_nback_mode                                              hard\n",
       "task_nback_matched                                          154.0\n",
       "task_nback_missed                                          -144.0\n",
       "task_nback_falseAlarm                                        17.0\n",
       "task_nback_trialCount                                        25.0\n",
       "task_nback_accuracy                                          6.08\n",
       "task_nback_precision                                     0.900585\n",
       "task_nback_recall                                            15.4\n",
       "task_nback_specificity                                  -0.133333\n",
       "task_nback_falseAlarmRate                                1.133333\n",
       "task_nback_F1                                            1.701657\n",
       "task_nback_MCC                                                NaN\n",
       "task_nback_bias                                               NaN\n",
       "Name: 35, dtype: object"
      ]
     },
     "execution_count": 881,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nback_df.iloc[35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean\n",
    "\n",
    "The cleaning process consists of removing any entries/rows where there is an impossible or extrememly improbable value in any of the `matched`, `missed` and `false_alarm` columns.\n",
    "\n",
    "Impossible means that any of: \n",
    "\n",
    "1. $\\text{matches} > 23$, given that there were only 23 possibile maches for the 3-back (hard mode).\n",
    "⚡ However, I chose to eliminate any trials that had a likelihood of less than 1 in a million, which was $\\text{matches} > 17$\n",
    "2. $\\text{misses} < 0$, given that it is impossible.\n",
    "\n",
    "3. $\\text{false alarm} > 25$, given that it is impossible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6332, 18)"
      ]
     },
     "execution_count": 882,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nback_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [],
   "source": [
    "nback_df = nback_df.loc[nback_df.task_nback_matched <18,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6179, 18)"
      ]
     },
     "execution_count": 884,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nback_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [],
   "source": [
    "nback_df = nback_df.loc[nback_df.task_nback_missed >= 0,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5971, 18)"
      ]
     },
     "execution_count": 886,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nback_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [],
   "source": [
    "nback_df = nback_df.loc[nback_df.task_nback_falseAlarm <= 25,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5971, 18)"
      ]
     },
     "execution_count": 888,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nback_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset:  30%|███       | 6/20 [00:00<00:00, 93.67it/s, Describe variable:task_nback_missed]     /Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/numpy/core/_methods.py:49: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/numpy/core/_methods.py:152: RuntimeWarning: invalid value encountered in reduce\n",
      "  arrmean = umr_sum(arr, axis, dtype, keepdims=True, where=where)\n",
      "Summarize dataset:  77%|███████▋  | 17/22 [00:00<00:00, 222.90it/s, Calculate auto correlation]                 /Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/ydata_profiling/model/correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.\n",
      "To hide this warning, disable the calculation\n",
      "(using `df.profile_report(correlations={\"auto\": {\"calculate\": False}})`\n",
      "If this is problematic for your use case, please report this as an issue:\n",
      "https://github.com/ydataai/ydata-profiling/issues\n",
      "(include the error message: 'cannot specify integer `bins` when input data contains infinity')\n",
      "  warnings.warn(\n",
      "Summarize dataset:   9%|▉         | 18/191 [00:00<00:00, 209.50it/s, scatter task_nback_bid, task_nback_bid]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 194/194 [00:09<00:00, 21.43it/s, Completed]                                                   \n",
      "Generate report structure: 100%|██████████| 1/1 [00:01<00:00,  1.99s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 117.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# rerun EDA\n",
    "profile = ProfileReport(nback_df.iloc[:,3:], title= f\"n-Back Task Run {run_num} - cleaned | Pandas Profiling Report\")\n",
    "profile.to_file(eda_reports_path + f\"nback_report_run{run_num}_clean.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GoNoGo\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "- 50 trials\n",
    "- Stimulus = 250ms\n",
    "- ITI = 450ms\n",
    "- go/no-go ratio 4:1 (40/10)\n",
    "- NOTE THAT IF YOU PRESS THE BUTTON DURING THE ITI IT STILL COUNTS FOR THAT TRIAL! So the stimulus disappears but the trial is still “on”…each trial = 250 + 450 = 700ms\n",
    "\n",
    "**Data**\n",
    "\n",
    "For each trial\n",
    "\n",
    "- `trialType` Go or NoGo trial\n",
    "- `stim` Circle color\n",
    "- `stimDuration` How long is stim on\n",
    "- `iti`\n",
    "- `RT` RT to click\n",
    "- `correct` Correct/Error\n",
    "    - Go trial = click\n",
    "    - NoGo trial = no click\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>📝 Note:</b><br>\n",
    "    According to <a href=\"https://link.springer.com/article/10.3758/s13428-017-0923-5\">this paper</a> optimal go/no-go ratios to maximize false alarms were predicted to occur for the shortest tested ITI (450 ms) and a go/no-go ratio near 4:1. \n",
    "    <br><br>These values are predicted to produce a mean of 6.4 to 8.7 false alarms per 150 trials (95% confidence interval of the mean)\n",
    "    <br><br>Given that we ran 50 trials we would expect 1/3 of this range. We found our mean false alarm rate was in this range at 2.7 (or 8.1 for 150 trials).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted existing df\n",
      "deleted gng_df\n"
     ]
    }
   ],
   "source": [
    "# erase df if it already exists\n",
    "if 'df' in globals():\n",
    "    del(df)\n",
    "    print('deleted existing df')\n",
    "\n",
    "if 'gng_df' in globals():\n",
    "    del(gng_df)\n",
    "    print('deleted gng_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_num ==1:\n",
    "    # run 1\n",
    "    df = pd.read_csv(save_path + 'run1_survey_results.csv')\n",
    "if run_num ==2:\n",
    "    # run 2\n",
    "    df = pd.read_csv(save_path + 'run2_survey_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [],
   "source": [
    "gng_df =  df.loc[df.ResultIdentifier == 'task_custom_gonogo'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reactionTime': {'0': 413,\n",
       "  '1': 397,\n",
       "  '2': 378,\n",
       "  '3': 444,\n",
       "  '4': 409,\n",
       "  '5': 394,\n",
       "  '6': 426,\n",
       "  '9': 455,\n",
       "  '11': 386,\n",
       "  '12': 435,\n",
       "  '13': 433,\n",
       "  '14': 414,\n",
       "  '15': 414,\n",
       "  '17': 478,\n",
       "  '18': 461,\n",
       "  '19': 474,\n",
       "  '20': 440,\n",
       "  '21': 456,\n",
       "  '22': 488,\n",
       "  '25': 433,\n",
       "  '26': 399,\n",
       "  '27': 397,\n",
       "  '29': 379,\n",
       "  '30': 444,\n",
       "  '31': 443,\n",
       "  '32': 408,\n",
       "  '33': 390,\n",
       "  '34': 440,\n",
       "  '35': 369,\n",
       "  '37': 437,\n",
       "  '38': 486,\n",
       "  '39': 451,\n",
       "  '40': 415,\n",
       "  '41': 398,\n",
       "  '42': 396,\n",
       "  '43': 394,\n",
       "  '44': 425,\n",
       "  '45': 8,\n",
       "  '46': 358,\n",
       "  '47': 406,\n",
       "  '49': 453},\n",
       " 'correctness': {'0': 0,\n",
       "  '1': 0,\n",
       "  '2': 0,\n",
       "  '3': 0,\n",
       "  '4': 0,\n",
       "  '5': 0,\n",
       "  '6': 0,\n",
       "  '9': 0,\n",
       "  '11': 0,\n",
       "  '12': 0,\n",
       "  '13': 0,\n",
       "  '14': 0,\n",
       "  '15': 0,\n",
       "  '17': 0,\n",
       "  '18': 0,\n",
       "  '19': 0,\n",
       "  '20': 0,\n",
       "  '21': 0,\n",
       "  '22': 0,\n",
       "  '25': 0,\n",
       "  '26': 0,\n",
       "  '27': 0,\n",
       "  '29': 0,\n",
       "  '30': 0,\n",
       "  '31': 0,\n",
       "  '32': 0,\n",
       "  '33': 0,\n",
       "  '34': 0,\n",
       "  '35': 1,\n",
       "  '37': 0,\n",
       "  '38': 0,\n",
       "  '39': 0,\n",
       "  '40': 0,\n",
       "  '41': 0,\n",
       "  '42': 0,\n",
       "  '43': 0,\n",
       "  '44': 0,\n",
       "  '45': 0,\n",
       "  '46': 0,\n",
       "  '47': 0,\n",
       "  '49': 0},\n",
       " 'incorrectNoGo': 1,\n",
       " 'correctGo': 40,\n",
       " 'correctNoGo': 9,\n",
       " 'incorrectGo': 0,\n",
       " 'sequence': ['G',\n",
       "  'G',\n",
       "  'G',\n",
       "  'G',\n",
       "  'G',\n",
       "  'G',\n",
       "  'G',\n",
       "  'N',\n",
       "  'N',\n",
       "  'G',\n",
       "  'N',\n",
       "  'G',\n",
       "  'G',\n",
       "  'G',\n",
       "  'G',\n",
       "  'G',\n",
       "  'N',\n",
       "  'G',\n",
       "  'G',\n",
       "  'G',\n",
       "  'G',\n",
       "  'G',\n",
       "  'G',\n",
       "  'N',\n",
       "  'N',\n",
       "  'G',\n",
       "  'G',\n",
       "  'G',\n",
       "  'N',\n",
       "  'G',\n",
       "  'G',\n",
       "  'G',\n",
       "  'G',\n",
       "  'G',\n",
       "  'G',\n",
       "  'N',\n",
       "  'N',\n",
       "  'G',\n",
       "  'G',\n",
       "  'G',\n",
       "  'G',\n",
       "  'G',\n",
       "  'G',\n",
       "  'G',\n",
       "  'G',\n",
       "  'G',\n",
       "  'G',\n",
       "  'G',\n",
       "  'N',\n",
       "  'G'],\n",
       " 'stimDuration': 250,\n",
       " 'iti': 450,\n",
       " 'aRT': 414}"
      ]
     },
     "execution_count": 916,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(gng_df.Answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(gng_df.shape[0]):\n",
    "    gng_df.loc[i, 'task_gng_incorrectNoGo'] = json.loads(gng_df.Answers[i])['incorrectNoGo']\n",
    "    gng_df.loc[i, 'task_gng_incorrectGo'] = json.loads(gng_df.Answers[i])['incorrectGo']    \n",
    "    gng_df.loc[i, 'task_gng_correctGo'] = json.loads(gng_df.Answers[i])['correctGo']\n",
    "    gng_df.loc[i, 'task_gng_correctNoGo'] = json.loads(gng_df.Answers[i])['correctNoGo']    \n",
    "    gng_df.loc[i, 'task_gng_avgRt'] = np.mean(list(json.loads(gng_df.Answers[i])['reactionTime'].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [],
   "source": [
    "gng_df['task_gng_time'] = gng_df.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [],
   "source": [
    "gng_df = gng_df[['ParticipantIdentifier', 'trial_date',\n",
    "                 'task_gng_time',\n",
    "                 'task_gng_incorrectNoGo',\n",
    "                 'task_gng_incorrectGo',\n",
    "                 'task_gng_correctGo',\n",
    "                 'task_gng_correctNoGo',\n",
    "                 'task_gng_avgRt'\n",
    "                ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>task_gng_time</th>\n",
       "      <th>task_gng_incorrectNoGo</th>\n",
       "      <th>task_gng_incorrectGo</th>\n",
       "      <th>task_gng_correctGo</th>\n",
       "      <th>task_gng_correctNoGo</th>\n",
       "      <th>task_gng_avgRt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>07:33:26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>412.780488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5599c2a7-88a5-4cde-9f2a-41b4bd03d660</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>07:39:38</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>483.142857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ParticipantIdentifier  trial_date task_gng_time  \\\n",
       "0  0151d9f1-1644-4437-805e-02f5e244a690  2023-04-06      07:33:26   \n",
       "1  5599c2a7-88a5-4cde-9f2a-41b4bd03d660  2023-04-06      07:39:38   \n",
       "\n",
       "   task_gng_incorrectNoGo  task_gng_incorrectGo  task_gng_correctGo  \\\n",
       "0                     1.0                   0.0                40.0   \n",
       "1                     2.0                   1.0                39.0   \n",
       "\n",
       "   task_gng_correctNoGo  task_gng_avgRt  \n",
       "0                   9.0      412.780488  \n",
       "1                   8.0      483.142857  "
      ]
     },
     "execution_count": 920,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gng_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 39/39 [00:01<00:00, 27.80it/s, Completed]                                             \n",
      "Generate report structure: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00,  4.12it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 250.57it/s]\n"
     ]
    }
   ],
   "source": [
    "profile = ProfileReport(gng_df.iloc[:,3:], title=f\"Go-Nogo Task Run {run_num} | Pandas Profiling Report\")\n",
    "profile.to_file(eda_reports_path + f\"task_gng_run{run_num}.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean\n",
    "\n",
    "We can see that there are 84 trials where the RT is 0. These trials are removed.\n",
    "\n",
    "We also know from the work of Luce (1984) and Whelan (2008) that RTs below 100ms are not realistic.\n",
    "\n",
    "Therefore all trials with RTs below 100 were also removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84, or 1.3% of trials had RTs of 0.\n",
      "154, or 2.4% of trials had RTs of less than 100.\n"
     ]
    }
   ],
   "source": [
    "zero_trials = (gng_df.task_gng_avgRt == 0).sum()\n",
    "sub100_trials = (gng_df.task_gng_avgRt < 100).sum()\n",
    "trials_n = gng_df.shape[0]\n",
    "\n",
    "print(f'{zero_trials}, or {(zero_trials/trials_n) *100:.1f}% of trials had RTs of 0.')\n",
    "print(f'{sub100_trials}, or {(sub100_trials/trials_n) * 100:.1f}% of trials had RTs of less than 100.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task_gng_incorrectNoGo      4.045353\n",
       "task_gng_incorrectGo        2.686218\n",
       "task_gng_correctGo         37.313782\n",
       "task_gng_correctNoGo        5.954647\n",
       "task_gng_avgRt            352.961181\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gng_df.iloc[:,3:].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 39/39 [00:01<00:00, 29.89it/s, Completed]                                             \n",
      "Generate report structure: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00,  4.08it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 256.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# Remove all trials with impossibly short rts\n",
    "gng_df = gng_df.loc[gng_df.task_gng_avgRt >= 100,]\n",
    "\n",
    "# Rerun EDA\n",
    "profile = ProfileReport(gng_df.iloc[:,3:], title=f\"Go-Nogo Task Run {run_num} - Clean | Pandas Profiling Report\")\n",
    "profile.to_file(eda_reports_path + f\"task_gng_run{run_num}_clean.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task_gng_incorrectNoGo      4.045353\n",
       "task_gng_incorrectGo        2.686218\n",
       "task_gng_correctGo         37.313782\n",
       "task_gng_correctNoGo        5.954647\n",
       "task_gng_avgRt            352.961181\n",
       "dtype: float64"
      ]
     },
     "execution_count": 925,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the decrease in average incorrectGo (false alarm)\n",
    "gng_df.iloc[:,3:].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BART\n",
    "\n",
    "> The primary score used to measure BART performance is the average number of pumps on unexploded balloons, with higher scores indicative of greater risk-taking propensity (Bornovalova et al. 2005; Lejuez et al. 2002)\n",
    "\n",
    "[Scoring Alternatives Paper](https://www.researchgate.net/publication/301645337_The_Multiple_Faces_of_Risk-Taking_Scoring_Alternatives_for_the_Balloon-Analogue_Risk_Task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted existing df\n",
      "deleted bart_df\n"
     ]
    }
   ],
   "source": [
    "# erase df if it already exists\n",
    "if 'df' in globals():\n",
    "    del(df)\n",
    "    print('deleted existing df')\n",
    "\n",
    "if 'bart_df' in globals():\n",
    "    del(bart_df)\n",
    "    print('deleted bart_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_num ==1:\n",
    "    # run 1\n",
    "    df = pd.read_csv(save_path + 'run1_survey_results.csv')\n",
    "if run_num ==2:\n",
    "    # run 2\n",
    "    df = pd.read_csv(save_path + 'run2_survey_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1064,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows with BART task\n",
    "bart_df = df.loc[df.ResultIdentifier.str.contains('custom_bart')].reset_index(drop=True)\n",
    "# Remove rows that are just directions\n",
    "bart_df = bart_df.loc[~bart_df.ResultIdentifier.str.contains('_info')].reset_index(drop=True)\n",
    "# Remove summary rows\n",
    "bart_df = bart_df.loc[~bart_df.ResultIdentifier.str.contains('summary')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'timingInMs': [283,\n",
       "  134,\n",
       "  148,\n",
       "  149,\n",
       "  151,\n",
       "  134,\n",
       "  132,\n",
       "  134,\n",
       "  150,\n",
       "  183,\n",
       "  150,\n",
       "  183,\n",
       "  150,\n",
       "  183,\n",
       "  200,\n",
       "  383],\n",
       " 'thisRoundEarnings': 80,\n",
       " 'numberOfPumps': 16,\n",
       " 'totalEarnings': 80,\n",
       " 'balloonPopsAt': 19}"
      ]
     },
     "execution_count": 1065,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(bart_df.Answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# avg rt\n",
    "def foo(x):\n",
    "    try:\n",
    "        return np.mean(json.loads(x)['timingInMs'][1:]) # start on second tap as people take longer on first...\n",
    "    except (ValueError, KeyError):\n",
    "        return None\n",
    "\n",
    "v = np.vectorize(foo)\n",
    "bart_df['avg_rt'] = v(bart_df.Answers)\n",
    "\n",
    "# pop?\n",
    "def foo(x):\n",
    "    try:\n",
    "        return json.loads(x)['thisRoundEarnings']\n",
    "    except (ValueError, KeyError):\n",
    "        return None\n",
    "\n",
    "v = np.vectorize(foo)\n",
    "bart_df['thisRoundEarnings'] = v(bart_df.Answers)\n",
    "    \n",
    "# numberOfPumps\n",
    "def foo(x):\n",
    "    try:\n",
    "        return json.loads(x)['numberOfPumps']\n",
    "    except (ValueError, KeyError):\n",
    "        return None\n",
    "\n",
    "v = np.vectorize(foo)\n",
    "bart_df['pumps'] = v(bart_df.Answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only take unpopped trials\n",
    "bart_df = bart_df.loc[bart_df.thisRoundEarnings>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>task_bart_unpopped_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-01-30</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-02-02</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ParticipantIdentifier  trial_date  task_bart_unpopped_n\n",
       "0  0151d9f1-1644-4437-805e-02f5e244a690  2023-01-30                     9\n",
       "1  0151d9f1-1644-4437-805e-02f5e244a690  2023-01-31                     9\n",
       "2  0151d9f1-1644-4437-805e-02f5e244a690  2023-02-01                     7\n",
       "3  0151d9f1-1644-4437-805e-02f5e244a690  2023-02-02                     6\n",
       "4  0151d9f1-1644-4437-805e-02f5e244a690  2023-02-03                     6"
      ]
     },
     "execution_count": 1068,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pumps = pd.DataFrame(bart_df.groupby(['ParticipantIdentifier', 'trial_date'])['pumps'].sum()).reset_index()\n",
    "pumps = pumps.rename(columns={'pumps': 'task_bart_total_pumps'})\n",
    "unpopped = pd.DataFrame(bart_df.groupby(['ParticipantIdentifier', 'trial_date'])['pumps'].count()).reset_index()\n",
    "unpopped = unpopped.rename(columns={'pumps': 'task_bart_unpopped_n'})\n",
    "unpopped.head()             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1069,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean of pumps and mean of rt for each DAY\n",
    "bart_df = pd.DataFrame(bart_df.groupby(['ParticipantIdentifier', 'trial_date'])[['avg_rt', 'pumps']].mean()).reset_index()\n",
    "bart_df = bart_df.rename(columns={\"avg_rt\": \"task_bart_avg_rt\", 'pumps': 'task_bart_avg_pumps'})\n",
    "\n",
    "# add other data\n",
    "bart_df = bart_df.merge(pumps, how='left', on=['ParticipantIdentifier', 'trial_date'])\n",
    "bart_df = bart_df.merge(unpopped, how='left', on=['ParticipantIdentifier', 'trial_date'])\n",
    "\n",
    "# calculate score\n",
    "bart_df['task_bart_score'] = bart_df.task_bart_total_pumps * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>task_bart_avg_rt</th>\n",
       "      <th>task_bart_avg_pumps</th>\n",
       "      <th>task_bart_total_pumps</th>\n",
       "      <th>task_bart_unpopped_n</th>\n",
       "      <th>task_bart_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-01-30</td>\n",
       "      <td>234.530449</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>114</td>\n",
       "      <td>9</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>191.290741</td>\n",
       "      <td>16.888889</td>\n",
       "      <td>152</td>\n",
       "      <td>9</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ParticipantIdentifier  trial_date  task_bart_avg_rt  \\\n",
       "0  0151d9f1-1644-4437-805e-02f5e244a690  2023-01-30        234.530449   \n",
       "1  0151d9f1-1644-4437-805e-02f5e244a690  2023-01-31        191.290741   \n",
       "\n",
       "   task_bart_avg_pumps  task_bart_total_pumps  task_bart_unpopped_n  \\\n",
       "0            12.666667                    114                     9   \n",
       "1            16.888889                    152                     9   \n",
       "\n",
       "   task_bart_score  \n",
       "0              570  \n",
       "1              760  "
      ]
     },
     "execution_count": 1070,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 39/39 [00:01<00:00, 23.46it/s, Completed]                                           \n",
      "Generate report structure: 100%|██████████| 1/1 [00:01<00:00,  1.45s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 419.81it/s]\n"
     ]
    }
   ],
   "source": [
    "profile = ProfileReport(bart_df.iloc[:,2:], title=f\"BART Task Run {run_num} | Pandas Profiling Report\")\n",
    "profile.to_file(eda_reports_path + f\"task_BART_run{run_num}.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean\n",
    "\n",
    "We can see that there are trials with VERY long average RTs. These should be removed before calculations are done.\n",
    "\n",
    "We used the $z$ transform method to flag outliers based on Berger and Kiefer ([2021](https://doi.org/10.3389/fpsyg.2021.675558)) where they tested multiple methods of removing outliers from rt data.\n",
    "\n",
    "We also set the flag threshold to 3.\n",
    "\n",
    "---\n",
    "\n",
    "We can also see that the `unpopped_n` (referring to trials where the balloon did not pop) values go up to 18 which is not possible since there are only 10 trials. Entries where there are more than 10 trials are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task_bart_avg_rt         263.456431\n",
       "task_bart_avg_pumps       15.131685\n",
       "task_bart_total_pumps    117.985638\n",
       "task_bart_unpopped_n       7.794880\n",
       "task_bart_score          589.928192\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1071,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart_df.iloc[:,2:].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean outlier rt values\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Step 1: Filter out rt cols\n",
    "rt_columns = [col for col in bart_df.columns if col.endswith('_rt')]\n",
    "\n",
    "# Step 2: Compute the z-scores for these columns\n",
    "for col in rt_columns:\n",
    "    z_col_name = col + '_z'\n",
    "    bart_df[z_col_name] = zscore(bart_df[col], nan_policy='omit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting a z-scire threshold of 3 removes 43 entries, or 0.7% of the total.\n"
     ]
    }
   ],
   "source": [
    "# Trial removal stats - RT\n",
    "threshold = 3  # Define a threshold value\n",
    "\n",
    "trials_removed = (abs(bart_df.task_bart_avg_rt_z) > threshold).sum()\n",
    "trials_n = bart_df.shape[0]\n",
    "\n",
    "print(f'Setting a z-score threshold of 3 removes {trials_removed} entries, or {(trials_removed/trials_n) * 100:.1f}% of the total.')\n",
    "\n",
    "# Remove trials\n",
    "bart_df = bart_df.loc[abs(bart_df.task_bart_avg_rt_z) <=threshold,]\n",
    "# Remove z-score column\n",
    "z_columns_to_drop = [col for col in bart_df.columns if col.endswith('_z')]\n",
    "bart_df = bart_df.drop(columns=z_columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 entries, or 0.0% that have more than 10 trials.\n"
     ]
    }
   ],
   "source": [
    "# Trial removal stats - trial num\n",
    "trials_removed = (bart_df.task_bart_unpopped_n > 10).sum()\n",
    "trials_n = bart_df.shape[0]\n",
    "\n",
    "print(f'There are {trials_removed} entries, or {(trials_removed/trials_n) * 100:.1f}% that have more than 10 trials.')\n",
    "\n",
    "# Remove trials\n",
    "bart_df = bart_df.loc[bart_df.task_bart_unpopped_n <=10,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 39/39 [00:01<00:00, 25.32it/s, Completed]                                           \n",
      "Generate report structure: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00,  4.06it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 216.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# Rerun EDA\n",
    "profile = ProfileReport(bart_df.iloc[:,2:], title=f\"BART Task Run {run_num} - Clean | Pandas Profiling Report\")\n",
    "profile.to_file(eda_reports_path + f\"task_BART_run{run_num}_clean.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EmoStroop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted existing df\n",
      "deleted emoStroop_df\n"
     ]
    }
   ],
   "source": [
    "# erase df if it already exists\n",
    "if 'df' in globals():\n",
    "    del(df)\n",
    "    print('deleted existing df')\n",
    "\n",
    "if 'emoStroop_df' in globals():\n",
    "    del(emoStroop_df)\n",
    "    print('deleted emoStroop_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1449,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_num ==1:\n",
    "    # run 1\n",
    "    df = pd.read_csv(save_path + 'run1_survey_results.csv')\n",
    "if run_num ==2:\n",
    "    # run 2\n",
    "    df = pd.read_csv(save_path + 'run2_survey_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1450,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoStroop_df = df.loc[df.ResultIdentifier.str.contains('emoStroop_trial')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'emotion': 'angry',\n",
       " 'text': 'happy',\n",
       " 'startTime': 5251,\n",
       " 'endTime': 6338,\n",
       " 'chosenEmotion': 'angry',\n",
       " 'correctness': 'incorrect'}"
      ]
     },
     "execution_count": 1451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(emoStroop_df.Answers[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1452,
   "metadata": {},
   "outputs": [],
   "source": [
    "# congruent\n",
    "def foo(x):\n",
    "    try:\n",
    "        return json.loads(x)['emotion'] == json.loads(x)['text']\n",
    "    except (ValueError, KeyError):\n",
    "        return None\n",
    "\n",
    "v = np.vectorize(foo)\n",
    "emoStroop_df['task_emoStroop_congruent'] = v(emoStroop_df.Answers)\n",
    "\n",
    "# rt\n",
    "def foo(x):\n",
    "    try:\n",
    "        return json.loads(x)['endTime'] - json.loads(x)['startTime']\n",
    "    except (ValueError, KeyError):\n",
    "        return None\n",
    "\n",
    "v = np.vectorize(foo)\n",
    "emoStroop_df['task_emoStroop_rt'] = v(emoStroop_df.Answers)\n",
    "    \n",
    "# correct\n",
    "def foo(x):\n",
    "    try:\n",
    "        return json.loads(x)['emotion'] == json.loads(x)['chosenEmotion']\n",
    "    except (ValueError, KeyError):\n",
    "        return None\n",
    "\n",
    "v = np.vectorize(foo)\n",
    "emoStroop_df['task_emoStroop_correct'] = v(emoStroop_df.Answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1453,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoStroop_df = pd.DataFrame(emoStroop_df.groupby(['ParticipantIdentifier', 'trial_date', 'task_emoStroop_congruent'])\n",
    "             [['task_emoStroop_rt', 'task_emoStroop_correct']].mean()).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1454,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to wide\n",
    "emoStroop_df = emoStroop_df.pivot_table(index = ['ParticipantIdentifier', 'trial_date'],\n",
    "                         columns = 'task_emoStroop_congruent',\n",
    "                         values = ['task_emoStroop_rt', 'task_emoStroop_correct']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([( 'ParticipantIdentifier',    ''),\n",
       "            (            'trial_date',    ''),\n",
       "            ('task_emoStroop_correct', False),\n",
       "            ('task_emoStroop_correct',  True),\n",
       "            (     'task_emoStroop_rt', False),\n",
       "            (     'task_emoStroop_rt',  True)],\n",
       "           names=[None, 'task_emoStroop_congruent'])"
      ]
     },
     "execution_count": 1455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoStroop_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1456,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create correct column names\n",
    "new_cols = []\n",
    "for i in range(emoStroop_df.shape[1]):\n",
    "    new_cols.append(emoStroop_df.columns.get_level_values(0)[i] + \n",
    "                    str(emoStroop_df.columns.get_level_values(1)[i]))\n",
    "# x.columns.get_level_values(0)[1] + str(x.columns.get_level_values(1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1457,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = [\n",
    "    'ParticipantIdentifier',\n",
    "    'trial_date',\n",
    "    'task_emoStroop_accuracy_incongruent',\n",
    "    'task_emoStroop_accuracy_congruent',\n",
    "    'task_emoStroop_rt_incongruent',\n",
    "    'task_emoStroop_rt_congruent'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1458,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoStroop_df.columns = emoStroop_df.columns.to_flat_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1459,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoStroop_df.columns = new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>task_emoStroop_accuracy_incongruent</th>\n",
       "      <th>task_emoStroop_accuracy_congruent</th>\n",
       "      <th>task_emoStroop_rt_incongruent</th>\n",
       "      <th>task_emoStroop_rt_congruent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1301.444444</td>\n",
       "      <td>946.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-01-30</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1024.125000</td>\n",
       "      <td>891.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ParticipantIdentifier  trial_date  \\\n",
       "0  0151d9f1-1644-4437-805e-02f5e244a690  2023-01-17   \n",
       "1  0151d9f1-1644-4437-805e-02f5e244a690  2023-01-30   \n",
       "\n",
       "   task_emoStroop_accuracy_incongruent  task_emoStroop_accuracy_congruent  \\\n",
       "0                             0.888889                           1.000000   \n",
       "1                             0.875000                           0.857143   \n",
       "\n",
       "   task_emoStroop_rt_incongruent  task_emoStroop_rt_congruent  \n",
       "0                    1301.444444                   946.000000  \n",
       "1                    1024.125000                   891.857143  "
      ]
     },
     "execution_count": 1460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoStroop_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1461,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 30/30 [00:01<00:00, 16.92it/s, Completed]                                                                       \n",
      "Generate report structure: 100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 278.86it/s]\n"
     ]
    }
   ],
   "source": [
    "profile = ProfileReport(emoStroop_df.iloc[:,2:], title=f\"EmoStroop Task Run {run_num} | Pandas Profiling Report\")\n",
    "profile.to_file(eda_reports_path + f\"task_emoStroop_run{run_num}.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean\n",
    "\n",
    "We can see that there are entries with VERY long average `rt_congruent` and `rt_incongruent` values. These should be removed before calculations are done.\n",
    "\n",
    "We used the Median Absolute Deviation (MAD) with a threshold of 3 to remove rt outliers ([Leys et al., 2014](https://www.sciencedirect.com/science/article/abs/pii/S0022103113000668)).\n",
    "\n",
    "Use rule of thumb of 10 seconds...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1386,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoStroop_df.to_csv('emostroop.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1464,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where the absolute deviation from the median is above 3 times the MAD\n",
    "emoStroop_df = emoStroop_df[emoStroop_df['task_emoStroop_rt_incongruent'] <= 10000]\n",
    "emoStroop_df = emoStroop_df[emoStroop_df['task_emoStroop_rt_congruent'] <= 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning using MAD with a threshold of 3 removed 1540 entries, or 23.9%.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import median_abs_deviation\n",
    "\n",
    "# Original size\n",
    "n_original = emoStroop_df.shape[0]\n",
    "\n",
    "# Clean outlier rt values\n",
    "threshold = 3  # Define a threshold value\n",
    "\n",
    "# Compute the MAD using scipy\n",
    "mad_i = median_abs_deviation(emoStroop_df['task_emoStroop_rt_incongruent'], nan_policy='omit')\n",
    "mad_c = median_abs_deviation(emoStroop_df['task_emoStroop_rt_congruent'], nan_policy='omit')\n",
    "\n",
    "# Compute the median value of the 'reaction time' column\n",
    "median_val_i = emoStroop_df['task_emoStroop_rt_incongruent'].median()\n",
    "median_val_c = emoStroop_df['task_emoStroop_rt_congruent'].median()\n",
    "\n",
    "# Filter rows where the absolute deviation from the median is above 3 times the MAD\n",
    "emoStroop_df = emoStroop_df[(emoStroop_df['task_emoStroop_rt_incongruent'] - median_val_i).abs() <= threshold * mad_i]\n",
    "emoStroop_df = emoStroop_df[(emoStroop_df['task_emoStroop_rt_congruent'] - median_val_c).abs() <= threshold * mad_c]\n",
    "\n",
    "n_clean = emoStroop_df.shape[0]\n",
    "\n",
    "print(f'Cleaning using MAD with a threshold of {threshold} removed {n_original - n_clean} entries, or {((n_original - n_clean) / n_original) * 100:.1f}%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1465,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset:  26%|██▌       | 7/27 [00:00<00:00, 135.31it/s, scatter task_emoStroop_accuracy_incongruent, task_emoStroop_accuracy_incongruent]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 29/29 [00:01<00:00, 21.75it/s, Completed]                                                                       \n",
      "Generate report structure: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 331.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# Rerun EDA\n",
    "profile = ProfileReport(emoStroop_df.iloc[:,2:], title=f\"EmoStroop Task Run {run_num} - Clean | Pandas Profiling Report\")\n",
    "profile.to_file(eda_reports_path + f\"task_emoStroop_run{run_num}_clean.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted existing df\n",
      "deleted task_motivation\n"
     ]
    }
   ],
   "source": [
    "# erase df if it already exists\n",
    "if 'df' in globals():\n",
    "    del(df)\n",
    "    print('deleted existing df')\n",
    "\n",
    "if 'task_motivation' in globals():\n",
    "    del(task_motivation)\n",
    "    print('deleted task_motivation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1393,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_num ==1:\n",
    "    # run 1\n",
    "    df = pd.read_csv(save_path + 'run1_survey_results.csv')\n",
    "if run_num ==2:\n",
    "    # run 2\n",
    "    df = pd.read_csv(save_path + 'run2_survey_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1394,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_motivation = df.loc[df.ResultIdentifier.str.contains('task_motivation')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1395,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_motivation = task_motivation[['ParticipantIdentifier', 'trial_date', 'time', 'Answers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6592, 4)"
      ]
     },
     "execution_count": 1396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_motivation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1397,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = [\n",
    "    'ParticipantIdentifier',\n",
    "    'trial_date',\n",
    "    'task_motivation_time',\n",
    "    'task_motivation_level'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>task_motivation_time</th>\n",
       "      <th>task_motivation_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5599c2a7-88a5-4cde-9f2a-41b4bd03d660</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>07:15:48</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>07:24:50</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ParticipantIdentifier  trial_date task_motivation_time  \\\n",
       "0  5599c2a7-88a5-4cde-9f2a-41b4bd03d660  2023-04-06             07:15:48   \n",
       "1  0151d9f1-1644-4437-805e-02f5e244a690  2023-04-06             07:24:50   \n",
       "\n",
       "  task_motivation_level  \n",
       "0                    10  \n",
       "1                     5  "
      ]
     },
     "execution_count": 1398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_motivation.columns = new_cols\n",
    "task_motivation.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1399,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/ydata_profiling/utils/dataframe.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={\"index\": \"df_index\"}, inplace=True)\n",
      "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 12/12 [00:00<00:00, 24.57it/s, Completed]                                          \n",
      "Generate report structure: 100%|██████████| 1/1 [00:00<00:00,  4.19it/s]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00, 31.39it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 629.68it/s]\n"
     ]
    }
   ],
   "source": [
    "profile = ProfileReport(task_motivation.iloc[:,2:], title=f\"Task Motivation Run {run_num} | Pandas Profiling Report\")\n",
    "profile.to_file(eda_reports_path + f\"task_motivation_run{run_num}.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NASA TLX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted existing df\n"
     ]
    }
   ],
   "source": [
    "# erase df if it already exists\n",
    "if 'df' in globals():\n",
    "    del(df)\n",
    "    print('deleted existing df')\n",
    "\n",
    "if 'nasa_tlx' in globals():\n",
    "    del(nasa_tlx)\n",
    "    print('deleted nasa_tlx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1401,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_num ==1:\n",
    "    # run 1\n",
    "    df = pd.read_csv(save_path + 'run1_survey_results.csv')\n",
    "if run_num ==2:\n",
    "    # run 2\n",
    "    df = pd.read_csv(save_path + 'run2_survey_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1405,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa_tlx = df.loc[df.ResultIdentifier.str.contains('nasa_')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>ResultIdentifier</th>\n",
       "      <th>Answers</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>datetime</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>nasa_mental_demand</td>\n",
       "      <td>11</td>\n",
       "      <td>2023-04-06T07:36:23-04:00</td>\n",
       "      <td>2023-04-06 07:36:23-04:00</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>07:36:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>nasa_temporal_demand</td>\n",
       "      <td>8</td>\n",
       "      <td>2023-04-06T07:36:27-04:00</td>\n",
       "      <td>2023-04-06 07:36:27-04:00</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>07:36:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>nasa_performance</td>\n",
       "      <td>10</td>\n",
       "      <td>2023-04-06T07:36:44-04:00</td>\n",
       "      <td>2023-04-06 07:36:44-04:00</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>07:36:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>nasa_effort</td>\n",
       "      <td>10</td>\n",
       "      <td>2023-04-06T07:36:55-04:00</td>\n",
       "      <td>2023-04-06 07:36:55-04:00</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>07:36:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>nasa_frustration</td>\n",
       "      <td>6</td>\n",
       "      <td>2023-04-06T07:37:01-04:00</td>\n",
       "      <td>2023-04-06 07:37:01-04:00</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>07:37:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ParticipantIdentifier      ResultIdentifier Answers  \\\n",
       "0  0151d9f1-1644-4437-805e-02f5e244a690    nasa_mental_demand      11   \n",
       "1  0151d9f1-1644-4437-805e-02f5e244a690  nasa_temporal_demand       8   \n",
       "2  0151d9f1-1644-4437-805e-02f5e244a690      nasa_performance      10   \n",
       "3  0151d9f1-1644-4437-805e-02f5e244a690           nasa_effort      10   \n",
       "4  0151d9f1-1644-4437-805e-02f5e244a690      nasa_frustration       6   \n",
       "\n",
       "                     EndDate                   datetime  trial_date      time  \n",
       "0  2023-04-06T07:36:23-04:00  2023-04-06 07:36:23-04:00  2023-04-06  07:36:23  \n",
       "1  2023-04-06T07:36:27-04:00  2023-04-06 07:36:27-04:00  2023-04-06  07:36:27  \n",
       "2  2023-04-06T07:36:44-04:00  2023-04-06 07:36:44-04:00  2023-04-06  07:36:44  \n",
       "3  2023-04-06T07:36:55-04:00  2023-04-06 07:36:55-04:00  2023-04-06  07:36:55  \n",
       "4  2023-04-06T07:37:01-04:00  2023-04-06 07:37:01-04:00  2023-04-06  07:37:01  "
      ]
     },
     "execution_count": 1406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nasa_tlx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to wide\n",
    "nasa_tlx = nasa_tlx.pivot_table(index = ['ParticipantIdentifier', 'trial_date'],\n",
    "                         columns = 'ResultIdentifier',\n",
    "                         values = 'Answers').reset_index()\n",
    "\n",
    "# remove index name\n",
    "nasa_tlx = nasa_tlx.rename_axis(None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['task_nasa_distraction',\n",
       " 'task_nasa_effort',\n",
       " 'task_nasa_frustration',\n",
       " 'task_nasa_luck',\n",
       " 'task_nasa_mental_demand',\n",
       " 'task_nasa_performance',\n",
       " 'task_nasa_temporal_demand']"
      ]
     },
     "execution_count": 1408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tweak column names\n",
    "list(nasa_tlx.iloc[:, 2:].add_prefix('task_').columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1409,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = [\n",
    "    'ParticipantIdentifier',\n",
    "    'trial_date',\n",
    "    'task_nasa_distraction',\n",
    "    'task_nasa_effort',\n",
    "    'task_nasa_frustration',\n",
    "    'task_nasa_luck',\n",
    "    'task_nasa_mental_demand',\n",
    "    'task_nasa_performance',\n",
    "    'task_nasa_temporal_demand'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>task_nasa_distraction</th>\n",
       "      <th>task_nasa_effort</th>\n",
       "      <th>task_nasa_frustration</th>\n",
       "      <th>task_nasa_luck</th>\n",
       "      <th>task_nasa_mental_demand</th>\n",
       "      <th>task_nasa_performance</th>\n",
       "      <th>task_nasa_temporal_demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-01-30</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ParticipantIdentifier  trial_date task_nasa_distraction  \\\n",
       "0  0151d9f1-1644-4437-805e-02f5e244a690  2023-01-30                  12.0   \n",
       "1  0151d9f1-1644-4437-805e-02f5e244a690  2023-01-31                  12.0   \n",
       "\n",
       "  task_nasa_effort task_nasa_frustration task_nasa_luck  \\\n",
       "0             13.0                  11.0           13.0   \n",
       "1             14.0                   0.0           12.0   \n",
       "\n",
       "  task_nasa_mental_demand task_nasa_performance task_nasa_temporal_demand  \n",
       "0                    11.0                  12.0                      13.0  \n",
       "1                     8.0                  10.0                       6.0  "
      ]
     },
     "execution_count": 1410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nasa_tlx.columns = new_cols\n",
    "\n",
    "nasa_tlx.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1411,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/ydata_profiling/utils/dataframe.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={\"index\": \"df_index\"}, inplace=True)\n",
      "Summarize dataset: 100%|██████████| 66/66 [00:03<00:00, 21.58it/s, Completed]                                                   \n",
      "Generate report structure: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00,  2.14it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 271.46it/s]\n"
     ]
    }
   ],
   "source": [
    "profile = ProfileReport(nasa_tlx.iloc[:,2:], title=f\"NASA TLX Run {run_num} | Pandas Profiling Report\")\n",
    "profile.to_file(eda_reports_path + f\"NASA_tlx_run{run_num}.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean\n",
    "\n",
    "There are maximimum values over 600 which doesn't make sense since the max is 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1413,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa_tlx.to_csv('nasa.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values greater than 20 in numeric columns with NaN\n",
    "nasa_tlx.iloc[:,2:] = nasa_tlx.iloc[:,2:].where(lambda x: x <= 20, other=pd.NA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1422,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/djw/Documents/pCloud_synced/Academics/Projects/2020_thesis/thesis_experiments/3_experiments/3_3_experience_sampling/.venv/lib/python3.11/site-packages/ydata_profiling/utils/dataframe.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={\"index\": \"df_index\"}, inplace=True)\n",
      "Summarize dataset: 100%|██████████| 66/66 [00:03<00:00, 18.68it/s, Completed]                                                   \n",
      "Generate report structure: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 195.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# rerun EDA\n",
    "profile = ProfileReport(nasa_tlx.iloc[:,2:], title=f\"NASA TLX Run {run_num} - Clean | Pandas Profiling Report\")\n",
    "profile.to_file(eda_reports_path + f\"NASA_tlx_run{run_num}_clean.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Custom Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6394, 8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gng_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6332, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nback_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6406, 7)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bart_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6432, 6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emoStroop_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6592, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_motivation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6353, 9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nasa_tlx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_tasks_df = task_motivation.merge(gng_df, how='outer', on=['ParticipantIdentifier', 'trial_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_tasks_df = custom_tasks_df.merge(bart_df, how='outer', on=['ParticipantIdentifier', 'trial_date'])\n",
    "custom_tasks_df = custom_tasks_df.merge(emoStroop_df, how='outer', on=['ParticipantIdentifier', 'trial_date'])\n",
    "custom_tasks_df = custom_tasks_df.merge(nback_df, how='outer', on=['ParticipantIdentifier', 'trial_date'])\n",
    "custom_tasks_df = custom_tasks_df.merge(nasa_tlx, how='outer', on=['ParticipantIdentifier', 'trial_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>task_motivation_time</th>\n",
       "      <th>task_motivation_level</th>\n",
       "      <th>task_gng_time</th>\n",
       "      <th>task_gng_incorrectNoGo</th>\n",
       "      <th>task_gng_incorrectGo</th>\n",
       "      <th>task_gng_correctGo</th>\n",
       "      <th>task_gng_correctNoGo</th>\n",
       "      <th>task_gng_avgRt</th>\n",
       "      <th>...</th>\n",
       "      <th>task_nback_missed</th>\n",
       "      <th>task_nback_falseAlarm</th>\n",
       "      <th>task_nback_accuracy</th>\n",
       "      <th>task_nasa_distraction</th>\n",
       "      <th>task_nasa_effort</th>\n",
       "      <th>task_nasa_frustration</th>\n",
       "      <th>task_nasa_luck</th>\n",
       "      <th>task_nasa_mental_demand</th>\n",
       "      <th>task_nasa_performance</th>\n",
       "      <th>task_nasa_temporal_demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5599c2a7-88a5-4cde-9f2a-41b4bd03d660</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>07:15:48</td>\n",
       "      <td>10</td>\n",
       "      <td>07:39:38</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>483.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>07:24:50</td>\n",
       "      <td>5</td>\n",
       "      <td>07:33:26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>412.780488</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ParticipantIdentifier  trial_date task_motivation_time  \\\n",
       "0  5599c2a7-88a5-4cde-9f2a-41b4bd03d660  2023-04-06             07:15:48   \n",
       "1  0151d9f1-1644-4437-805e-02f5e244a690  2023-04-06             07:24:50   \n",
       "\n",
       "  task_motivation_level task_gng_time  task_gng_incorrectNoGo  \\\n",
       "0                    10      07:39:38                     2.0   \n",
       "1                     5      07:33:26                     1.0   \n",
       "\n",
       "   task_gng_incorrectGo  task_gng_correctGo  task_gng_correctNoGo  \\\n",
       "0                   1.0                39.0                   8.0   \n",
       "1                   0.0                40.0                   9.0   \n",
       "\n",
       "   task_gng_avgRt  ...  task_nback_missed  task_nback_falseAlarm  \\\n",
       "0      483.142857  ...                1.0                    0.0   \n",
       "1      412.780488  ...                1.0                    0.0   \n",
       "\n",
       "   task_nback_accuracy  task_nasa_distraction  task_nasa_effort  \\\n",
       "0             0.954545                    6.0              11.0   \n",
       "1             0.954545                    8.0              10.0   \n",
       "\n",
       "   task_nasa_frustration  task_nasa_luck  task_nasa_mental_demand  \\\n",
       "0                    8.0             5.0                      5.0   \n",
       "1                    6.0             5.0                     11.0   \n",
       "\n",
       "   task_nasa_performance task_nasa_temporal_demand  \n",
       "0                    7.0                       4.0  \n",
       "1                   10.0                       8.0  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "custom_tasks_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HK Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trail Making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[RKStudio Documentation](https://rkstudio-support.careevolution.com/hc/en-us/articles/1500002201361-Trailmaking-Active-Task-Export-Format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is trailmaking task really measuring?\n",
    "\n",
    ">The Trail Making Test is a neuropsychological test of visual attention and task switching. It consists of two parts in which the subject is instructed to connect a set of 25 dots as quickly as possible while still maintaining accuracy. The test can provide information about visual search speed, scanning, speed of processing, mental flexibility, as well as executive functioning.[[1](https://doi.apa.org/doiLanding?doi=10.1037%2F1040-3590.7.2.220)]\n",
    "\n",
    "- visual attention\n",
    "- task switching\n",
    "- fluid intelligence/cognitive abilities\n",
    "\n",
    "**Reference**\n",
    "\n",
    "[1] [Salthouse, 2011](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3141679/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b><br>\n",
    "<ul> \n",
    "    <li>We are using fewer \"dots\" (12)</li>\n",
    "    <li>We are using both a number only and a letter/number version (e.g. 1-A-2-B-3-C...).</li>\n",
    "<ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted existing df\n",
      "deleted trailmaking_df\n"
     ]
    }
   ],
   "source": [
    "# erase df if it already exists\n",
    "if 'df' in globals():\n",
    "    del(df)\n",
    "    print('deleted existing df')\n",
    "\n",
    "if 'trailmaking_df' in globals():\n",
    "    del(trailmaking_df)\n",
    "    print('deleted trailmaking_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cohort 2...\n"
     ]
    }
   ],
   "source": [
    "print(f'Loading cohort {run_num}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:01<00:00, 47.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# loop through all days\n",
    "days = [i for i in os.listdir(path) if i.startswith('RK')]\n",
    "days.sort()\n",
    "for day in tqdm(days):\n",
    "    files = os.listdir(path + day)\n",
    "    surveyQuestions = [i for i in files if i.startswith('SurveyTrailmakingResults')]\n",
    "    versionInfo = [i for i in files if i.startswith('SurveyResults')]\n",
    "    # there should be only one\n",
    "    for file in surveyQuestions:\n",
    "        if 'df' not in globals():\n",
    "            df = pd.read_csv(path + day + '/' + file)\n",
    "            df_version = pd.read_csv(path + day + '/' + versionInfo[0])\n",
    "        else:\n",
    "            temp_df = pd.read_csv(path + day + '/' + file)\n",
    "            temp_df_version = pd.read_csv(path + day + '/' + versionInfo[0])\n",
    "            df = pd.concat([df,temp_df], axis=0)\n",
    "            df_version = pd.concat([df_version,temp_df_version], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the numeric and alphanumeric versions\n",
    "df_version = df_version[['SurveyResultKey', 'SurveyName']]\n",
    "df_version = df_version.loc[df_version.SurveyName.str.contains('_trail')][['SurveyResultKey', 'SurveyName']]\n",
    "df = pd.merge(df, df_version, how='left', on='SurveyResultKey')\n",
    "\n",
    "# rename SurveyName\n",
    "d = {'task_hk_trail_making': 'task_hk_trailmaking_alphaNumeric', 'task_hk_trailmaking_a1': 'task_hk_trailmaking_numeric'}\n",
    "\n",
    "df = df.replace({\"SurveyName\": d})\n",
    "\n",
    "df = df.dropna(subset=['EndDate']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select subjects from correct run\n",
    "df = df.loc[df.ParticipantIdentifier.isin(subjects)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13031/13031 [00:01<00:00, 9486.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# add trial date and time columns\n",
    "for i in tqdm(range(df.shape[0])):\n",
    "    dt = parser.parse(df.loc[i, 'EndDate'])\n",
    "    df.loc[i, 'datetime'] = dt\n",
    "    df.loc[i, 'trial_date'] = (dt + datetime.timedelta(hours = -4)).date() # trial day associated with sample (4am is when the day flips)\n",
    "    df.loc[i, 'time'] = dt.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SurveyTrailmakingResultKey</th>\n",
       "      <th>SurveyStepResultKey</th>\n",
       "      <th>SurveyResultKey</th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>NumberOfErrors</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Taps</th>\n",
       "      <th>SurveyName</th>\n",
       "      <th>datetime</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8b02e79a-1291-ed11-aac3-0afb9334277d</td>\n",
       "      <td>7b02e79a-1291-ed11-aac3-0afb9334277d</td>\n",
       "      <td>7002e79a-1291-ed11-aac3-0afb9334277d</td>\n",
       "      <td>4f4440e7-3a38-4fa7-9271-9730806e441a</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-10T13:14:12-05:00</td>\n",
       "      <td>2023-01-10T13:14:26-05:00</td>\n",
       "      <td>[{\"TapTimestamp\":1.3185780048370361,\"TapIndex\"...</td>\n",
       "      <td>task_hk_trailmaking_numeric</td>\n",
       "      <td>2023-01-10 13:14:26-05:00</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>13:14:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96b7e6b8-1291-ed11-aac3-0afb9334277d</td>\n",
       "      <td>81b7e6b8-1291-ed11-aac3-0afb9334277d</td>\n",
       "      <td>73b7e6b8-1291-ed11-aac3-0afb9334277d</td>\n",
       "      <td>4f4440e7-3a38-4fa7-9271-9730806e441a</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-10T13:14:54-05:00</td>\n",
       "      <td>2023-01-10T13:15:11-05:00</td>\n",
       "      <td>[{\"TapTimestamp\":1.0001180171966553,\"TapIndex\"...</td>\n",
       "      <td>task_hk_trailmaking_alphaNumeric</td>\n",
       "      <td>2023-01-10 13:15:11-05:00</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>13:15:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             SurveyTrailmakingResultKey                   SurveyStepResultKey  \\\n",
       "0  8b02e79a-1291-ed11-aac3-0afb9334277d  7b02e79a-1291-ed11-aac3-0afb9334277d   \n",
       "1  96b7e6b8-1291-ed11-aac3-0afb9334277d  81b7e6b8-1291-ed11-aac3-0afb9334277d   \n",
       "\n",
       "                        SurveyResultKey                 ParticipantIdentifier  \\\n",
       "0  7002e79a-1291-ed11-aac3-0afb9334277d  4f4440e7-3a38-4fa7-9271-9730806e441a   \n",
       "1  73b7e6b8-1291-ed11-aac3-0afb9334277d  4f4440e7-3a38-4fa7-9271-9730806e441a   \n",
       "\n",
       "   NumberOfErrors                  StartDate                    EndDate  \\\n",
       "0               1  2023-01-10T13:14:12-05:00  2023-01-10T13:14:26-05:00   \n",
       "1               1  2023-01-10T13:14:54-05:00  2023-01-10T13:15:11-05:00   \n",
       "\n",
       "                                                Taps  \\\n",
       "0  [{\"TapTimestamp\":1.3185780048370361,\"TapIndex\"...   \n",
       "1  [{\"TapTimestamp\":1.0001180171966553,\"TapIndex\"...   \n",
       "\n",
       "                         SurveyName                   datetime  trial_date  \\\n",
       "0       task_hk_trailmaking_numeric  2023-01-10 13:14:26-05:00  2023-01-10   \n",
       "1  task_hk_trailmaking_alphaNumeric  2023-01-10 13:15:11-05:00  2023-01-10   \n",
       "\n",
       "       time  \n",
       "0  13:14:26  \n",
       "1  13:15:11  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important data is in `Taps` where we have:\n",
    "- `TapTimestamp`\n",
    "- `TapIndex`\n",
    "- `TapIncorrect`\n",
    "\n",
    "I want to get the last `TapTimestamp` to calculate total timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"TapTimestamp\":1.0669429302215576,\"TapIndex\":0,\"TapIncorrect\":false},{\"TapTimestamp\":1.43839693069458,\"TapIndex\":2,\"TapIncorrect\":true},{\"TapTimestamp\":2.8393769264221191,\"TapIndex\":4,\"TapIncorrect\":true},{\"TapTimestamp\":3.4151489734649658,\"TapIndex\":0,\"TapIncorrect\":true},{\"TapTimestamp\":5.4343969821929932,\"TapIndex\":1,\"TapIncorrect\":false},{\"TapTimestamp\":6.535146951675415,\"TapIndex\":2,\"TapIncorrect\":false},{\"TapTimestamp\":7.366270899772644,\"TapIndex\":3,\"TapIncorrect\":false},{\"TapTimestamp\":7.936242938041687,\"TapIndex\":4,\"TapIncorrect\":false},{\"TapTimestamp\":8.4680279493331909,\"TapIndex\":5,\"TapIncorrect\":false},{\"TapTimestamp\":9.1123839616775513,\"TapIndex\":6,\"TapIncorrect\":false},{\"TapTimestamp\":9.9355719089508057,\"TapIndex\":7,\"TapIncorrect\":false},{\"TapTimestamp\":13.255127906799316,\"TapIndex\":9,\"TapIncorrect\":true},{\"TapTimestamp\":13.660766959190369,\"TapIndex\":8,\"TapIncorrect\":false},{\"TapTimestamp\":14.298128962516785,\"TapIndex\":9,\"TapIncorrect\":false},{\"TapTimestamp\":15.024495005607605,\"TapIndex\":10,\"TapIncorrect\":false},{\"TapTimestamp\":15.646173000335693,\"TapIndex\":11,\"TapIncorrect\":false},{\"TapTimestamp\":16.491595983505249,\"TapIndex\":12,\"TapIncorrect\":false}]'"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taps is a string of a list of dictionaries\n",
    "df.Taps[250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TapTimestamp': 12.300704956054688, 'TapIndex': 12, 'TapIncorrect': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12.300704956054688"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can convert to list of dicts and then access an individual dict\n",
    "data = json.loads(df.Taps[0])\n",
    "print(data[-1])\n",
    "data[-1]['TapTimestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1667\n",
      "11010\n"
     ]
    }
   ],
   "source": [
    "# convert string Taps to list of dicts\n",
    "df['TapsList'] = df['Taps'].apply(json.loads)\n",
    "\n",
    "# test if any lists are empty...\n",
    "for i in range(len(df.TapsList)):\n",
    "    if df.TapsList[i]:\n",
    "        x = df.TapsList[i][-1]['TapTimestamp']\n",
    "    else:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with empty lists\n",
    "df = df.drop(df.index[[\n",
    "    1667,\n",
    "    11010\n",
    "    ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13029, 13)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add variance\n",
    "def variance_of_differences(taps_str):\n",
    "    # Convert string to list of dictionaries\n",
    "    taps_list = json.loads(taps_str)\n",
    "    \n",
    "    # Extract TapTimestamp values\n",
    "    timestamps = [tap['TapTimestamp'] for tap in taps_list]\n",
    "    \n",
    "    # Calculate the differences between consecutive timestamps\n",
    "    differences = np.diff(timestamps)[1:] # diff between first two taps not relevant\n",
    "    \n",
    "    # Return variance of differences\n",
    "    return np.var(differences)\n",
    "\n",
    "# Apply the function to the TapsList column\n",
    "df['variance_of_diff'] = df['Taps'].apply(variance_of_differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign new columns with final value from TapsList\n",
    "# rename column\n",
    "df = df.assign(task_trailmaking_time=lambda x: x.TapsList.apply(lambda x: x[-1]['TapTimestamp'] - x[1]['TapTimestamp']),\n",
    "               task_trailmaking_errors=lambda x: x.NumberOfErrors)\n",
    "\n",
    "# keep relevant columns\n",
    "trailmaking_df = df[['ParticipantIdentifier', 'trial_date', 'time', 'SurveyName', 'task_trailmaking_time', 'task_trailmaking_errors', 'variance_of_diff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN DATA (see cleaning heading for detail)\n",
    "trailmaking_df = trailmaking_df.loc[(trailmaking_df['task_trailmaking_time'] < 30) & (trailmaking_df['task_trailmaking_time'] !=0) & (trailmaking_df['task_trailmaking_errors'] <=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>time</th>\n",
       "      <th>SurveyName</th>\n",
       "      <th>task_trailmaking_time</th>\n",
       "      <th>task_trailmaking_errors</th>\n",
       "      <th>variance_of_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4f4440e7-3a38-4fa7-9271-9730806e441a</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>13:14:26</td>\n",
       "      <td>task_hk_trailmaking_numeric</td>\n",
       "      <td>8.969085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.288832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4f4440e7-3a38-4fa7-9271-9730806e441a</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>13:15:11</td>\n",
       "      <td>task_hk_trailmaking_alphaNumeric</td>\n",
       "      <td>14.234255</td>\n",
       "      <td>1</td>\n",
       "      <td>0.567672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1dd79a79-dd14-4932-b81b-16f95bbcd796</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>16:53:17</td>\n",
       "      <td>task_hk_trailmaking_numeric</td>\n",
       "      <td>13.172253</td>\n",
       "      <td>0</td>\n",
       "      <td>0.514233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1dd79a79-dd14-4932-b81b-16f95bbcd796</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>16:54:22</td>\n",
       "      <td>task_hk_trailmaking_alphaNumeric</td>\n",
       "      <td>13.540070</td>\n",
       "      <td>0</td>\n",
       "      <td>0.310045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68794228-9bbc-4199-b58c-192307df77f2</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>23:01:39</td>\n",
       "      <td>task_hk_trailmaking_numeric</td>\n",
       "      <td>8.000827</td>\n",
       "      <td>0</td>\n",
       "      <td>0.202404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ParticipantIdentifier  trial_date      time  \\\n",
       "0  4f4440e7-3a38-4fa7-9271-9730806e441a  2023-01-10  13:14:26   \n",
       "1  4f4440e7-3a38-4fa7-9271-9730806e441a  2023-01-10  13:15:11   \n",
       "2  1dd79a79-dd14-4932-b81b-16f95bbcd796  2023-01-10  16:53:17   \n",
       "3  1dd79a79-dd14-4932-b81b-16f95bbcd796  2023-01-10  16:54:22   \n",
       "4  68794228-9bbc-4199-b58c-192307df77f2  2023-01-10  23:01:39   \n",
       "\n",
       "                         SurveyName  task_trailmaking_time  \\\n",
       "0       task_hk_trailmaking_numeric               8.969085   \n",
       "1  task_hk_trailmaking_alphaNumeric              14.234255   \n",
       "2       task_hk_trailmaking_numeric              13.172253   \n",
       "3  task_hk_trailmaking_alphaNumeric              13.540070   \n",
       "4       task_hk_trailmaking_numeric               8.000827   \n",
       "\n",
       "   task_trailmaking_errors  variance_of_diff  \n",
       "0                        1          0.288832  \n",
       "1                        1          0.567672  \n",
       "2                        0          0.514233  \n",
       "3                        0          0.310045  \n",
       "4                        0          0.202404  "
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trailmaking_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make wide\n",
    "trailmaking_df = trailmaking_df.pivot_table(index=['trial_date', 'ParticipantIdentifier'],\n",
    "                                            columns='SurveyName', \n",
    "                                            values=['task_trailmaking_time', 'task_trailmaking_errors', 'variance_of_diff']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten columns\n",
    "trailmaking_df.columns = trailmaking_df.columns.to_series().str.join('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "trailmaking_df.columns = ['trial_date', 'ParticipantIdentifier', 'task_trailmaking_alphaNumeric_errors', 'task_trailmaking_numeric_errors', 'task_trailmaking_alphaNumeric_time', 'task_trailmaking_numeric_time', 'task_trailmaking_alphaNumeric_var', 'task_trailmaking_numeric_var']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial_date</th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>task_trailmaking_alphaNumeric_errors</th>\n",
       "      <th>task_trailmaking_numeric_errors</th>\n",
       "      <th>task_trailmaking_alphaNumeric_time</th>\n",
       "      <th>task_trailmaking_numeric_time</th>\n",
       "      <th>task_trailmaking_alphaNumeric_var</th>\n",
       "      <th>task_trailmaking_numeric_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>1dd79a79-dd14-4932-b81b-16f95bbcd796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.540070</td>\n",
       "      <td>13.172253</td>\n",
       "      <td>0.310045</td>\n",
       "      <td>0.514233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>4f4440e7-3a38-4fa7-9271-9730806e441a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.234255</td>\n",
       "      <td>8.969085</td>\n",
       "      <td>0.567672</td>\n",
       "      <td>0.288832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>68794228-9bbc-4199-b58c-192307df77f2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.918175</td>\n",
       "      <td>8.000827</td>\n",
       "      <td>0.572064</td>\n",
       "      <td>0.202404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>f8f71506-9382-40c7-99db-5c170b2a9abb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.848368</td>\n",
       "      <td>6.397513</td>\n",
       "      <td>0.545629</td>\n",
       "      <td>0.114705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>5af5c134-5a74-416b-b6b2-4e5a29f55688</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.117682</td>\n",
       "      <td>4.998748</td>\n",
       "      <td>0.356313</td>\n",
       "      <td>0.023884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trial_date                 ParticipantIdentifier  \\\n",
       "0  2023-01-10  1dd79a79-dd14-4932-b81b-16f95bbcd796   \n",
       "1  2023-01-10  4f4440e7-3a38-4fa7-9271-9730806e441a   \n",
       "2  2023-01-10  68794228-9bbc-4199-b58c-192307df77f2   \n",
       "3  2023-01-11  f8f71506-9382-40c7-99db-5c170b2a9abb   \n",
       "4  2023-01-13  5af5c134-5a74-416b-b6b2-4e5a29f55688   \n",
       "\n",
       "   task_trailmaking_alphaNumeric_errors  task_trailmaking_numeric_errors  \\\n",
       "0                                   0.0                              0.0   \n",
       "1                                   1.0                              1.0   \n",
       "2                                   0.0                              0.0   \n",
       "3                                   1.0                              0.0   \n",
       "4                                   1.0                              0.0   \n",
       "\n",
       "   task_trailmaking_alphaNumeric_time  task_trailmaking_numeric_time  \\\n",
       "0                           13.540070                      13.172253   \n",
       "1                           14.234255                       8.969085   \n",
       "2                           16.918175                       8.000827   \n",
       "3                           11.848368                       6.397513   \n",
       "4                           17.117682                       4.998748   \n",
       "\n",
       "   task_trailmaking_alphaNumeric_var  task_trailmaking_numeric_var  \n",
       "0                           0.310045                      0.514233  \n",
       "1                           0.567672                      0.288832  \n",
       "2                           0.572064                      0.202404  \n",
       "3                           0.545629                      0.114705  \n",
       "4                           0.356313                      0.023884  "
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trailmaking_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task_trailmaking_numeric_errors       0.395709\n",
       "task_trailmaking_alphaNumeric_time    7.686384\n",
       "task_trailmaking_numeric_time         6.320767\n",
       "task_trailmaking_alphaNumeric_var     0.234049\n",
       "task_trailmaking_numeric_var          0.149666\n",
       "dtype: float64"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trailmaking_df.iloc[:,3:].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6406, 8)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trailmaking_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 52/52 [00:02<00:00, 22.98it/s, Completed]                                                                         \n",
      "Generate report structure: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00,  2.77it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 193.30it/s]\n"
     ]
    }
   ],
   "source": [
    "profile = ProfileReport(trailmaking_df.iloc[:,2:], title=f\"Trailmaking Task Run {run_num} | Pandas Profiling Report\")\n",
    "profile.to_file(eda_reports_path + f\"task_trailmaking_run{run_num}.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean\n",
    "\n",
    "We had numerous outlier values.\n",
    "\n",
    "**ERRORS**\n",
    "\n",
    "Given that there were only 12 responses in a given trial and that the mean error rate was close to 0.5, maximum values such as 54 seem a bit unlikely and may indicate either someone was not trying or not understanding the task.\n",
    "\n",
    "Given that we are dealing with a zero-inflated skewed distribution removing outliers appropriately is challenging.\n",
    "\n",
    "I used an ad-hoc decision to remove those trials with more than 10 errors. This was total of 26 out fo the 6498 total trials.\n",
    "\n",
    "**RTs**\n",
    "\n",
    "We used median absolute deviation to remove outliers (see [Leys et al., 2013](https://www.sciencedirect.com/science/article/abs/pii/S0022103113000668)).\n",
    "\n",
    "We set the flag threshold to 3.\n",
    "\n",
    "However this removed more than 10% of the obervations.\n",
    "\n",
    "Therefore we decided to again use an ad-hoc approach setting the maximum RT threshold to 30 seconds which removes less than 1% of trials.\n",
    "\n",
    "**Also** there were a number of trials with RTs of 0. These were removed.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>📝 Note:</b><br>\n",
    "    I went back and applied these cleaning heuristics to the data in long format so as not to remove both trials in the event they were not both outliers.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMERIC\n",
      "Setting a threshold of 10 removes 0 trials out of 6491 total numeric trials.\n",
      "This is 0.0% of the trials.\n",
      "\n",
      "ALPHANUMERIC\n",
      "Setting a threshold of 10 removes 0 trials out of 6491 total alpha-numeric trials.\n",
      "This is 0.0% of the trials.\n"
     ]
    }
   ],
   "source": [
    "# Remove high error trials\n",
    "\n",
    "threshold = 10\n",
    "\n",
    "count = (trailmaking_df.task_trailmaking_numeric_errors > threshold).sum()\n",
    "total_n =  len(trailmaking_df)\n",
    "\n",
    "print(f'NUMERIC')\n",
    "print(f'Setting a threshold of {threshold} removes {count} trials out of {total_n} total numeric trials.')\n",
    "print(f'This is {(count/total_n)*100:.1f}% of the trials.\\n')\n",
    "\n",
    "count = (trailmaking_df.task_trailmaking_alphaNumeric_errors > threshold).sum()\n",
    "\n",
    "print(f'ALPHANUMERIC')\n",
    "print(f'Setting a threshold of {threshold} removes {count} trials out of {total_n} total alpha-numeric trials.')\n",
    "print(f'This is {(count/total_n)*100:.1f}% of the trials.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMERIC:\n",
      "Using a threshold of 3.0 with MAD we find 590 outliers in the 6491 observations.\n",
      "\n",
      "ALPHANUMERIC:\n",
      "Using a threshold of 3.0 with MAD we find 826 outliers in the 6491 observations.\n"
     ]
    }
   ],
   "source": [
    "# MAD approach to RT outlier removal\n",
    "\n",
    "# Calculate MAD for the specified columns\n",
    "def mad(series):\n",
    "    median_value = series.median()\n",
    "    return (series - median_value).abs().median()\n",
    "\n",
    "# MAD-based outlier detection\n",
    "def detect_outliers(series, threshold):\n",
    "    median_value = series.median()\n",
    "    mad_value = mad(series)\n",
    "    \n",
    "    # Detect outliers\n",
    "    outliers = ((series - median_value).abs() > threshold * mad_value)\n",
    "    return outliers\n",
    "\n",
    "threshold = 3.0\n",
    "\n",
    "# Detect outliers in the 'task_trailmaking_numeric_time' column\n",
    "x = detect_outliers(trailmaking_df['task_trailmaking_numeric_time'], threshold=threshold).sum()\n",
    "print(f'NUMERIC:\\nUsing a threshold of {threshold} with MAD we find {x} outliers in the {trailmaking_df.shape[0]} observations.\\n')\n",
    "\n",
    "# Detect outliers in the 'task_trailmaking_alphaNumeric_time' column\n",
    "x = detect_outliers(trailmaking_df['task_trailmaking_alphaNumeric_time'], threshold=threshold).sum()\n",
    "print(f'ALPHANUMERIC:\\nUsing a threshold of {threshold} with MAD we find {x} outliers in the {trailmaking_df.shape[0]} observations.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMERIC\n",
      "Setting a threshold of 30 removes 0 trials out of 6491 total numeric trials.\n",
      "This is 0.0% of the trials.\n",
      "\n",
      "ALPHANUMERIC\n",
      "Setting a threshold of 30 removes 0 trials out of 6491 total alpha-numeric trials.\n",
      "This is 0.0% of the trials.\n"
     ]
    }
   ],
   "source": [
    "# Ad hoc approach to RT outlier removal\n",
    "threshold = 30\n",
    "\n",
    "count = (trailmaking_df.task_trailmaking_numeric_time > threshold).sum()\n",
    "total_n = trailmaking_df.shape[0]\n",
    "\n",
    "print(f'NUMERIC')\n",
    "print(f'Setting a threshold of {threshold} removes {count} trials out of {total_n} total numeric trials.')\n",
    "print(f'This is {(count/total_n)*100:.1f}% of the trials.\\n')\n",
    "\n",
    "count = (trailmaking_df.task_trailmaking_alphaNumeric_time > threshold).sum()\n",
    "\n",
    "print(f'ALPHANUMERIC')\n",
    "print(f'Setting a threshold of {threshold} removes {count} trials out of {total_n} total alpha-numeric trials.')\n",
    "print(f'This is {(count/total_n)*100:.1f}% of the trials.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stroop\n",
    "\n",
    "[RK Studio Documentation](http://researchkit.org/docs/docs/ActiveTasks/ActiveTasks.html#stroophttp://researchkit.org/docs/docs/ActiveTasks/ActiveTasks.html#stroop)\n",
    "\n",
    "[Scarpina & Tagini, 2017](https://www.frontiersin.org/articles/10.3389/fpsyg.2017.00557/full) on scoring in their paper The Stroop Color and Words Test.\n",
    "\n",
    ">The Stroop Color and Word Test (SCWT) is a neuropsychological test extensively used to assess the ability to inhibit cognitive interference that occurs when the processing of a specific stimulus feature impedes the simultaneous processing of a second stimulus attribute, well-known as the Stroop Effect.\n",
    "\n",
    "**Interpretation**\n",
    ">While the SCWT is widelyused to measure the ability to inhibit cognitive interference; previous literature also reports itsapplication to measure other cognitive functions such as attention, processing speed, cognitive flexibility (Jensen and Rohwer, 1966), and working memory(Kane and Engle, 2003). Thus, it may be possible to use the SCWTto measure multiple cognitive functions.\n",
    "\n",
    ">According to the review, the studies with Italian normativedata present different theoretical interpretations of the SCWTscores.Amato et al. (2006)andCaffarra et al. (2002)describe theSCWT score as a measure of the fronto-executive functioning,while others use it as an index of the attentional functioning(Barbarotto et al., 1998; Valgimigli et al., 2010) or of generalcognitive efficiency (Brugnolo et al., 2015). Slowing to a responseconflict would be due to a failure of selective attention or a lack inthe cognitive efficiency instead of a failure of response inhibition(Chafetz and Matthews, 2004); however, the performance inthe SCWT is not exclusively related to concentration, attentionor cognitive effectiveness, but it relies to a more specificexecutive-frontal domain. Indeed, subjects have to processselectively a specific visual feature blocking out continuouslythe automatic processing of reading (Zajano and Gorman, 1986;Shum et al., 1990), in order to solve correctly the task. The specificinvolvement of executive processes is supported by clinical data.Patients with anterior frontal lesions, and not with posteriorcerebral damages, report significant difficulties in maintaining aconsistent activation of the intended response (Valgimigli et al.,2010). Furthermore, Parkinson’s Disease patients, characterizedby executive dysfunction due to the disruption of dopaminergicpathway (Fera et al., 2007), reported difficulties in SCWT despiteunimpaired attentional abilities (Fera et al., 2007; Djamshidianet al., 2011)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted existing df\n",
      "deleted existing stroop_df\n"
     ]
    }
   ],
   "source": [
    "# erase df if it already exists\n",
    "if 'df' in globals():\n",
    "    del(df)\n",
    "    print('deleted existing df')\n",
    "    \n",
    "if 'stroop_df' in globals():\n",
    "    del(stroop_df)\n",
    "    print('deleted existing stroop_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:00<00:00, 64.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# loop through all days\n",
    "days = [i for i in os.listdir(path) if i.startswith('RK')]\n",
    "for day in tqdm(days):\n",
    "    files = os.listdir(path + day)\n",
    "    surveyQuestions = [i for i in files if i.startswith('SurveyStroopResults')]\n",
    "    # there should be only one\n",
    "    for file in surveyQuestions:\n",
    "        if 'df' not in globals():\n",
    "            df = pd.read_csv(path + day + '/' + file)\n",
    "        else:\n",
    "            temp_df = pd.read_csv(path + day + '/' + file)\n",
    "            df = pd.concat([df,temp_df], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SurveyStroopResultKey         0\n",
       "SurveyStepResultKey           0\n",
       "SurveyResultKey               0\n",
       "ParticipantIdentifier         0\n",
       "StartTime                     0\n",
       "EndTime                       0\n",
       "ColorSelected                 0\n",
       "Color                         0\n",
       "Text                          0\n",
       "StroopStyle              132596\n",
       "StartDate                     0\n",
       "EndDate                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for na dates...\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['EndDate']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only subjects in correct cohort\n",
    "df = df.loc[df.ParticipantIdentifier.isin(subjects)].reset_index(drop=True)\n",
    "\n",
    "# # temporarily removing spanish participant\n",
    "# df = df.loc[df.ParticipantIdentifier!='35d11ffc-7034-4708-a086-cd4bd47b51fd'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130058/130058 [00:13<00:00, 9527.16it/s] \n"
     ]
    }
   ],
   "source": [
    "# add trial date and time columns\n",
    "for i in tqdm(range(df.shape[0])):\n",
    "    dt = parser.parse(df.loc[i, 'EndDate'])\n",
    "    df.loc[i, 'datetime'] = dt\n",
    "    df.loc[i, 'trial_date'] = (dt + datetime.timedelta(hours = -4)).date() # trial day associated with sample (4am is when the day flips)\n",
    "    df.loc[i, 'time'] = dt.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SurveyStroopResultKey</th>\n",
       "      <th>SurveyStepResultKey</th>\n",
       "      <th>SurveyResultKey</th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "      <th>ColorSelected</th>\n",
       "      <th>Color</th>\n",
       "      <th>Text</th>\n",
       "      <th>StroopStyle</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>datetime</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e71501c5-6cd4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>c01501c5-6cd4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>aa1501c5-6cd4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>5599c2a7-88a5-4cde-9f2a-41b4bd03d660</td>\n",
       "      <td>684851.72330562503</td>\n",
       "      <td>684853.02502758335</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>RED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-06T07:18:17-04:00</td>\n",
       "      <td>2023-04-06T07:18:17-04:00</td>\n",
       "      <td>2023-04-06 07:18:17-04:00</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>07:18:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e91501c5-6cd4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>c01501c5-6cd4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>aa1501c5-6cd4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>5599c2a7-88a5-4cde-9f2a-41b4bd03d660</td>\n",
       "      <td>684853.52752987505</td>\n",
       "      <td>684854.27328762505</td>\n",
       "      <td>YELLOW</td>\n",
       "      <td>YELLOW</td>\n",
       "      <td>YELLOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-06T07:18:18-04:00</td>\n",
       "      <td>2023-04-06T07:18:18-04:00</td>\n",
       "      <td>2023-04-06 07:18:18-04:00</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>07:18:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  SurveyStroopResultKey                   SurveyStepResultKey  \\\n",
       "0  e71501c5-6cd4-ed11-aac6-0afb9334277d  c01501c5-6cd4-ed11-aac6-0afb9334277d   \n",
       "1  e91501c5-6cd4-ed11-aac6-0afb9334277d  c01501c5-6cd4-ed11-aac6-0afb9334277d   \n",
       "\n",
       "                        SurveyResultKey                 ParticipantIdentifier  \\\n",
       "0  aa1501c5-6cd4-ed11-aac6-0afb9334277d  5599c2a7-88a5-4cde-9f2a-41b4bd03d660   \n",
       "1  aa1501c5-6cd4-ed11-aac6-0afb9334277d  5599c2a7-88a5-4cde-9f2a-41b4bd03d660   \n",
       "\n",
       "            StartTime             EndTime ColorSelected   Color    Text  \\\n",
       "0  684851.72330562503  684853.02502758335         GREEN   GREEN     RED   \n",
       "1  684853.52752987505  684854.27328762505        YELLOW  YELLOW  YELLOW   \n",
       "\n",
       "   StroopStyle                  StartDate                    EndDate  \\\n",
       "0          NaN  2023-04-06T07:18:17-04:00  2023-04-06T07:18:17-04:00   \n",
       "1          NaN  2023-04-06T07:18:18-04:00  2023-04-06T07:18:18-04:00   \n",
       "\n",
       "                    datetime  trial_date      time  \n",
       "0  2023-04-06 07:18:17-04:00  2023-04-06  07:18:17  \n",
       "1  2023-04-06 07:18:18-04:00  2023-04-06  07:18:18  "
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace commas with dots\n",
    "df['StartTime'] = df['StartTime'].replace(',', '.', regex=True)\n",
    "df.StartTime = df.StartTime.astype('float')\n",
    "\n",
    "df['EndTime'] = df['EndTime'].replace(',', '.', regex=True)\n",
    "df.EndTime = df.EndTime.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "      <th>ColorSelected</th>\n",
       "      <th>Color</th>\n",
       "      <th>Text</th>\n",
       "      <th>congruent</th>\n",
       "      <th>correct</th>\n",
       "      <th>rt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5599c2a7-88a5-4cde-9f2a-41b4bd03d660</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>684851.723306</td>\n",
       "      <td>684853.025028</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>RED</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.301722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5599c2a7-88a5-4cde-9f2a-41b4bd03d660</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>684853.527530</td>\n",
       "      <td>684854.273288</td>\n",
       "      <td>YELLOW</td>\n",
       "      <td>YELLOW</td>\n",
       "      <td>YELLOW</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.745758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5599c2a7-88a5-4cde-9f2a-41b4bd03d660</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>684854.775675</td>\n",
       "      <td>684855.522062</td>\n",
       "      <td>YELLOW</td>\n",
       "      <td>YELLOW</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.746387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ParticipantIdentifier  trial_date      StartTime  \\\n",
       "0  5599c2a7-88a5-4cde-9f2a-41b4bd03d660  2023-04-06  684851.723306   \n",
       "1  5599c2a7-88a5-4cde-9f2a-41b4bd03d660  2023-04-06  684853.527530   \n",
       "2  5599c2a7-88a5-4cde-9f2a-41b4bd03d660  2023-04-06  684854.775675   \n",
       "\n",
       "         EndTime ColorSelected   Color    Text  congruent  correct        rt  \n",
       "0  684853.025028         GREEN   GREEN     RED      False     True  1.301722  \n",
       "1  684854.273288        YELLOW  YELLOW  YELLOW       True     True  0.745758  \n",
       "2  684855.522062        YELLOW  YELLOW   GREEN      False     True  0.746387  "
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create correct, congruous and time columns\n",
    "df = df[['ParticipantIdentifier', 'trial_date', 'StartTime', 'EndTime', 'ColorSelected', 'Color', 'Text']]\n",
    "df = df.assign(congruent=lambda x: x.Color == x.Text,\n",
    "               correct=lambda x: x.Color == x.ColorSelected,\n",
    "               rt=lambda x: (x.EndTime - x.StartTime)\n",
    "              )\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add additional columns\n",
    "# define function that returns a Series of all aggregations\n",
    "\n",
    "def f(x):\n",
    "    d = {}\n",
    "    \n",
    "    d['task_stroop_totalCorrectProp'] = x['correct'].sum()/len(x['correct'])\n",
    "    d['task_stroop_congruentCorrectProp'] = len(x.loc[(x.congruent==True) & (x.correct==True)])/ (x.congruent == True).sum()\n",
    "    d['task_stroop_incongruentCorrectProp'] = len(x.loc[(x.congruent==False) & (x.correct==True)])/ (x.congruent == False).sum()\n",
    "    d['task_stroop_totalAvgRT'] = x['rt'].sum()/len(x['rt'])    \n",
    "    d['task_stroop_congruentAvgRT'] = x.loc[x.congruent==True,'rt'].sum()/ (x.congruent == True).sum()\n",
    "    d['task_stroop_incongruentAvgRT'] = x.loc[x.congruent==False,'rt'].sum()/ (x.congruent == False).sum()\n",
    "    \n",
    "    return pd.Series(d, index=['task_stroop_totalCorrectProp', 'task_stroop_congruentCorrectProp',\n",
    "                               'task_stroop_incongruentCorrectProp', 'task_stroop_totalAvgRT',\n",
    "                               'task_stroop_congruentAvgRT', 'task_stroop_incongruentAvgRT'\n",
    "                              ])\n",
    "\n",
    "# note that value_counts gives us the number of trues and falses for boolean columns\n",
    "# then indexing into 0 for false and 1 for true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>task_stroop_totalCorrectProp</th>\n",
       "      <th>task_stroop_congruentCorrectProp</th>\n",
       "      <th>task_stroop_incongruentCorrectProp</th>\n",
       "      <th>task_stroop_totalAvgRT</th>\n",
       "      <th>task_stroop_congruentAvgRT</th>\n",
       "      <th>task_stroop_incongruentAvgRT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.767591</td>\n",
       "      <td>0.649432</td>\n",
       "      <td>0.864267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-01-30</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.759695</td>\n",
       "      <td>0.670685</td>\n",
       "      <td>0.893211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.765498</td>\n",
       "      <td>0.770194</td>\n",
       "      <td>0.764324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ParticipantIdentifier  trial_date  \\\n",
       "0  0151d9f1-1644-4437-805e-02f5e244a690  2023-01-17   \n",
       "1  0151d9f1-1644-4437-805e-02f5e244a690  2023-01-30   \n",
       "2  0151d9f1-1644-4437-805e-02f5e244a690  2023-01-31   \n",
       "\n",
       "   task_stroop_totalCorrectProp  task_stroop_congruentCorrectProp  \\\n",
       "0                          0.95                               1.0   \n",
       "1                          0.95                               1.0   \n",
       "2                          1.00                               1.0   \n",
       "\n",
       "   task_stroop_incongruentCorrectProp  task_stroop_totalAvgRT  \\\n",
       "0                            0.909091                0.767591   \n",
       "1                            0.875000                0.759695   \n",
       "2                            1.000000                0.765498   \n",
       "\n",
       "   task_stroop_congruentAvgRT  task_stroop_incongruentAvgRT  \n",
       "0                    0.649432                      0.864267  \n",
       "1                    0.670685                      0.893211  \n",
       "2                    0.770194                      0.764324  "
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stroop_df = df.groupby(['ParticipantIdentifier', 'trial_date']).apply(f).reset_index()\n",
    "stroop_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task_stroop_totalCorrectProp          0.939470\n",
       "task_stroop_congruentCorrectProp      0.977041\n",
       "task_stroop_incongruentCorrectProp    0.901700\n",
       "task_stroop_totalAvgRT                0.907755\n",
       "task_stroop_congruentAvgRT            0.902239\n",
       "task_stroop_incongruentAvgRT          0.915852\n",
       "dtype: float64"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stroop_df.iloc[:,2:].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 51/51 [00:01<00:00, 30.22it/s, Completed]                                                                     \n",
      "Generate report structure: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 197.66it/s]\n"
     ]
    }
   ],
   "source": [
    "profile = ProfileReport(stroop_df.iloc[:,2:], title=f\"Stroop Task Run {run_num} | Pandas Profiling Report\")\n",
    "profile.to_file(eda_reports_path + f\"task_stroop_run{run_num}.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean\n",
    "\n",
    "We had some clear RT outlier values given that the mean of the trials' average RT (even with outliers) was less than 1 second, and yet there where maxmum average RT that were multiple minutes.\n",
    "\n",
    "**RTs**\n",
    "\n",
    "We first used median absolute deviation to remove outliers (see [Leys et al., 2013](https://www.sciencedirect.com/science/article/abs/pii/S0022103113000668)).\n",
    "\n",
    "We set the flag threshold to 3.\n",
    "\n",
    "However this would remove more than 10% of the obervations.\n",
    "\n",
    "Therefore we decided to use an ad-hoc approach setting the maximum RT threshold to 3 seconds which removes less than 1% of trials.\n",
    "\n",
    "We also know from the work of Luce (1984) and Whelan (2008) that RTs below 100ms are not realistic.\n",
    "\n",
    "Therefore all trials with average RTs below 100 were also removed (this only removed one trial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMERIC:\n",
      "Using a threshold of 3.0 with MAD we find 818 outliers in the 6406 observations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MAD approach to RT outlier removal\n",
    "\n",
    "# Calculate MAD for the specified columns\n",
    "def mad(series):\n",
    "    median_value = series.median()\n",
    "    return (series - median_value).abs().median()\n",
    "\n",
    "# MAD-based outlier detection\n",
    "def detect_outliers(series, threshold):\n",
    "    median_value = series.median()\n",
    "    mad_value = mad(series)\n",
    "    \n",
    "    # Detect outliers\n",
    "    outliers = ((series - median_value).abs() > threshold * mad_value)\n",
    "    return outliers\n",
    "\n",
    "threshold = 3.0\n",
    "\n",
    "# Detect outliers in the 'task_trailmaking_numeric_time' column\n",
    "x = detect_outliers(stroop_df['task_stroop_totalAvgRT'], threshold=threshold).sum()\n",
    "print(f'NUMERIC:\\nUsing a threshold of {threshold} with MAD we find {x} outliers in the {trailmaking_df.shape[0]} observations.\\n')\n",
    "\n",
    "# # Detect outliers in the 'task_trailmaking_alphaNumeric_time' column\n",
    "# x = detect_outliers(trailmaking_df['task_trailmaking_alphaNumeric_time'], threshold=threshold).sum()\n",
    "# print(f'ALPHANUMERIC:\\nUsing a threshold of {threshold} with MAD we find {x} outliers in the {trailmaking_df.shape[0]} observations.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEILING\n",
      "Setting a threshold of 3s removes 0 trials out of 6484 total numeric trials.\n",
      "This is 0.0% of the trials.\n",
      "\n",
      "FLOOR\n",
      "Setting a threshold of 0.1s removes 0 trials out of 6484 total alpha-numeric trials.\n",
      "This is 0.0% of the trials.\n"
     ]
    }
   ],
   "source": [
    "# Ad hoc approach to RT outlier removal\n",
    "threshold = 3\n",
    "\n",
    "count = (stroop_df.task_stroop_totalAvgRT > threshold).sum()\n",
    "total_n = stroop_df.shape[0]\n",
    "\n",
    "print(f'CEILING')\n",
    "print(f'Setting a threshold of {threshold}s removes {count} trials out of {total_n} total numeric trials.')\n",
    "print(f'This is {(count/total_n)*100:.1f}% of the trials.\\n')\n",
    "\n",
    "# Remove values based on these thresholds\n",
    "stroop_df = stroop_df.loc[stroop_df.task_stroop_totalAvgRT <= threshold]\n",
    "\n",
    "threshold = .1\n",
    "count = (stroop_df.task_stroop_totalAvgRT < threshold).sum()\n",
    "\n",
    "print(f'FLOOR')\n",
    "print(f'Setting a threshold of {threshold}s removes {count} trials out of {total_n} total alpha-numeric trials.')\n",
    "print(f'This is {(count/total_n)*100:.1f}% of the trials.')\n",
    "\n",
    "stroop_df = stroop_df.loc[stroop_df.task_stroop_totalAvgRT > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 51/51 [00:01<00:00, 27.91it/s, Completed]                                                                     \n",
      "Generate report structure: 100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00,  2.85it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 458.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# Rerun EDA with clean df\n",
    "profile = ProfileReport(stroop_df.iloc[:,2:], title=f\"Stroop Task Run {run_num} - Clean | Pandas Profiling Report\")\n",
    "profile.to_file(eda_reports_path + f\"task_stroop_run{run_num}_clean.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSAT\n",
    "\n",
    "[RKStudio Documentation](https://rkstudio-support.careevolution.com/hc/en-us/articles/1500002352262-Paced-Serial-Addition-Test-PSAT-Active-Task-Export-Format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted existing df\n",
      "deleted existing psat_df\n"
     ]
    }
   ],
   "source": [
    "# erase df if it already exists\n",
    "if 'df' in globals():\n",
    "    del(df)\n",
    "    print('deleted existing df')\n",
    "    \n",
    "if 'psat_df' in globals():\n",
    "    del(psat_df)\n",
    "    print('deleted existing psat_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:00<00:00, 210.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# loop through all days\n",
    "days = [i for i in os.listdir(path) if i.startswith('RK')]\n",
    "for day in tqdm(days):\n",
    "    files = os.listdir(path + day)\n",
    "    surveyQuestions = [i for i in files if i.startswith('SurveyPSATResults')]\n",
    "    # there should be only one\n",
    "    for file in surveyQuestions:\n",
    "        if 'df' not in globals():\n",
    "            df = pd.read_csv(path + day + '/' + file)\n",
    "        else:\n",
    "            temp_df = pd.read_csv(path + day + '/' + file)\n",
    "            df = pd.concat([df,temp_df], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SurveyPSATResultKey      0\n",
       "SurveyStepResultKey      0\n",
       "SurveyResultKey          0\n",
       "ParticipantIdentifier    0\n",
       "PresentationMode         0\n",
       "InterStimulusInterval    0\n",
       "StimulusDuration         0\n",
       "Length                   0\n",
       "TotalCorrect             0\n",
       "TotalDyad                0\n",
       "TotalTime                0\n",
       "InitialDigit             0\n",
       "StartDate                0\n",
       "EndDate                  0\n",
       "Samples                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for na dates...\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['EndDate']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only subjects in current run\n",
    "df = df.loc[df.ParticipantIdentifier.isin(subjects)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6418/6418 [00:00<00:00, 9199.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# add trial date and time columns\n",
    "for i in tqdm(range(df.shape[0])):\n",
    "    dt = parser.parse(df.loc[i, 'EndDate'])\n",
    "    df.loc[i, 'datetime'] = dt\n",
    "    df.loc[i, 'trial_date'] = (dt + datetime.timedelta(hours = -4)).date() # trial day associated with sample (4am is when the day flips)\n",
    "    df.loc[i, 'time'] = dt.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SurveyPSATResultKey</th>\n",
       "      <th>SurveyStepResultKey</th>\n",
       "      <th>SurveyResultKey</th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>PresentationMode</th>\n",
       "      <th>InterStimulusInterval</th>\n",
       "      <th>StimulusDuration</th>\n",
       "      <th>Length</th>\n",
       "      <th>TotalCorrect</th>\n",
       "      <th>TotalDyad</th>\n",
       "      <th>TotalTime</th>\n",
       "      <th>InitialDigit</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Samples</th>\n",
       "      <th>datetime</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f1280b3d-6dd4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>d7280b3d-6dd4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>c9280b3d-6dd4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>5599c2a7-88a5-4cde-9f2a-41b4bd03d660</td>\n",
       "      <td>Visual</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>48.8601155419601</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-04-06T07:22:05-04:00</td>\n",
       "      <td>2023-04-06T07:22:05-04:00</td>\n",
       "      <td>[{\"Answer\":11,\"Correct\":true,\"Time\":1.38083220...</td>\n",
       "      <td>2023-04-06 07:22:05-04:00</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>07:22:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d180e650-6ed4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>c280e650-6ed4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>b480e650-6ed4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>Visual</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>33.7597789999999</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-04-06T07:29:40-04:00</td>\n",
       "      <td>2023-04-06T07:29:40-04:00</td>\n",
       "      <td>[{\"Answer\":4,\"Correct\":true,\"Time\":1.594179666...</td>\n",
       "      <td>2023-04-06 07:29:40-04:00</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>07:29:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    SurveyPSATResultKey                   SurveyStepResultKey  \\\n",
       "0  f1280b3d-6dd4-ed11-aac6-0afb9334277d  d7280b3d-6dd4-ed11-aac6-0afb9334277d   \n",
       "1  d180e650-6ed4-ed11-aac6-0afb9334277d  c280e650-6ed4-ed11-aac6-0afb9334277d   \n",
       "\n",
       "                        SurveyResultKey                 ParticipantIdentifier  \\\n",
       "0  c9280b3d-6dd4-ed11-aac6-0afb9334277d  5599c2a7-88a5-4cde-9f2a-41b4bd03d660   \n",
       "1  b480e650-6ed4-ed11-aac6-0afb9334277d  0151d9f1-1644-4437-805e-02f5e244a690   \n",
       "\n",
       "  PresentationMode  InterStimulusInterval  StimulusDuration  Length  \\\n",
       "0           Visual                      3                 1      30   \n",
       "1           Visual                      3                 1      30   \n",
       "\n",
       "   TotalCorrect  TotalDyad         TotalTime  InitialDigit  \\\n",
       "0            29         27  48.8601155419601             2   \n",
       "1            30         29  33.7597789999999             3   \n",
       "\n",
       "                   StartDate                    EndDate  \\\n",
       "0  2023-04-06T07:22:05-04:00  2023-04-06T07:22:05-04:00   \n",
       "1  2023-04-06T07:29:40-04:00  2023-04-06T07:29:40-04:00   \n",
       "\n",
       "                                             Samples  \\\n",
       "0  [{\"Answer\":11,\"Correct\":true,\"Time\":1.38083220...   \n",
       "1  [{\"Answer\":4,\"Correct\":true,\"Time\":1.594179666...   \n",
       "\n",
       "                    datetime  trial_date      time  \n",
       "0  2023-04-06 07:22:05-04:00  2023-04-06  07:22:05  \n",
       "1  2023-04-06 07:29:40-04:00  2023-04-06  07:29:40  "
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The important data is:\n",
    "- `Length` + `TotalCorrect` to determine accuracy\n",
    "- `TotalTime` / `Length` to get time/trial \n",
    "    - (use this instead of `TotalTime` in case we change number of trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace commas with decimals (for European participants)\n",
    "df['TotalTime'] = df['TotalTime'].replace(',', '.', regex=True)\n",
    "df.TotalTime = df.TotalTime.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>task_psat_accuracy</th>\n",
       "      <th>task_psat_avgRT</th>\n",
       "      <th>task_psat_varRT</th>\n",
       "      <th>task_psat_flag_sub100RT_n</th>\n",
       "      <th>task_psat_flag_3plusRT_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5599c2a7-88a5-4cde-9f2a-41b4bd03d660</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.432420</td>\n",
       "      <td>0.254876</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.125326</td>\n",
       "      <td>0.115776</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ParticipantIdentifier  trial_date  task_psat_accuracy  \\\n",
       "0  5599c2a7-88a5-4cde-9f2a-41b4bd03d660  2023-04-06            0.966667   \n",
       "1  0151d9f1-1644-4437-805e-02f5e244a690  2023-04-06            1.000000   \n",
       "\n",
       "   task_psat_avgRT  task_psat_varRT  task_psat_flag_sub100RT_n  \\\n",
       "0         1.432420         0.254876                          0   \n",
       "1         1.125326         0.115776                          0   \n",
       "\n",
       "   task_psat_flag_3plusRT_n  \n",
       "0                         1  \n",
       "1                         0  "
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate 'task_psat_accuracy' column\n",
    "df['task_psat_accuracy'] = df['TotalCorrect'] / df['Length']\n",
    "\n",
    "# Define a function to calculate 'task_psat_avgRT', 'task_psat_flag_3plusRT_n', 'task_psat_flag_sub100RT_n' and 'task_psat_varRT'\n",
    "def calculate_avgRT_and_flag(samples, length):\n",
    "    # Convert the string representation of the samples list into a list of dictionaries\n",
    "    samples_list = json.loads(samples)\n",
    "    \n",
    "    # Extract all 'Time' values\n",
    "    times = [item[\"Time\"] for item in samples_list]\n",
    "    \n",
    "    # Count the number of 'Time' values greater than 3.0\n",
    "    flag_count = sum(1 for time in times if time > 3.0)\n",
    "    \n",
    "    # Replace 'Time' values greater than 3.0 with 3.0\n",
    "    times = [min(time, 3.0) for time in times]\n",
    "    \n",
    "    # Calculate the average 'Time' value\n",
    "    avgRT = sum(times) / length\n",
    "    \n",
    "    # Flag 'Time' values less than 100ms\n",
    "    min100_count = sum(1 for time in times if time < 0.1)\n",
    "    \n",
    "    # Calculate the variance of 'Time' values\n",
    "    varRT = np.var(times)\n",
    "    \n",
    "    return avgRT, flag_count, varRT, min100_count\n",
    "\n",
    "# Apply the function to the DataFrame and split the results into two new columns\n",
    "df['task_psat_avgRT'], df['task_psat_flag_3plusRT_n'], df['task_psat_varRT'], df['task_psat_flag_sub100RT_n'] = zip(*df.apply(lambda row: calculate_avgRT_and_flag(row['Samples'], row['Length']), axis=1))\n",
    "\n",
    "# keep relevant columns\n",
    "psat_df = df[['ParticipantIdentifier', 'trial_date', 'task_psat_accuracy', 'task_psat_avgRT', 'task_psat_varRT', 'task_psat_flag_sub100RT_n', 'task_psat_flag_3plusRT_n']]\n",
    "psat_df.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 30/30 [00:00<00:00, 33.77it/s, Completed]                                                   \n",
      "Generate report structure: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 598.50it/s]\n"
     ]
    }
   ],
   "source": [
    "profile = ProfileReport(psat_df.iloc[:,2:], title=f\"PSAT Task Run {run_num} | Pandas Profiling Report\")\n",
    "profile.to_file(eda_reports_path + f\"task_psat_run{run_num}.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean\n",
    "\n",
    "We had some clear RT outlier values given that the mean of the trials' average RT (even with outliers) was less than 1 second, and yet there where maxmum average RT that were multiple minutes.\n",
    "\n",
    "Going back it appeared that there were glitches as on some trials there were response times above 3.0 seconds which should have been the in-app limit. \n",
    "\n",
    "I replaced any values above 3.0 with 3.0 before calculating the average RT time per trial.\n",
    "I also created a column called `task_psat_flag_3plusRT_n` that indicated how many responses had an RT greater than 3.0 orginally, for each trial. For cohort 2, for example, 212 trials (out of 6418) had at least one RT greater than 3.0.\n",
    "\n",
    "**RTs**\n",
    "\n",
    "We also know from the work of Luce (1984) and Whelan (2008) that RTs below 100ms are not realistic.\n",
    "\n",
    "We therefore also counted up how many responses in each trial had RTs BELOW 100ms and indicated the numebr in the column `task_psat_flag_sub100RT_n`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tower of Hanoi\n",
    "\n",
    "[RK Studio Documentation](http://researchkit.org/docs/docs/ActiveTasks/ActiveTasks.html#towerhttp://researchkit.org/docs/docs/ActiveTasks/ActiveTasks.html#tower)\n",
    "\n",
    ">In the Tower of Hanoi task the user is asked to solve the classic Tower of Hanoi puzzle in a minimum number of moves. To solve the puzzle, the user must move the entire stack to the highlighted platform in as few moves as possible. This task measures the user’s problem solving skills. A Tower of Hanoi task finishes when the user completes the puzzle correctly or concedes that they cannot solve the puzzle.\n",
    "\n",
    ">Data collected by this task is in the form of an ORKTowerOfHanoiResult object. It contains every move taken by the user and indicates whether the puzzle was successfully completed or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted existing df\n",
      "deleted existing toh_df\n"
     ]
    }
   ],
   "source": [
    "# erase df if it already exists\n",
    "if 'df' in globals():\n",
    "    del(df)\n",
    "    print('deleted existing df')\n",
    "    \n",
    "if 'toh_df' in globals():\n",
    "    del(toh_df)\n",
    "    print('deleted existing toh_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:00<00:00, 212.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# loop through all days\n",
    "days = [i for i in os.listdir(path) if i.startswith('RK')]\n",
    "for day in tqdm(days):\n",
    "    files = os.listdir(path + day)\n",
    "    surveyQuestions = [i for i in files if i.startswith('SurveyTowerOfHanoiResults')]\n",
    "    # there should be only one\n",
    "    for file in surveyQuestions:\n",
    "        if 'df' not in globals():\n",
    "            df = pd.read_csv(path + day + '/' + file)\n",
    "        else:\n",
    "            temp_df = pd.read_csv(path + day + '/' + file)\n",
    "            df = pd.concat([df,temp_df], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SurveyTowerOfHanoiResultKey    0\n",
       "SurveyStepResultKey            0\n",
       "SurveyResultKey                0\n",
       "ParticipantIdentifier          0\n",
       "PuzzleWasSolved                0\n",
       "StartDate                      0\n",
       "EndDate                        0\n",
       "Moves                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for na dates...\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['EndDate']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only subjects in current run\n",
    "df = df.loc[df.ParticipantIdentifier.isin(subjects)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 1883/6533 [00:00<00:00, 9422.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6533/6533 [00:00<00:00, 9425.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SurveyTowerOfHanoiResultKey</th>\n",
       "      <th>SurveyStepResultKey</th>\n",
       "      <th>SurveyResultKey</th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>PuzzleWasSolved</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Moves</th>\n",
       "      <th>datetime</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86e6ebd6-6cd4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>6ee6ebd6-6cd4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>5ae6ebd6-6cd4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>5599c2a7-88a5-4cde-9f2a-41b4bd03d660</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-04-06T07:18:50-04:00</td>\n",
       "      <td>2023-04-06T07:19:06-04:00</td>\n",
       "      <td>[{\"Timestamp\":0.0,\"DonorTowerIndex\":0,\"Recipie...</td>\n",
       "      <td>2023-04-06 07:19:06-04:00</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>07:19:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>381fe5fc-6dd4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>1f1fe5fc-6dd4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>081fe5fc-6dd4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-04-06T07:27:07-04:00</td>\n",
       "      <td>2023-04-06T07:27:21-04:00</td>\n",
       "      <td>[{\"Timestamp\":0.0,\"DonorTowerIndex\":0,\"Recipie...</td>\n",
       "      <td>2023-04-06 07:27:21-04:00</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>07:27:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3c696e9e-71d4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>29696e9e-71d4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>18696e9e-71d4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>35d11ffc-7034-4708-a086-cd4bd47b51fd</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-04-06T07:52:20-04:00</td>\n",
       "      <td>2023-04-06T07:53:22-04:00</td>\n",
       "      <td>[{\"Timestamp\":0.0,\"DonorTowerIndex\":0,\"Recipie...</td>\n",
       "      <td>2023-04-06 07:53:22-04:00</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>07:53:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            SurveyTowerOfHanoiResultKey                   SurveyStepResultKey  \\\n",
       "0  86e6ebd6-6cd4-ed11-aac6-0afb9334277d  6ee6ebd6-6cd4-ed11-aac6-0afb9334277d   \n",
       "1  381fe5fc-6dd4-ed11-aac6-0afb9334277d  1f1fe5fc-6dd4-ed11-aac6-0afb9334277d   \n",
       "2  3c696e9e-71d4-ed11-aac6-0afb9334277d  29696e9e-71d4-ed11-aac6-0afb9334277d   \n",
       "\n",
       "                        SurveyResultKey                 ParticipantIdentifier  \\\n",
       "0  5ae6ebd6-6cd4-ed11-aac6-0afb9334277d  5599c2a7-88a5-4cde-9f2a-41b4bd03d660   \n",
       "1  081fe5fc-6dd4-ed11-aac6-0afb9334277d  0151d9f1-1644-4437-805e-02f5e244a690   \n",
       "2  18696e9e-71d4-ed11-aac6-0afb9334277d  35d11ffc-7034-4708-a086-cd4bd47b51fd   \n",
       "\n",
       "   PuzzleWasSolved                  StartDate                    EndDate  \\\n",
       "0             True  2023-04-06T07:18:50-04:00  2023-04-06T07:19:06-04:00   \n",
       "1             True  2023-04-06T07:27:07-04:00  2023-04-06T07:27:21-04:00   \n",
       "2             True  2023-04-06T07:52:20-04:00  2023-04-06T07:53:22-04:00   \n",
       "\n",
       "                                               Moves  \\\n",
       "0  [{\"Timestamp\":0.0,\"DonorTowerIndex\":0,\"Recipie...   \n",
       "1  [{\"Timestamp\":0.0,\"DonorTowerIndex\":0,\"Recipie...   \n",
       "2  [{\"Timestamp\":0.0,\"DonorTowerIndex\":0,\"Recipie...   \n",
       "\n",
       "                    datetime  trial_date      time  \n",
       "0  2023-04-06 07:19:06-04:00  2023-04-06  07:19:06  \n",
       "1  2023-04-06 07:27:21-04:00  2023-04-06  07:27:21  \n",
       "2  2023-04-06 07:53:22-04:00  2023-04-06  07:53:22  "
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add trial date and time columns\n",
    "for i in tqdm(range(df.shape[0])):\n",
    "    dt = parser.parse(df.loc[i, 'EndDate'])\n",
    "    df.loc[i, 'datetime'] = dt\n",
    "    df.loc[i, 'trial_date'] = (dt + datetime.timedelta(hours = -4)).date() # trial day associated with sample (4am is when the day flips)\n",
    "    df.loc[i, 'time'] = dt.time()\n",
    "    \n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important data is in `Moves` where we have:\n",
    "- `TapTimestamp`\n",
    "- `TapIndex`\n",
    "- `TapIncorrect`\n",
    "\n",
    "I want to get the last `TapTimestamp` to calculate total timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"Timestamp\":0.0,\"DonorTowerIndex\":0,\"RecipientTowerIndex\":2},{\"Timestamp\":1.0491399765014648,\"DonorTowerIndex\":0,\"RecipientTowerIndex\":1},{\"Timestamp\":1.4823609590530396,\"DonorTowerIndex\":2,\"RecipientTowerIndex\":1},{\"Timestamp\":2.0486660003662109,\"DonorTowerIndex\":0,\"RecipientTowerIndex\":2},{\"Timestamp\":2.53186297416687,\"DonorTowerIndex\":1,\"RecipientTowerIndex\":0},{\"Timestamp\":2.9984489679336548,\"DonorTowerIndex\":1,\"RecipientTowerIndex\":2},{\"Timestamp\":3.5813790559768677,\"DonorTowerIndex\":0,\"RecipientTowerIndex\":2},{\"Timestamp\":4.1143800020217896,\"DonorTowerIndex\":0,\"RecipientTowerIndex\":1},{\"Timestamp\":4.563789963722229,\"DonorTowerIndex\":2,\"RecipientTowerIndex\":1},{\"Timestamp\":5.097709059715271,\"DonorTowerIndex\":2,\"RecipientTowerIndex\":0},{\"Timestamp\":5.5808260440826416,\"DonorTowerIndex\":1,\"RecipientTowerIndex\":0},{\"Timestamp\":6.0962109565734863,\"DonorTowerIndex\":2,\"RecipientTowerIndex\":1},{\"Timestamp\":6.5959550142288208,\"DonorTowerIndex\":0,\"RecipientTowerIndex\":2},{\"Timestamp\":7.0955619812011719,\"DonorTowerIndex\":0,\"RecipientTowerIndex\":1},{\"Timestamp\":7.6787470579147339,\"DonorTowerIndex\":2,\"RecipientTowerIndex\":1},{\"Timestamp\":8.2283840179443359,\"DonorTowerIndex\":0,\"RecipientTowerIndex\":2},{\"Timestamp\":8.6945329904556274,\"DonorTowerIndex\":1,\"RecipientTowerIndex\":0},{\"Timestamp\":9.17838203907013,\"DonorTowerIndex\":1,\"RecipientTowerIndex\":2},{\"Timestamp\":9.727599024772644,\"DonorTowerIndex\":0,\"RecipientTowerIndex\":2},{\"Timestamp\":10.177242994308472,\"DonorTowerIndex\":1,\"RecipientTowerIndex\":0},{\"Timestamp\":10.693634986877441,\"DonorTowerIndex\":2,\"RecipientTowerIndex\":1},{\"Timestamp\":11.193461060523987,\"DonorTowerIndex\":2,\"RecipientTowerIndex\":0},{\"Timestamp\":11.660377025604248,\"DonorTowerIndex\":1,\"RecipientTowerIndex\":0},{\"Timestamp\":12.12614905834198,\"DonorTowerIndex\":1,\"RecipientTowerIndex\":2},{\"Timestamp\":12.675623059272766,\"DonorTowerIndex\":0,\"RecipientTowerIndex\":2},{\"Timestamp\":13.225206971168518,\"DonorTowerIndex\":0,\"RecipientTowerIndex\":1},{\"Timestamp\":13.674962043762207,\"DonorTowerIndex\":2,\"RecipientTowerIndex\":1},{\"Timestamp\":14.174193978309631,\"DonorTowerIndex\":0,\"RecipientTowerIndex\":2},{\"Timestamp\":14.707520961761475,\"DonorTowerIndex\":1,\"RecipientTowerIndex\":0},{\"Timestamp\":15.207800984382629,\"DonorTowerIndex\":1,\"RecipientTowerIndex\":2},{\"Timestamp\":15.773602962493897,\"DonorTowerIndex\":0,\"RecipientTowerIndex\":2}]'"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taps is a string of a list of dictionaries\n",
    "df.Moves[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Timestamp': 15.773602962493896, 'DonorTowerIndex': 0, 'RecipientTowerIndex': 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15.773602962493896"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can convert to list of dicts and then access an individual dict\n",
    "data = json.loads(df.Moves[0])\n",
    "\n",
    "# print last dict\n",
    "print(data[-1])\n",
    "\n",
    "# extract the time\n",
    "data[-1]['Timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numbmer of moves\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string Taps to list of dicts\n",
    "df['MovesList'] = df['Moves'].apply(json.loads)\n",
    "\n",
    "# test if any lists are empty...this means NO MOVES\n",
    "drop_ix = []\n",
    "\n",
    "for i in range(len(df.MovesList)):\n",
    "    if df.MovesList[i]:\n",
    "        x = df.MovesList[i][-1]['Timestamp']\n",
    "    else:\n",
    "        drop_ix.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with empty move lists\n",
    "df = df.drop(df.index[drop_ix]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The important data is:\n",
    "- `PuzzleWasSolved`\n",
    "    - just to indicate completion\n",
    "- Get total time required\n",
    "    - `Timestamp` in last dictionary\n",
    "- Get number of moves\n",
    "    - 1 dict/move so get count of dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lw/ys_1b9sj08s904m4402qr0bm0000gn/T/ipykernel_55486/698439430.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  toh_df['task_hanoi_extraMoves'] = toh_df['task_hanoi_moves'] - 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>task_hanoi_solved</th>\n",
       "      <th>task_hanoi_time</th>\n",
       "      <th>task_hanoi_moves</th>\n",
       "      <th>task_hanoi_extraMoves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5599c2a7-88a5-4cde-9f2a-41b4bd03d660</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>True</td>\n",
       "      <td>15.773603</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>True</td>\n",
       "      <td>13.860316</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ParticipantIdentifier  trial_date  task_hanoi_solved  \\\n",
       "0  5599c2a7-88a5-4cde-9f2a-41b4bd03d660  2023-04-06               True   \n",
       "1  0151d9f1-1644-4437-805e-02f5e244a690  2023-04-06               True   \n",
       "\n",
       "   task_hanoi_time  task_hanoi_moves  task_hanoi_extraMoves  \n",
       "0        15.773603                31                      0  \n",
       "1        13.860316                31                      0  "
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign new columns\n",
    "df = df.assign(task_hanoi_solved=lambda x: x.PuzzleWasSolved,\n",
    "               task_hanoi_time=lambda x: x.MovesList.apply(lambda x: x[-1]['Timestamp']),\n",
    "               task_hanoi_moves=[len(moves) for moves in df.MovesList] # maybe give this as a multiple on optimality (ideal = 1)?\n",
    "              )\n",
    "\n",
    "# keep relevant columns\n",
    "toh_df = df[['ParticipantIdentifier', 'trial_date', 'task_hanoi_solved', 'task_hanoi_time', 'task_hanoi_moves']]\n",
    "\n",
    "# add extra moves column\n",
    "toh_df['task_hanoi_extraMoves'] = toh_df['task_hanoi_moves'] - 31\n",
    "toh_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task_hanoi_solved         0.936546\n",
       "task_hanoi_time          43.112464\n",
       "task_hanoi_moves         42.777189\n",
       "task_hanoi_extraMoves    11.777189\n",
       "dtype: float64"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toh_df.iloc[:, 2:].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 22/22 [00:00<00:00, 42.98it/s, Completed]                                           \n",
      "Generate report structure: 100%|██████████| 1/1 [00:00<00:00,  2.12it/s]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 307.32it/s]\n"
     ]
    }
   ],
   "source": [
    "profile = ProfileReport(toh_df.iloc[:,2:], title=f\"TOH Task Run {run_num} | Pandas Profiling Report\")\n",
    "profile.to_file(eda_reports_path + f\"task_toh_run{run_num}.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean\n",
    "\n",
    "**RTs**\n",
    "\n",
    "While our mean time to solve the puzzle was about 48 seconds (without removing outliers), we have extreme values of over 12,000 seconds.\n",
    "\n",
    "We chose to use an ad-hoc method of removing trials where we cut out any trials that took longer than 10 minutes. This only removed 13 trials (out of 6333) in cohort 2.\n",
    "\n",
    "---\n",
    "\n",
    "We also have values of zero (95 in cohort 2). Most of these actually indicate that the puzzle was solved, which is of course impossible.\n",
    "\n",
    "All rows with a `task_hanoi_time` of zero are removed.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 22/22 [00:00<00:00, 41.82it/s, Completed]                                           \n",
      "Generate report structure: 100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00,  9.11it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 912.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# Remove all trials with zero time\n",
    "toh_df = toh_df.loc[toh_df['task_hanoi_time'] >0]\n",
    "\n",
    "# Remove all trials with more than 10 minutes time\n",
    "toh_df = toh_df.loc[toh_df['task_hanoi_time'] <=600]\n",
    "\n",
    "# Rerun EDA\n",
    "profile = ProfileReport(toh_df.iloc[:,2:], title=f\"TOH Task Run {run_num} - Clean | Pandas Profiling Report\")\n",
    "profile.to_file(eda_reports_path + f\"task_toh_run{run_num}_clean.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reaction Time\n",
    "\n",
    "This was **Not Working** for at least the first half of **Run 1**.\n",
    "\n",
    "A new task has been created by RK Studio, called the **Normalized Reaction Time** task.\n",
    "\n",
    "The data export format info is [here](https://support.mydatahelps.org/hc/en-us/articles/1500002230281-Normalized-Reaction-Time-Active-Task-Export-Format)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted existing df\n",
      "deleted existing rt_df\n"
     ]
    }
   ],
   "source": [
    "# erase df if it already exists\n",
    "if 'df' in globals():\n",
    "    del(df)\n",
    "    print('deleted existing df')\n",
    "    \n",
    "if 'rt_df' in globals():\n",
    "    del(rt_df)\n",
    "    print('deleted existing rt_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:00<00:00, 217.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# loop through all days\n",
    "days = [i for i in os.listdir(path) if i.startswith('RK')]\n",
    "for day in tqdm(days):\n",
    "    files = os.listdir(path + day)\n",
    "    surveyQuestions = [i for i in files if i.startswith('SurveyNormalizedReactionTime')]\n",
    "    # there should be only one\n",
    "    for file in surveyQuestions:\n",
    "        if 'df' not in globals():\n",
    "            df = pd.read_csv(path + day + '/' + file)\n",
    "        else:\n",
    "            temp_df = pd.read_csv(path + day + '/' + file)\n",
    "            df = pd.concat([df,temp_df], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SurveyNormalizedReactionTimeResultKey    0\n",
       "SurveyStepResultKey                      0\n",
       "SurveyResultKey                          0\n",
       "ParticipantIdentifier                    0\n",
       "ReactionDate                             0\n",
       "StimulusStartDate                        0\n",
       "TimerStartDate                           0\n",
       "TimerEndDate                             0\n",
       "CurrentInterval                          0\n",
       "StartDate                                0\n",
       "EndDate                                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for na dates...\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['EndDate']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only subjects in current run\n",
    "df = df.loc[df.ParticipantIdentifier.isin(subjects)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26119/26119 [00:02<00:00, 9860.60it/s] \n"
     ]
    }
   ],
   "source": [
    "# add trial date and time columns\n",
    "for i in tqdm(range(df.shape[0])):\n",
    "    dt = parser.parse(df.loc[i, 'EndDate'])\n",
    "    df.loc[i, 'datetime'] = dt\n",
    "    df.loc[i, 'trial_date'] = (dt + datetime.timedelta(hours = -4)).date() # trial day associated with sample (4am is when the day flips)\n",
    "    df.loc[i, 'time'] = dt.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SurveyNormalizedReactionTimeResultKey</th>\n",
       "      <th>SurveyStepResultKey</th>\n",
       "      <th>SurveyResultKey</th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>ReactionDate</th>\n",
       "      <th>StimulusStartDate</th>\n",
       "      <th>TimerStartDate</th>\n",
       "      <th>TimerEndDate</th>\n",
       "      <th>CurrentInterval</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>datetime</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bdea09a1-6cd4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>9eea09a1-6cd4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>6aea09a1-6cd4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>5599c2a7-88a5-4cde-9f2a-41b4bd03d660</td>\n",
       "      <td>684795.33562904166</td>\n",
       "      <td>684794.69247337501</td>\n",
       "      <td>684795.00184995832</td>\n",
       "      <td>684795.33570358332</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-04-06T07:17:19-04:00</td>\n",
       "      <td>2023-04-06T07:17:19-04:00</td>\n",
       "      <td>2023-04-06 07:17:19-04:00</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>07:17:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c0ea09a1-6cd4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>9eea09a1-6cd4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>6aea09a1-6cd4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>5599c2a7-88a5-4cde-9f2a-41b4bd03d660</td>\n",
       "      <td>684805.07946041669</td>\n",
       "      <td>684804.38685095834</td>\n",
       "      <td>684804.74665975</td>\n",
       "      <td>684805.07948995836</td>\n",
       "      <td>6</td>\n",
       "      <td>2023-04-06T07:17:29-04:00</td>\n",
       "      <td>2023-04-06T07:17:29-04:00</td>\n",
       "      <td>2023-04-06 07:17:29-04:00</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>07:17:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SurveyNormalizedReactionTimeResultKey                   SurveyStepResultKey  \\\n",
       "0  bdea09a1-6cd4-ed11-aac6-0afb9334277d  9eea09a1-6cd4-ed11-aac6-0afb9334277d   \n",
       "1  c0ea09a1-6cd4-ed11-aac6-0afb9334277d  9eea09a1-6cd4-ed11-aac6-0afb9334277d   \n",
       "\n",
       "                        SurveyResultKey                 ParticipantIdentifier  \\\n",
       "0  6aea09a1-6cd4-ed11-aac6-0afb9334277d  5599c2a7-88a5-4cde-9f2a-41b4bd03d660   \n",
       "1  6aea09a1-6cd4-ed11-aac6-0afb9334277d  5599c2a7-88a5-4cde-9f2a-41b4bd03d660   \n",
       "\n",
       "         ReactionDate   StimulusStartDate      TimerStartDate  \\\n",
       "0  684795.33562904166  684794.69247337501  684795.00184995832   \n",
       "1  684805.07946041669  684804.38685095834     684804.74665975   \n",
       "\n",
       "         TimerEndDate  CurrentInterval                  StartDate  \\\n",
       "0  684795.33570358332                2  2023-04-06T07:17:19-04:00   \n",
       "1  684805.07948995836                6  2023-04-06T07:17:29-04:00   \n",
       "\n",
       "                     EndDate                   datetime  trial_date      time  \n",
       "0  2023-04-06T07:17:19-04:00  2023-04-06 07:17:19-04:00  2023-04-06  07:17:19  \n",
       "1  2023-04-06T07:17:29-04:00  2023-04-06 07:17:29-04:00  2023-04-06  07:17:29  "
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace commas with dots\n",
    "df['ReactionDate'] = df['ReactionDate'].replace(',', '.', regex=True)\n",
    "df.ReactionDate = df.ReactionDate.astype('float')\n",
    "\n",
    "df['StimulusStartDate'] = df['StimulusStartDate'].replace(',', '.', regex=True)\n",
    "df.StimulusStartDate = df.StimulusStartDate.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['task_rt_time'] = df.ReactionDate - df.StimulusStartDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>task_rt_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5599c2a7-88a5-4cde-9f2a-41b4bd03d660</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>0.643156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5599c2a7-88a5-4cde-9f2a-41b4bd03d660</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>0.692609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5599c2a7-88a5-4cde-9f2a-41b4bd03d660</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>0.728588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5599c2a7-88a5-4cde-9f2a-41b4bd03d660</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>0.793508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>0.430718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>0.483464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>0.498956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>0.431452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35d11ffc-7034-4708-a086-cd4bd47b51fd</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>0.725344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>35d11ffc-7034-4708-a086-cd4bd47b51fd</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>0.552103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ParticipantIdentifier  trial_date  task_rt_time\n",
       "0  5599c2a7-88a5-4cde-9f2a-41b4bd03d660  2023-04-06      0.643156\n",
       "1  5599c2a7-88a5-4cde-9f2a-41b4bd03d660  2023-04-06      0.692609\n",
       "2  5599c2a7-88a5-4cde-9f2a-41b4bd03d660  2023-04-06      0.728588\n",
       "3  5599c2a7-88a5-4cde-9f2a-41b4bd03d660  2023-04-06      0.793508\n",
       "4  0151d9f1-1644-4437-805e-02f5e244a690  2023-04-06      0.430718\n",
       "5  0151d9f1-1644-4437-805e-02f5e244a690  2023-04-06      0.483464\n",
       "6  0151d9f1-1644-4437-805e-02f5e244a690  2023-04-06      0.498956\n",
       "7  0151d9f1-1644-4437-805e-02f5e244a690  2023-04-06      0.431452\n",
       "8  35d11ffc-7034-4708-a086-cd4bd47b51fd  2023-04-06      0.725344\n",
       "9  35d11ffc-7034-4708-a086-cd4bd47b51fd  2023-04-06      0.552103"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep relevant columns\n",
    "rt_df = df[['ParticipantIdentifier', 'trial_date', 'task_rt_time']]\n",
    "# If negative it was a missed/error trial\n",
    "rt_df.loc[rt_df.task_rt_time <=0, 'task_rt_time'] = None\n",
    "\n",
    "rt_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    'task_rt_1',\n",
    "    'task_rt_2',\n",
    "    'task_rt_3',\n",
    "    'task_rt_4',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lw/ys_1b9sj08s904m4402qr0bm0000gn/T/ipykernel_55486/1635772240.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rt_df['label'] = None\n"
     ]
    }
   ],
   "source": [
    "oldSub = None\n",
    "oldDay = None\n",
    "i = 1\n",
    "rt_df['label'] = None\n",
    "\n",
    "for row in range(len(df)):\n",
    "    sub = rt_df.loc[row,'ParticipantIdentifier']\n",
    "    day = rt_df.loc[row, 'trial_date']\n",
    "    if (sub == oldSub) & (day == oldDay):\n",
    "        if i >3:\n",
    "            continue\n",
    "        else:\n",
    "            rt_df.loc[row, 'label'] = labels[i]\n",
    "            oldSub = sub\n",
    "            oldDay = day\n",
    "            i+=1\n",
    "    else:\n",
    "        rt_df.loc[row, 'label'] = labels[0]\n",
    "        i = 1\n",
    "        oldSub = sub\n",
    "        oldDay = day\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_df = rt_df.dropna(subset=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "758"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt_df.duplicated(subset=['ParticipantIdentifier', 'trial_date', 'label']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_df = rt_df.drop_duplicates(subset=['ParticipantIdentifier', 'trial_date', 'label'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>task_rt_1</th>\n",
       "      <th>task_rt_2</th>\n",
       "      <th>task_rt_3</th>\n",
       "      <th>task_rt_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-01-30</td>\n",
       "      <td>0.430230</td>\n",
       "      <td>0.500456</td>\n",
       "      <td>0.563285</td>\n",
       "      <td>0.448408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>0.414063</td>\n",
       "      <td>0.766173</td>\n",
       "      <td>0.466758</td>\n",
       "      <td>0.431114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>0.426607</td>\n",
       "      <td>0.429335</td>\n",
       "      <td>0.428868</td>\n",
       "      <td>0.445612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-02-02</td>\n",
       "      <td>0.496612</td>\n",
       "      <td>0.447787</td>\n",
       "      <td>0.481698</td>\n",
       "      <td>0.431870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>0.431316</td>\n",
       "      <td>0.481745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ParticipantIdentifier  trial_date  task_rt_1  task_rt_2  \\\n",
       "0  0151d9f1-1644-4437-805e-02f5e244a690  2023-01-30   0.430230   0.500456   \n",
       "1  0151d9f1-1644-4437-805e-02f5e244a690  2023-01-31   0.414063   0.766173   \n",
       "2  0151d9f1-1644-4437-805e-02f5e244a690  2023-02-01   0.426607   0.429335   \n",
       "3  0151d9f1-1644-4437-805e-02f5e244a690  2023-02-02   0.496612   0.447787   \n",
       "4  0151d9f1-1644-4437-805e-02f5e244a690  2023-02-03   0.431316   0.481745   \n",
       "\n",
       "   task_rt_3  task_rt_4  \n",
       "0   0.563285   0.448408  \n",
       "1   0.466758   0.431114  \n",
       "2   0.428868   0.445612  \n",
       "3   0.481698   0.431870  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt_df = rt_df.pivot(index=['ParticipantIdentifier', 'trial_date'], columns='label', values='task_rt_time').reset_index()\n",
    "\n",
    "# Remove index name\n",
    "rt_df = rt_df.rename_axis(None, axis=1)\n",
    "\n",
    "rt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract columns starting with \"task_rt_\"\n",
    "task_rt_columns = [col for col in rt_df.columns if col.startswith(\"task_rt_\")]\n",
    "\n",
    "# Replace values in task_rt_columns that are below 0.1 with NaN\n",
    "rt_df[task_rt_columns] = rt_df[task_rt_columns].applymap(lambda x: x if x >= 0.1 else float('nan'))\n",
    "\n",
    "# Calculate 'task_rt_avgRT' column\n",
    "rt_df['task_rt_avgRT'] = rt_df[task_rt_columns].mean(axis=1)\n",
    "\n",
    "# Calculate 'task_rt_flag_plus2_n' column\n",
    "rt_df['task_rt_flag_plus2_n'] = rt_df[task_rt_columns].apply(lambda row: sum(row > 2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 41/41 [00:12<00:00,  3.35it/s, Completed]                           \n",
      "Generate report structure: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 300.67it/s]\n"
     ]
    }
   ],
   "source": [
    "profile = ProfileReport(rt_df.iloc[:,2:], title=f\"RT Task Run {run_num} | Pandas Profiling Report\")\n",
    "profile.to_file(eda_reports_path + f\"task_rt_run{run_num}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>task_rt_1</th>\n",
       "      <th>task_rt_2</th>\n",
       "      <th>task_rt_3</th>\n",
       "      <th>task_rt_4</th>\n",
       "      <th>task_rt_avgRT</th>\n",
       "      <th>task_rt_flag_plus2_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-01-30</td>\n",
       "      <td>0.430230</td>\n",
       "      <td>0.500456</td>\n",
       "      <td>0.563285</td>\n",
       "      <td>0.448408</td>\n",
       "      <td>0.485595</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>0.414063</td>\n",
       "      <td>0.766173</td>\n",
       "      <td>0.466758</td>\n",
       "      <td>0.431114</td>\n",
       "      <td>0.519527</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>0.426607</td>\n",
       "      <td>0.429335</td>\n",
       "      <td>0.428868</td>\n",
       "      <td>0.445612</td>\n",
       "      <td>0.432606</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-02-02</td>\n",
       "      <td>0.496612</td>\n",
       "      <td>0.447787</td>\n",
       "      <td>0.481698</td>\n",
       "      <td>0.431870</td>\n",
       "      <td>0.464492</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>0.431316</td>\n",
       "      <td>0.481745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.456530</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ParticipantIdentifier  trial_date  task_rt_1  task_rt_2  \\\n",
       "0  0151d9f1-1644-4437-805e-02f5e244a690  2023-01-30   0.430230   0.500456   \n",
       "1  0151d9f1-1644-4437-805e-02f5e244a690  2023-01-31   0.414063   0.766173   \n",
       "2  0151d9f1-1644-4437-805e-02f5e244a690  2023-02-01   0.426607   0.429335   \n",
       "3  0151d9f1-1644-4437-805e-02f5e244a690  2023-02-02   0.496612   0.447787   \n",
       "4  0151d9f1-1644-4437-805e-02f5e244a690  2023-02-03   0.431316   0.481745   \n",
       "\n",
       "   task_rt_3  task_rt_4  task_rt_avgRT  task_rt_flag_plus2_n  \n",
       "0   0.563285   0.448408       0.485595                     0  \n",
       "1   0.466758   0.431114       0.519527                     0  \n",
       "2   0.428868   0.445612       0.432606                     0  \n",
       "3   0.481698   0.431870       0.464492                     0  \n",
       "4        NaN        NaN       0.456530                     0  "
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean\n",
    "\n",
    "**RTs**\n",
    "\n",
    "We have some very long RTs (many minutes long). Clearly people are distracted for these trials. \n",
    "\n",
    "We leave these in but create a column called `task_rt_flag_plus2_n` that indicates how many trials had rts greater than 2 seconds.\n",
    "\n",
    "We also know from the work of Luce (1984) and Whelan (2008) that RTs below 100ms are not realistic, so we remove those values and replace with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 41/41 [00:01<00:00, 25.12it/s, Completed]                           \n",
      "Generate report structure: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00,  3.95it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 764.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# Rerun EDA filtering out flagged trials\n",
    "profile = ProfileReport(rt_df.loc[rt_df['task_rt_flag_plus2_n']==0, \"task_rt_1\":], title=f\"RT Task Run {run_num} - Cleaned | Pandas Profiling Report\")\n",
    "profile.to_file(eda_reports_path + f\"task_rt_run{run_num}_clean.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Span Memory\n",
    "\n",
    "\n",
    "[RK Studio Documentation](http://researchkit.org/docs/docs/ActiveTasks/ActiveTasks.html#spatialhttp://researchkit.org/docs/docs/ActiveTasks/ActiveTasks.html#spatial)\n",
    "\n",
    "> In the spatial memory task the user is asked to observe and then recall pattern sequences of increasing length in a game-like environment. The task collects data that can be used to assess visuospatial memory and executive function.\n",
    "\n",
    ">The span (that is, the length of the pattern sequence) is automatically varied during the task, increasing after successful completion of a sequence, and decreasing after failures, in the range from minimumSpan to maximumSpan. The playSpeed property lets you control the speed of sequence playback, and the customTargetImage property lets you customize the shape of the tap target. The game finishes when either maxTests tests have been completed, or the user has made maxConsecutiveFailures errors in a row.\n",
    "\n",
    ">The results collected are scores derived from the game, the details of the game, and the touch inputs made by the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted existing df\n"
     ]
    }
   ],
   "source": [
    "# erase df if it already exists\n",
    "if 'df' in globals():\n",
    "    del(df)\n",
    "    print('deleted existing df')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:00<00:00, 65.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# loop through all days\n",
    "days = [i for i in os.listdir(path) if i.startswith('RK')]\n",
    "for day in tqdm(days):\n",
    "    files = os.listdir(path + day)\n",
    "    surveyQuestions = [i for i in files if i.startswith('SurveySpatialSpanMemoryResults')]\n",
    "    # there should be only one\n",
    "    for file in surveyQuestions:\n",
    "        if 'df' not in globals():\n",
    "            df = pd.read_csv(path + day + '/' + file)\n",
    "        else:\n",
    "            temp_df = pd.read_csv(path + day + '/' + file)\n",
    "            df = pd.concat([df,temp_df], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SurveySpatialSpanMemoryResultKey    0\n",
       "SurveyStepResultKey                 0\n",
       "SurveyResultKey                     0\n",
       "ParticipantIdentifier               0\n",
       "Score                               0\n",
       "NumberOfGames                       0\n",
       "NumberOfFailures                    0\n",
       "StartDate                           0\n",
       "EndDate                             0\n",
       "GameRecords                         0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check for na dates...\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['EndDate']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only subjects in run 1\n",
    "df = df.loc[df.ParticipantIdentifier.isin(subjects)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6430/6430 [00:01<00:00, 4453.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# add trial date and time columns\n",
    "for i in tqdm(range(df.shape[0])):\n",
    "    dt = parser.parse(df.loc[i, 'EndDate'])\n",
    "    df.loc[i, 'datetime'] = dt\n",
    "    df.loc[i, 'trial_date'] = (dt + datetime.timedelta(hours = -4)).date() # trial day associated with sample (4am is when the day flips)\n",
    "    df.loc[i, 'time'] = dt.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SurveySpatialSpanMemoryResultKey</th>\n",
       "      <th>SurveyStepResultKey</th>\n",
       "      <th>SurveyResultKey</th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>Score</th>\n",
       "      <th>NumberOfGames</th>\n",
       "      <th>NumberOfFailures</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>GameRecords</th>\n",
       "      <th>datetime</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89a2d274-6ed4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>7aa2d274-6ed4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>6ca2d274-6ed4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>540</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-04-06T07:29:46-04:00</td>\n",
       "      <td>2023-04-06T07:30:42-04:00</td>\n",
       "      <td>[{\"Seed\":980801876,\"Sequence\":[8,7,1],\"GameSiz...</td>\n",
       "      <td>2023-04-06 07:30:42-04:00</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>07:30:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>532b549c-70d4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>3c2b549c-70d4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>2c2b549c-70d4-ed11-aac6-0afb9334277d</td>\n",
       "      <td>5599c2a7-88a5-4cde-9f2a-41b4bd03d660</td>\n",
       "      <td>385</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-04-06T07:45:19-04:00</td>\n",
       "      <td>2023-04-06T07:46:11-04:00</td>\n",
       "      <td>[{\"Seed\":1347940271,\"Sequence\":[2,3,8],\"GameSi...</td>\n",
       "      <td>2023-04-06 07:46:11-04:00</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>07:46:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SurveySpatialSpanMemoryResultKey                   SurveyStepResultKey  \\\n",
       "0  89a2d274-6ed4-ed11-aac6-0afb9334277d  7aa2d274-6ed4-ed11-aac6-0afb9334277d   \n",
       "1  532b549c-70d4-ed11-aac6-0afb9334277d  3c2b549c-70d4-ed11-aac6-0afb9334277d   \n",
       "\n",
       "                        SurveyResultKey                 ParticipantIdentifier  \\\n",
       "0  6ca2d274-6ed4-ed11-aac6-0afb9334277d  0151d9f1-1644-4437-805e-02f5e244a690   \n",
       "1  2c2b549c-70d4-ed11-aac6-0afb9334277d  5599c2a7-88a5-4cde-9f2a-41b4bd03d660   \n",
       "\n",
       "   Score  NumberOfGames  NumberOfFailures                  StartDate  \\\n",
       "0    540              6                 0  2023-04-06T07:29:46-04:00   \n",
       "1    385              6                 1  2023-04-06T07:45:19-04:00   \n",
       "\n",
       "                     EndDate  \\\n",
       "0  2023-04-06T07:30:42-04:00   \n",
       "1  2023-04-06T07:46:11-04:00   \n",
       "\n",
       "                                         GameRecords  \\\n",
       "0  [{\"Seed\":980801876,\"Sequence\":[8,7,1],\"GameSiz...   \n",
       "1  [{\"Seed\":1347940271,\"Sequence\":[2,3,8],\"GameSi...   \n",
       "\n",
       "                    datetime  trial_date      time  \n",
       "0  2023-04-06 07:30:42-04:00  2023-04-06  07:30:42  \n",
       "1  2023-04-06 07:46:11-04:00  2023-04-06  07:46:11  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "To capture performance we are using:\n",
    "- `Score` \n",
    "\n",
    "**NB** | Might be worth checking out exactly how this is calculated, but for our purposes it seems to be a good proxy of how well you actually do on the task (e.g. you get a better score if you fail on the last attempt (to get 8 in a row) then if you fail on the second attempt and only make it to 6 in a row...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>task_spatialSpan_score</th>\n",
       "      <th>task_spatialSpan_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0151d9f1-1644-4437-805e-02f5e244a690</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>540</td>\n",
       "      <td>07:30:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5599c2a7-88a5-4cde-9f2a-41b4bd03d660</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>385</td>\n",
       "      <td>07:46:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ParticipantIdentifier  trial_date  task_spatialSpan_score  \\\n",
       "0  0151d9f1-1644-4437-805e-02f5e244a690  2023-04-06                     540   \n",
       "1  5599c2a7-88a5-4cde-9f2a-41b4bd03d660  2023-04-06                     385   \n",
       "\n",
       "  task_spatialSpan_time  \n",
       "0              07:30:42  \n",
       "1              07:46:11  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assign new column with accuracy value\n",
    "df = df.assign(task_spatialSpan_score=lambda x: x.Score,\n",
    "               task_spatialSpan_time=lambda x: x.time\n",
    "              )\n",
    "\n",
    "# keep relevant columns\n",
    "spatialSpan_df = df[['ParticipantIdentifier', 'trial_date', 'task_spatialSpan_score', 'task_spatialSpan_time']]\n",
    "spatialSpan_df.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
