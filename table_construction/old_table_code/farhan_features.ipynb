{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8652065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import datetime\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e44161",
   "metadata": {},
   "source": [
    "### Required Files:\n",
    "- 'SurveyTrailmakingResults'\n",
    "- 'SurveyStroopResults'\n",
    "- 'SurveyPSATResults'\n",
    "- 'SurveyTowerOfHanoiResults'\n",
    "- 'SurveyReactionTimeResults'\n",
    "- 'SurveySpatialSpanMemoryResults'\n",
    "\n",
    "### Tasks that are currently relevant\n",
    "- Trail making\n",
    "- Stroop\n",
    "- PSAT\n",
    "- Tower of Hanoi\n",
    "- Reaction Time\n",
    "- Spatial Span Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b1cb18",
   "metadata": {},
   "source": [
    "### Variable Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7824fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input Directory\n",
    "directory = \"../daily_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9e2127b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output Directory\n",
    "out_dir = \"../indv_table_exports/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5a298afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Good Participants\n",
    "good_subjects = ['01801252-3a7e-4f5f-8b6d-49e8da3902f3',\n",
    "                 'd26d4b78-7fcf-488e-b687-2d1c93c47b74',\n",
    "                 '531d7f6d-b880-4a0b-b467-80005a316f1c']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997d82b0",
   "metadata": {},
   "source": [
    "### Handy Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "80045cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to fix date from UTC to ET\n",
    "def fix_date_to_ET(dataframe, date_col_name):\n",
    "    # Add date column to samples dataframe\n",
    "    df = dataframe\n",
    "    df[date_col_name] = 0\n",
    "    \n",
    "    for i in range(len(df.EndDate)):\n",
    "        df.iloc[i]\n",
    "        if pd.to_datetime(df.EndDate[i], format= '%Y-%m-%d', utc=True).tz_convert('US/Eastern').hour < 5:\n",
    "            # subtract one day from date\n",
    "            df.loc[i, date_col_name] = pd.to_datetime(df.EndDate[i], format= '%Y-%m-%d', utc=True).tz_convert('US/Eastern').date() - datetime.timedelta(days=1)\n",
    "        else:\n",
    "            df.loc[i, date_col_name] = pd.to_datetime(df.EndDate[i], format= '%Y-%m-%d', utc=True).tz_convert('US/Eastern').date()\n",
    "    return df\n",
    "\n",
    "def fix_columns_by_category(dataframe, categories):\n",
    "    df = dataframe\n",
    "    for item in categories:\n",
    "        if item not in df.columns.to_list():\n",
    "            df[item] = 'NaN'\n",
    "    return df\n",
    "\n",
    "def pivot_df(dataframe, pos: list, col, val):\n",
    "    df = dataframe\n",
    "    df = df.pivot_table(index=pos,\n",
    "                    columns=col, \n",
    "                    values=val).reset_index()\n",
    "    return df\n",
    "\n",
    "def get_time_diff(d2, d1):\n",
    "    return (d2 - d1).days\n",
    "\n",
    "def convert_survey_file_to_dataframe(directory, filename, date_col):\n",
    "    df_survey_list = []\n",
    "    for folder in os.listdir(directory):\n",
    "        survey_file_name = \"\"\n",
    "        path = directory + \"/\" + folder\n",
    "        for f_name in os.listdir(path):\n",
    "            if f_name.startswith(filename):\n",
    "                survey_file_name = f_name\n",
    "                break\n",
    "\n",
    "        if survey_file_name == \"\":\n",
    "            continue\n",
    "\n",
    "        path = path + '/' + survey_file_name\n",
    "\n",
    "        current_df = pd.read_csv(path) \n",
    "        current_df[date_col] = 0\n",
    "        current_df = fix_date_to_ET(current_df, date_col)\n",
    "        df_survey_list.append(current_df)\n",
    "\n",
    "    df_survey = pd.concat(df_survey_list)\n",
    "    return df_survey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb8c9c7",
   "metadata": {},
   "source": [
    "### Trailmaking Task\n",
    "The subject is instructed to connect a set of 25 dots as quickly as possible while still maintaining accuracy. \n",
    "It measures:\n",
    "- visual attention\n",
    "- task switching\n",
    "- fluid intelligence/cognitive abilities\n",
    "\n",
    "We are doing a version that is like the typical Version B:\n",
    "- Salthouse, 2011\n",
    "\n",
    "_We want to get the last TapTimestamp to calculate total timing_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e60b0d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Got all 'SurveyTrailmakingResults' till date in a dataframe\n",
    "df_tr_survey = convert_survey_file_to_dataframe(directory, \n",
    "                                                'SurveyTrailmakingResults', \n",
    "                                                'ActualDueDate')\n",
    "\n",
    "## convert string Taps to list of dicts (Wilson, D.)\n",
    "df = df_tr_survey\n",
    "df['TapsList'] = df['Taps'].apply(json.loads)\n",
    "\n",
    "## assign new columns with final value from TapsList (Wilson, D.)\n",
    "df = df.assign(Task_Trailmaking_Time=lambda x: x.TapsList.apply(lambda x: x[-1]['TapTimestamp']),\n",
    "               Task_Trailmaking_Errors=lambda x: x.NumberOfErrors)\n",
    "\n",
    "## keep relevant columns\n",
    "df = df[['ParticipantIdentifier', 'ActualDueDate', 'Task_Trailmaking_Time', 'Task_Trailmaking_Errors']]\n",
    "df_trail_making = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85bdb9c",
   "metadata": {},
   "source": [
    "### Stroop Task\n",
    "- (Scarpina & Tagini, 2017)\n",
    "- The Stroop Color and Word Test (SCWT) \n",
    "- Will calculate the stroop effect and relevant descriptive stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a2da1ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function that returns a Series of all Stroop results aggregates (Wilson, D.)\n",
    "def get_stroop_results(x):\n",
    "    d = {}\n",
    "    \n",
    "    d['Task_Stroop_TotalCorrectProp'] = x['Correct'].sum()/len(x['Correct'])\n",
    "    d['Task_Stroop_CongruentCorrectProp'] = len(x.loc[(x.Congruent==True) & (x.Correct==True)])/x.Congruent.value_counts()[1]\n",
    "    d['Task_Stroop_IncongruentCorrectProp'] = len(x.loc[(x.Congruent==False) & (x.Correct==True)])/x.Congruent.value_counts()[0]\n",
    "    d['Task_Stroop_TotalAvgRT'] = x['Time'].sum()/len(x['Time'])    \n",
    "    d['Task_Stroop_CongruentAvgRT'] = x.loc[x.Congruent==True,'Time'].sum()/x.Congruent.value_counts()[1]    \n",
    "    d['Task_Stroop_IncongruentAvgRT'] = x.loc[x.Congruent==False,'Time'].sum()/x.Congruent.value_counts()[0]\n",
    "    \n",
    "    return pd.Series(d, index=['Task_Stroop_TotalCorrectProp', 'Task_Stroop_CongruentCorrectProp',\n",
    "                               'Task_Stroop_IncongruentCorrectProp', 'Task_Stroop_TotalAvgRT',\n",
    "                               'Task_Stroop_CongruentAvgRT', 'Task_Stroop_IncongruentAvgRT'\n",
    "                              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b8b5f4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Got all 'SurveyStroopResults' till date in a dataframe\n",
    "df_stroop_survey = convert_survey_file_to_dataframe(directory, \n",
    "                                                'SurveyStroopResults', \n",
    "                                                'ActualDueDate')\n",
    "\n",
    "## Keep Relevant columns only (Wilson, D.)\n",
    "df = df_stroop_survey\n",
    "df = df[['ParticipantIdentifier', 'ActualDueDate', 'StartTime', \n",
    "         'EndTime', 'ColorSelected', 'Color', 'Text']]\n",
    "\n",
    "# Create correct, congruent and time columns (Wilson, D.)\n",
    "df = df.assign(Congruent=lambda x: x.Color == x.Text,\n",
    "               Correct=lambda x: x.Color == x.ColorSelected,\n",
    "               Time=lambda x: (x.EndTime - x.StartTime)\n",
    "              )\n",
    "\n",
    "df = df.groupby(['ActualDueDate', \n",
    "                 'ParticipantIdentifier']).apply(get_stroop_results).reset_index()\n",
    "df_stroop = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dacf570",
   "metadata": {},
   "source": [
    "### PSAT Results\n",
    "- Calculate TotalTime/Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b10cb095",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get all PSAT results till date in a dataframe\n",
    "df_psat_survey = convert_survey_file_to_dataframe(directory, \n",
    "                                                'SurveyPSATResults', \n",
    "                                                'ActualDueDate')\n",
    "\n",
    "## Assign new column with accuracy value (Wilson D.)\n",
    "df = df_psat_survey\n",
    "df = df.assign(Task_PSAT_Accuracy=lambda x: x.TotalCorrect/x.Length,\n",
    "               Task_PSAT_AvgTime=lambda x: x.TotalTime/x.Length\n",
    "              )\n",
    "\n",
    "## Keep relevant columns\n",
    "df_psat = df[['ParticipantIdentifier', 'ActualDueDate', 'Task_PSAT_Accuracy', 'Task_PSAT_AvgTime']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1b4c49",
   "metadata": {},
   "source": [
    "### Tower of Hanoi Task\n",
    "- Moves is a string of a list of dictionaries\n",
    "- Get total time required: Timestamp in last dictionary\n",
    "- Get number of moves: 1 dict/move so get count of dicts)\n",
    "\n",
    "**Important data is:**\n",
    "- PuzzleWasSolved: Indicate completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "14de8c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get all TOH results till date in a dataframe\n",
    "df_TOH_survey = convert_survey_file_to_dataframe(directory, \n",
    "                                                'SurveyTowerOfHanoiResults', \n",
    "                                                'ActualDueDate')\n",
    "df = df_TOH_survey\n",
    "\n",
    "## Convert string Moves to list of dicts (Wilson D.)\n",
    "df['MovesList'] = df['Moves'].apply(json.loads)\n",
    "\n",
    "## Assign new columns (Wilson D.)\n",
    "df = df.assign(Task_Hanoi_Solved=lambda x: x.PuzzleWasSolved,\n",
    "               Task_Hanoi_Time=lambda x: x.MovesList.apply(lambda x: x[-1]['Timestamp']),\n",
    "               Task_Hanoi_Moves=[len(moves) for moves in df.MovesList] # maybe give this as a multiple on optimality (ideal = 1)?\n",
    "              )\n",
    "\n",
    "## Keep relevant columns\n",
    "df_TOH = df[['ParticipantIdentifier', 'ActualDueDate', 'Task_Hanoi_Solved', 'Task_Hanoi_Time', 'Task_Hanoi_Moves']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ec90be",
   "metadata": {},
   "source": [
    "### Reaction Time Results\n",
    "- The important data is:\n",
    "- ReactionTime\n",
    "    - Use this to calculate both mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "edd2e604",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get all Reaction Time results till date in a dataframe\n",
    "df_rt_survey = convert_survey_file_to_dataframe(directory, \n",
    "                                                'SurveyReactionTimeResults', \n",
    "                                                'ActualDueDate')\n",
    "\n",
    "## Get mean and SD of Reaction Time\n",
    "df = df_rt_survey\n",
    "df = pd.DataFrame(df.groupby(['ActualDueDate', 'ParticipantIdentifier'])['ReactionTime'].agg(['mean', 'std'])).reset_index()\n",
    "\n",
    "## Rename columns (Wilson D.)\n",
    "df.rename(columns={'mean': 'Task_RT_Mean', 'std': 'Task_RT_SD'}, inplace=True)\n",
    "\n",
    "## Get final RT Results dataframe\n",
    "df_reaction_time = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfd6c0f",
   "metadata": {},
   "source": [
    "### Spatial Span Memory Results\n",
    "- To capture performance we are using: Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2b664151",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get all Spatial Span Memory results till date in a dataframe\n",
    "df_ssm_survey = convert_survey_file_to_dataframe(directory, \n",
    "                                                'SurveySpatialSpanMemoryResults', \n",
    "                                                'ActualDueDate')\n",
    "## Assign new column with accuracy value (Wilson D.)\n",
    "df = df_ssm_survey\n",
    "df = df.assign(Task_SSMemory_Score=lambda x: x.Score)\n",
    "\n",
    "## Keep relevant columns\n",
    "df = df[['ParticipantIdentifier', 'ActualDueDate', 'Task_SSMemory_Score']]\n",
    "df_spatial_span = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0256b22f",
   "metadata": {},
   "source": [
    "## Get Task Dataframe\n",
    "For this, we need to get the following df of each good participant:\n",
    "- df_trail_making\n",
    "- df_stroop\n",
    "- df_psat\n",
    "- df_TOH\n",
    "- df_reaction_time\n",
    "- df_spatial_span\n",
    "    \n",
    "Merge these 6 dataframes on ParticipantIdentifier and ActualDueDate\n",
    "- This will give Task Dataframe of one participant\n",
    "\n",
    "_Do the same for all good participants and concatenate to get final df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7e39952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_list = []\n",
    "for item in good_subjects:\n",
    "    ## Get all relevant DF for the current good subject\n",
    "    df_trail_making_temp = df_trail_making[df_trail_making.ParticipantIdentifier.isin([item])].reset_index(drop=True)\n",
    "    df_stroop_temp = df_stroop[df_stroop.ParticipantIdentifier.isin([item])].reset_index(drop=True)\n",
    "    df_psat_temp = df_psat[df_psat.ParticipantIdentifier.isin([item])].reset_index(drop=True)\n",
    "    df_TOH_temp = df_TOH[df_TOH.ParticipantIdentifier.isin([item])].reset_index(drop=True)\n",
    "    df_reaction_time_temp = df_reaction_time[df_reaction_time.ParticipantIdentifier.isin([item])].reset_index(drop=True)\n",
    "    df_spatial_span_temp = df_spatial_span[df_spatial_span.ParticipantIdentifier.isin([item])].reset_index(drop=True)\n",
    "    \n",
    "    ## Merge them to get this subject's task df\n",
    "    df_task_temp = df_trail_making_temp\n",
    "    df_task_temp = df_task_temp.merge(df_stroop_temp, how='left', on=['ParticipantIdentifier', 'ActualDueDate'])\n",
    "    df_task_temp = df_task_temp.merge(df_psat_temp, how='left', on=['ParticipantIdentifier', 'ActualDueDate'])\n",
    "    df_task_temp = df_task_temp.merge(df_TOH_temp, how='left', on=['ParticipantIdentifier', 'ActualDueDate'])\n",
    "    df_task_temp = df_task_temp.merge(df_reaction_time_temp, how='left', on=['ParticipantIdentifier', 'ActualDueDate'])\n",
    "    df_task_temp = df_task_temp.merge(df_spatial_span_temp, how='left', on=['ParticipantIdentifier', 'ActualDueDate'])\n",
    "    \n",
    "    df_task_list.append(df_task_temp)\n",
    "\n",
    "df_task = pd.concat(df_task_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab5475c",
   "metadata": {},
   "source": [
    "### Export Task Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8d62f078",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task.to_csv('tasks.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e2bd98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
